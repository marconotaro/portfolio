{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Predicting salary and new connections from network data\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "Note: data from the Coursera course [Applied Social Network Analysis in Python](https://www.coursera.org/learn/python-social-network-analysis?specialization=data-science-python)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8555f884d1a86e615633814fe0640fa9",
     "grade": false,
     "grade_id": "cell-04d6d26d762f743a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24751ee5132e6ae445b370a534718f46",
     "grade": false,
     "grade_id": "cell-a8b02acc0a67f5cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Company Emails\n",
    "\n",
    "Here I analzye a company's email network where a node corresponds to a person and an edge indicates that at least one email has been sent between two people. The network also contains the node attributes `Department` and `ManagmentSalary`. `Department` indicates the department in the company which the person belongs to, and `ManagmentSalary` indicates whether that person is receiving a managment position salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e722c34a6345262e25f7b6f3aa9ea24f",
     "grade": false,
     "grade_id": "cell-8318572a20542eb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 1005 nodes and 16706 edges\n"
     ]
    }
   ],
   "source": [
    "G = pickle.load(open('data/email_prediction.txt', 'rb'))\n",
    "\n",
    "print(f\"Graph with {len(nx.nodes(G))} nodes and {len(nx.edges(G))} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fce5fb3b46c870ef3a396d6272fb5741",
     "grade": false,
     "grade_id": "cell-e87009c4bfab6968",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Salary Prediction\n",
    "\n",
    "Here I aim at predicting if people whithout a `ManagementSalary` will receive a managment position salary. To this end, I train a classifier on people that have `ManagementSalary` and then I predict the probability of receiving a managment salary for those people where `ManagementSalary` is missing. Models are evaluated with different performance metrics, Area Under the ROC Curve (AUCROC), Area under the Precision Recall Curve (AUPRC) and Balanced Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d02e4f542d1aa318bbf2d31a4190f873",
     "grade": false,
     "grade_id": "cell-5980e664930b216a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'Department': 1, 'ManagementSalary': 0.0}),\n",
       " (1, {'Department': 1, 'ManagementSalary': nan}),\n",
       " (581, {'Department': 3, 'ManagementSalary': 0.0}),\n",
       " (6, {'Department': 25, 'ManagementSalary': 1.0}),\n",
       " (65, {'Department': 4, 'ManagementSalary': nan})]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(G.nodes(data=True))[:5] # print the first 5 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_salary_dataset(G):\n",
    "    df = pd.DataFrame()\n",
    "    df['management_salary'] = nx.get_node_attributes(G, 'ManagementSalary')\n",
    "    df['department'] = nx.get_node_attributes(G, 'Department')\n",
    "    df['clustering'] = nx.clustering(G)\n",
    "    df['betweenness'] = nx.betweenness_centrality(G)\n",
    "    df['closenness'] = nx.closeness_centrality(G)\n",
    "    df['pagerank'] = nx.pagerank(G)\n",
    "    df['hubs'], df['auth'] = nx.hits(G)\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_feature_and_label(df, label='management_salary'):\n",
    "    X = df.drop(columns=[label]) ## df.iloc[:,1:]\n",
    "    y = df[label]                ## df.iloc[:,0]\n",
    "    return X,y\n",
    "\n",
    "class GridDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(GridDict, self).__init__(*args, **kwargs)\n",
    "        self.best_params_ = self\n",
    "\n",
    "def get_best_parameters(X, y, tune=True):\n",
    "    # from sklearn.model_selection import train_test_split\n",
    "    ## with random_state=0 same as splitting below\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    X_train, y_train = X.loc[~y.isna(),:], y[~y.isna()]\n",
    "    X_test, y_test = X.loc[y.isna(),:], y[y.isna()]\n",
    "\n",
    "    # Create the pipeline: in this way the scaling is included in each cv, making the model selection more robust\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), # Step 1: Scale the data \n",
    "                         ('rfc', RandomForestClassifier(random_state=0)) # Step 2: Train the model \n",
    "                        ])\n",
    "    ## grid search\n",
    "    param_grid = {\n",
    "        'rfc__n_estimators': [50, 100, 200],\n",
    "        'rfc__max_depth': [10, 20, 30],\n",
    "        'rfc__min_samples_split': [2, 5, 10],\n",
    "        'rfc__min_samples_leaf': [1, 2, 4],\n",
    "        'rfc__max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "    if tune:\n",
    "        rfc = RandomForestClassifier(random_state=0)\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        return grid_search\n",
    "    else:\n",
    "        ## random subsampling grid search to avoid grader's TimeoutError\n",
    "        ## to select the first elem: [value[0]]\n",
    "        param_grid = {key: random.choice(value) for key, value in param_grid.items()}\n",
    "        return GridDict(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7923c33da469542ff6e642a304dce099",
     "grade": false,
     "grade_id": "cell-c1ae7e7278c56f0c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## build dataset\n",
    "df = build_salary_dataset(G)\n",
    "X, y = get_feature_and_label(df)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "## with random_state=0 same as splitting below\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train, y_train = X.loc[~y.isna(),:], y[~y.isna()]\n",
    "X_test, y_test = X.loc[y.isna(),:], y[y.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       0.082298\n",
       "2       0.900215\n",
       "5       0.990329\n",
       "8       0.062392\n",
       "14      0.095849\n",
       "          ...   \n",
       "992     0.000000\n",
       "994     0.001667\n",
       "996     0.000000\n",
       "1000    0.010440\n",
       "1001    0.026925\n",
       "Length: 252, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def salary_predictions(X_train, y_train, X_test, y_test):\n",
    "    ### scale dataset\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    ## gest best parameter\n",
    "    best_param = get_best_parameters(X, y, tune=True)\n",
    "    \n",
    "    ## train model\n",
    "    clf = RandomForestClassifier(max_depth=best_param.best_params_['rfc__max_depth'], \n",
    "                                 max_features=best_param.best_params_['rfc__max_features'], \n",
    "                                 min_samples_leaf=best_param.best_params_['rfc__min_samples_leaf'], \n",
    "                                 min_samples_split=best_param.best_params_['rfc__min_samples_split'], \n",
    "                                 n_estimators=best_param.best_params_['rfc__n_estimators'], \n",
    "                                 n_jobs=-1, random_state=0)\n",
    "\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    ## return proba\n",
    "    y_pred = clf.predict_proba(X_test_scaled)\n",
    "    probs = y_pred[:,1]\n",
    "    return pd.Series(probs, index=X_test.index)\n",
    "\n",
    "pred = salary_predictions(X_train, y_train, X_test, y_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged AUROC: 0.954\n",
      "Averaged AUPRC: 0.851\n",
      "Averaged Balanced Accuracy: 0.771\n"
     ]
    }
   ],
   "source": [
    "mask = ~y.isna()\n",
    "X_known, y_known = X[mask], y[mask]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rfc', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "metrics = ['roc_auc', 'average_precision', 'balanced_accuracy']\n",
    "perfname = ['AUROC', 'AUPRC', 'Balanced Accuracy']\n",
    "\n",
    "for perf, name in zip(metrics, perfname):\n",
    "  scores = cross_val_score(pipeline, X_known, y_known, cv=5, scoring=perf)\n",
    "  print(f\"Averaged {name}: {scores.mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01ee118d34018c23ed12b93790c65e49",
     "grade": false,
     "grade_id": "cell-636bdc6669fbdf2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## New Connections Prediction\n",
    "\n",
    "Here I aim at predicting future connections between employees of the network. The future connections information is loaded into the variable `future_connections`. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the `Future Connection` column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ae78d5616c6a6fba11b22d9bf5c9bac",
     "grade": false,
     "grade_id": "cell-23900b187593a4a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Future Connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(6, 840)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(4, 197)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(620, 979)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(519, 872)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(382, 423)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(165, 923)</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(673, 755)</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(939, 940)</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(555, 905)</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(75, 101)</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488446 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Future Connection\n",
       "(6, 840)                  0.0\n",
       "(4, 197)                  0.0\n",
       "(620, 979)                0.0\n",
       "(519, 872)                0.0\n",
       "(382, 423)                0.0\n",
       "...                       ...\n",
       "(165, 923)                NaN\n",
       "(673, 755)                NaN\n",
       "(939, 940)                NaN\n",
       "(555, 905)                NaN\n",
       "(75, 101)                 NaN\n",
       "\n",
       "[488446 rows x 1 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_connections = pd.read_csv('data/future_connections.csv', index_col=0, converters={0: eval})\n",
    "future_connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24c7b4c993f6a3300acc98b46d49f81b",
     "grade": false,
     "grade_id": "cell-2d5376bc66158f80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here I aim at predicting if people will have a future connections. To this end:\n",
    "\n",
    "1. I creat a matrix of features for the edges found in `future_connections` using Networkx     \n",
    "2. I train a sklearn classifier on those edges in `future_connections` that have `Future Connection` data     \n",
    "3. I predict a probability of the edge being a future connection for those edges in `future_connections` where `Future Connection` is missing.\n",
    "4. I evaluate the model with different metrics - AUROC, AUPRC and Balaced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build data\n",
    "def build_connection_dataset(future_connections, G):\n",
    "    df = future_connections.copy() ## create a deep copy of future_connections\n",
    "    df.rename(columns={'Future Connection': 'future_conn'}, inplace=True)\n",
    "    map_edges = lambda ed: dict({(x,y):z for x,y,z in ed})\n",
    "    df['common_neigh'] = map_edges([(e[0], e[1], len(list(nx.common_neighbors(G, e[0], e[1])))) for e in nx.non_edges(G)])\n",
    "    df['jaccard_coef'] = map_edges(nx.jaccard_coefficient(G))\n",
    "    df['alloc_index']  = map_edges(nx.resource_allocation_index(G))\n",
    "    df['adamic_adar']  = map_edges(nx.adamic_adar_index(G))\n",
    "    df['pref_attach']  = map_edges(nx.preferential_attachment(G))\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_feature_and_label(df, label='future_conn'):\n",
    "    X = df.drop(columns=[label]) ## df.iloc[:,1:]\n",
    "    y = df[label]                ## df.iloc[:,0]\n",
    "    return X,y\n",
    "\n",
    "df = build_connection_dataset(future_connections, G)\n",
    "X, y = get_feature_and_label(df, label='future_conn')\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "## with random_state=0 same as splitting below\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train, y_train = X.loc[~y.isna(),:], y[~y.isna()]\n",
    "X_test, y_test = X.loc[y.isna(),:], y[y.isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)          0.015451\n",
       "(0, 19)         0.052432\n",
       "(0, 20)         0.332290\n",
       "(0, 35)         0.006085\n",
       "(0, 38)         0.009872\n",
       "                  ...   \n",
       "(998, 999)      0.014456\n",
       "(1000, 1002)    0.011865\n",
       "(1000, 1003)    0.011865\n",
       "(1000, 1004)    0.011865\n",
       "(1001, 1002)    0.012798\n",
       "Length: 122112, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GridDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(GridDict, self).__init__(*args, **kwargs)\n",
    "        self.best_params_ = self\n",
    "\n",
    "def get_best_parameters(X_train, y_train, tune=True):\n",
    "    # Create the pipeline: in this way the scaling is included in each cv, making the model selection more robust\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), # Step 1: Scale the data \n",
    "                         ('rfc', RandomForestClassifier(random_state=0)) # Step 2: Train the model \n",
    "                        ])\n",
    "    ## grid search\n",
    "    param_grid = {\n",
    "        'rfc__n_estimators': [50, 100, 200],\n",
    "        'rfc__max_depth': [10, 20, 30],\n",
    "        'rfc__min_samples_split': [2, 5, 10],\n",
    "        'rfc__min_samples_leaf': [1, 2, 4],\n",
    "        'rfc__max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "    if tune:\n",
    "        rfc = RandomForestClassifier(random_state=0)\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        return grid_search\n",
    "    else:\n",
    "        ## random subsampling grid search to avoid grader's TimeoutError\n",
    "        ## to select the first elem: [value[0]]\n",
    "        param_grid = {key: random.choice(value) for key, value in param_grid.items()}\n",
    "        return GridDict(param_grid)\n",
    "    \n",
    "def new_connections_predictions(X_train, y_train, X_test, y_test, tune=False):\n",
    "    ### scale dataset\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    ## get best parameters\n",
    "    best_param = get_best_parameters(X, y, tune=tune)\n",
    "\n",
    "    ## train model\n",
    "    clf = RandomForestClassifier(max_depth=best_param.best_params_['rfc__max_depth'], \n",
    "                                    max_features=best_param.best_params_['rfc__max_features'], \n",
    "                                    min_samples_leaf=best_param.best_params_['rfc__min_samples_leaf'], \n",
    "                                    min_samples_split=best_param.best_params_['rfc__min_samples_split'], \n",
    "                                    n_estimators=best_param.best_params_['rfc__n_estimators'], \n",
    "                                    n_jobs=-1, random_state=0)\n",
    "\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    ## return proba\n",
    "    y_pred = clf.predict_proba(X_test_scaled)\n",
    "    probs = y_pred[:,1]\n",
    "    return pd.Series(probs, index=X_test.index)\n",
    "\n",
    "pred = new_connections_predictions(X_train, y_train, X_test, y_test, tune=False)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged AUROC: 0.888\n",
      "Averaged AUPRC: 0.736\n",
      "Averaged Balanced Accuracy: 0.786\n"
     ]
    }
   ],
   "source": [
    "mask = ~y.isna()\n",
    "X_known, y_known = X[mask], y[mask]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rfc', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "metrics = ['roc_auc', 'average_precision', 'balanced_accuracy']\n",
    "perfname = ['AUROC', 'AUPRC', 'Balanced Accuracy']\n",
    "\n",
    "for perf, name in zip(metrics, perfname):\n",
    "  scores = cross_val_score(pipeline, X_known, y_known, cv=5, scoring=perf)\n",
    "  print(f\"Averaged {name}: {scores.mean():.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
