[
  {
    "objectID": "weather-records.html",
    "href": "weather-records.html",
    "title": "Visualization of Michigan’s temperature records",
    "section": "",
    "text": "Plot line graphs of the min and max temperatures for the years 2005 through 2014 highlighting the daily 2015 temperatures that exceeded those values."
  },
  {
    "objectID": "weather-records.html#goal",
    "href": "weather-records.html#goal",
    "title": "Visualization of Michigan’s temperature records",
    "section": "",
    "text": "Plot line graphs of the min and max temperatures for the years 2005 through 2014 highlighting the daily 2015 temperatures that exceeded those values."
  },
  {
    "objectID": "weather-records.html#dataset",
    "href": "weather-records.html#dataset",
    "title": "Visualization of Michigan’s temperature records",
    "section": "Dataset",
    "text": "Dataset\nThe data comes from a subset of The National Centers for Environmental Information (NCEI) Global Historical Climatology Network daily (GHCNd) (GHCN-Daily), which includes daily climate records from thousands of land surface stations across the globe.\nHere I use data from the Ann Arbor Michigan location.\nEach row in this datafile corresponds to a single observation from a weather station, and has the following variables:\n\nid : station identification code\ndate : date in YYYY-MM-DD format (e.g. 2012-01-24 = January 24, 2012)\nelement : indicator of element type\n\nTMAX : Maximum temperature (tenths of degrees C)\nTMIN : Minimum temperature (tenths of degrees C)\n\nvalue : data value for element (tenths of degrees C)\n\n\n#  I'll be using the folium package to render the data into a map in Jupyter.\n\nimport folium\nimport pandas as pd\n\n# get the location information for this dataset\ndf = pd.read_csv('data/BinSize_d400.csv')\nstation_locations_by_hash = df[df['hash'] == 'fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89']\n\n# get longitude and lattitude to plot\nlons = station_locations_by_hash['LONGITUDE'].tolist()\nlats = station_locations_by_hash['LATITUDE'].tolist()\n\n# plot on a beautiful folium map\nmy_map = folium.Map(location = [lats[0], lons[0]], height = 500,  zoom_start = 9)\nfor lat, lon in zip(lats, lons):\n    folium.Marker([lat, lon]).add_to(my_map)\n\n# render map in Jupyter\ndisplay(my_map)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nStep 1\nLoad the dataset and transform the data into Celsius (refer to documentation) then extract all of the rows which have minimum or maximum temperatures.\n\nimport pandas as pd\ndf = pd.read_csv('data/temperatures.csv')\ndf.head()\n\n\n\n\n\n\n\n\nID\nDate\nElement\nData_Value\n\n\n\n\n0\nUSW00094889\n2014-11-12\nTMAX\n22\n\n\n1\nUSC00208972\n2009-04-29\nTMIN\n56\n\n\n2\nUSC00200032\n2008-05-26\nTMAX\n278\n\n\n3\nUSC00205563\n2005-11-11\nTMAX\n139\n\n\n4\nUSC00200230\n2014-02-27\nTMAX\n-106\n\n\n\n\n\n\n\n\n# In this code cell, transform the Data_Value column\ndf['Data_Value_Tenths'] = df['Data_Value'] / 10\n\n## drop leap day\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df[~((df['Date'].dt.month == 2) & (df['Date'].dt.day == 29))]\n\ndf_max = df[df['Element'] == 'TMAX']\ndf_min = df[df['Element'] == 'TMIN']\n\nprint(df.shape, df_min.shape, df_max.shape)\n\n(165002, 5) (81982, 5) (83020, 5)\n\n\n\n\nStep 2\nIn order to visualize the data we would plot the min and max data for each day of the year between the years 2005 and 2014 across all weather stations. But we also need to find out when the min or max temperature in 2015 falls below the min or rises above the max for the previous decade.\n\n# create a DataFrame of maximum temperature by date\nmax_temp_date = df_max.groupby('Date')['Data_Value_Tenths'].max().reset_index()\n\n# create a DataFrame of minimum temperatures by date\nmin_temp_date = df_min.groupby('Date')['Data_Value_Tenths'].min().reset_index()\n\nprint(max_temp_date.shape, min_temp_date.shape)\n\n(4015, 2) (4015, 2)\n\n\n\n\nStep 3\nNow that we have grouped the daily max and min temperatures for each day of the years 2005 through 2015, we can separate out the data for 2015.\n\nimport numpy as np\n\n# calculate the minimum and maximum values for the day of the year for 2005 through 2014\nmax_temp_0514 = max_temp_date[max_temp_date['Date'].dt.year &lt; 2015]\nmax_temp_0514 = max_temp_0514.groupby(max_temp_0514['Date'].dt.strftime('%m-%d')).agg({'Data_Value_Tenths': 'max'})\nmax_temp_0514.rename(columns={'Data_Value_Tenths': 'Max_Temp_0514'}, inplace=True)\n\nmin_temp_0514 = min_temp_date[min_temp_date['Date'].dt.year &lt; 2015]\nmin_temp_0514 = min_temp_0514.groupby(min_temp_0514['Date'].dt.strftime('%m-%d')).agg({'Data_Value_Tenths': 'min'})\nmin_temp_0514.rename(columns={'Data_Value_Tenths': 'Min_Temp_0514'}, inplace=True)\n\n# calculate the minimum and maximum values for the years 2015\nmax_temp_2015 = max_temp_date[max_temp_date['Date'].dt.year == 2015]\nmax_temp_2015 = max_temp_2015.groupby(max_temp_2015['Date'].dt.strftime('%m-%d')).agg({'Data_Value_Tenths': 'max'})\nmax_temp_2015.rename(columns={'Data_Value_Tenths': 'Max_Temp_2015'}, inplace=True)\n\nmin_temp_2015 = min_temp_date[min_temp_date['Date'].dt.year == 2015]\nmin_temp_2015 = min_temp_2015.groupby(min_temp_2015['Date'].dt.strftime('%m-%d')).agg({'Data_Value_Tenths': 'min'})\nmin_temp_2015.rename(columns={'Data_Value_Tenths': 'Min_Temp_2015'}, inplace=True)\n\n## join df and find broken records\ndf_temp = pd.merge(max_temp_0514, min_temp_0514, on='Date').merge(max_temp_2015, on='Date').merge(min_temp_2015, on='Date')\ndf_temp['Broke_Record_Max'] = df_temp['Max_Temp_2015'] &gt; df_temp['Max_Temp_0514']\ndf_temp['Broke_Record_Min'] = df_temp['Min_Temp_2015'] &lt; df_temp['Min_Temp_0514']\n\nprint(max_temp_0514.shape, min_temp_0514.shape, max_temp_2015.shape, min_temp_2015.shape, df_temp.shape)\n\n(365, 1) (365, 1) (365, 1) (365, 1) (365, 6)\n\n\n\n\nStep 4\nNow it’s time to plot!\n\nimport matplotlib.pyplot as plt\nfrom calendar import month_abbr\n\n# put your plotting code here!\nfig, ax = plt.subplots(figsize=(12, 6))\n\nplt.plot(df_temp['Max_Temp_0514'].values, label='Max Temp (2005-2014)', linewidth=1, alpha = 0.7, c='firebrick')\nplt.plot(df_temp['Min_Temp_0514'].values, label='Min Temp (2005-2014)', linewidth=1, alpha = 0.7, c='royalblue')\n\nplt.fill_between(range(df_temp.shape[0]), df_temp['Max_Temp_0514'], df_temp['Min_Temp_0514'], facecolor='gray', alpha=0.3)\n\nplt.scatter(np.where(df_temp['Broke_Record_Max'] == True), \n            df_temp[df_temp['Broke_Record_Max'] == True]['Max_Temp_2015'].values,\n            s=15, color='red', label='High Temp Broken (2015)', marker='^')\nplt.scatter(np.where(df_temp['Broke_Record_Min'] == True), \n            df_temp[df_temp['Broke_Record_Min'] == True]['Min_Temp_2015'].values,\n            s=15, color='indigo', label='Low Temp Broken (2015)', marker='v')\n\nplt.legend(loc = 'upper right', fontsize=8)\n\nplt.xticks(np.linspace(0, 365, num = 12), list(month_abbr)[1:], size=10)\nplt.yticks(size=10)\nplt.xlabel('Months', size = 12)\nplt.ylabel('Temperature (Celsius)', size = 12)\nplt.title('Temperature Patterns', size = 14)\n\nax.spines[['right', 'top']].set_visible(False)\n# ax.spines[['bottom', 'left']].set_alpha(0.3)\n# ax.tick_params(axis='x', color='gray')\n# ax.tick_params(axis='y', color='gray')\n\n# plt.savefig('temperature_plot.png')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAll in one\n\nimport pandas as pd\nimport numpy as np\nfrom calendar import month_abbr\n\n## load data\ndf = pd.read_csv('data/temperatures.csv')\n\n## isolate year,month,day\ndf['Date'] = pd.to_datetime(df['Date'])\ndf['Year'] = df['Date'].dt.year\ndf['Month'] = df['Date'].dt.strftime('%b') ## month short form\ndf['Day'] = df['Date'].dt.day\n\n## sort month alphabethically\nmonth_order = list(month_abbr)[1:]\ndf['Month'] = pd.Categorical(df['Month'], categories=month_order, ordered=True)\n\n## drop leap day\ndf = df[~((df['Month'] == 'Feb') & (df['Day'] == 29))]\n\n## transform temp\ndf['Data_Value'] = df['Data_Value'] / 10\n\n## group temps\nmax_temp_0514 = df[(df['Element'] == 'TMAX') & (df['Year'] &lt; 2015)].groupby(['Month','Day'], observed=True).agg({'Data_Value': 'max'})\nmin_temp_0514 = df[(df['Element'] == 'TMIN') & (df['Year'] &lt; 2015)].groupby(['Month','Day'], observed=True).agg({'Data_Value': 'min'})\nmax_temp_2015 = df[(df['Element'] == 'TMAX') & (df['Year'] == 2015)].groupby(['Month','Day'], observed=True).agg({'Data_Value': 'max'})\nmin_temp_2015 = df[(df['Element'] == 'TMIN') & (df['Year'] == 2015)].groupby(['Month','Day'], observed=True).agg({'Data_Value': 'min'})\n\n## rename\nmax_temp_0514.rename(columns={'Data_Value': 'Max_Temp_0514'}, inplace=True)\nmin_temp_0514.rename(columns={'Data_Value': 'Min_Temp_0514'}, inplace=True)\nmax_temp_2015.rename(columns={'Data_Value': 'Max_Temp_2015'}, inplace=True)\nmin_temp_2015.rename(columns={'Data_Value': 'Min_Temp_2015'}, inplace=True)\n\n## join df and find broken records\ndf_temp = pd.merge(max_temp_0514, min_temp_0514, on=['Month', 'Day'])\\\n            .merge(max_temp_2015, on=['Month', 'Day'])\\\n            .merge(min_temp_2015, on=['Month', 'Day'])\ndf_temp['Broke_Record_Max'] = df_temp['Max_Temp_2015'] &gt; df_temp['Max_Temp_0514']\ndf_temp['Broke_Record_Min'] = df_temp['Min_Temp_2015'] &lt; df_temp['Min_Temp_0514']\n\n## drop 29/30/31 in Feb because of merge\ndf_temp.dropna(inplace=True)\n\n# plotting \nfig, ax = plt.subplots(figsize=(12, 6))\n\nplt.plot(df_temp['Max_Temp_0514'].values, label='Max Temp (2005-2014)', linewidth=1, alpha = 0.7, c='firebrick')\nplt.plot(df_temp['Min_Temp_0514'].values, label='Min Temp (2005-2014)', linewidth=1, alpha = 0.7, c='royalblue')\n\nplt.fill_between(range(df_temp.shape[0]), df_temp['Max_Temp_0514'], df_temp['Min_Temp_0514'], facecolor='gray', alpha=0.3)\n\nplt.scatter(np.where(df_temp['Broke_Record_Max'] == True), \n            df_temp[df_temp['Broke_Record_Max'] == True]['Max_Temp_2015'].values,\n            s=15, color='red', label='High Temp Broken (2015)', marker='^')\nplt.scatter(np.where(df_temp['Broke_Record_Min'] == True), \n            df_temp[df_temp['Broke_Record_Min'] == True]['Min_Temp_2015'].values,\n            s=15, color='indigo', label='Low Temp Broken (2015)', marker='v')\n\nplt.legend(loc = 'best', fontsize=10)\n\nplt.xticks(np.linspace(0, 365, num = 12), list(month_abbr)[1:], size=10)\nplt.yticks(size=10)\nplt.xlabel('Months', size = 12)\nplt.ylabel('Temperature (Celsius)', size = 12)\nplt.title('Temperature Patterns', size = 14)\n\nax.spines[['right', 'top']].set_visible(False)\n# ax.spines[['bottom', 'left']].set_alpha(0.3)\n# ax.tick_params(axis='x', color='gray')\n# ax.tick_params(axis='y', color='gray')\n\nplt.show()"
  },
  {
    "objectID": "predict-housing-prices.html",
    "href": "predict-housing-prices.html",
    "title": "Predicting California housing prices",
    "section": "",
    "text": "The goal of this report is to predict housing prices in California from property features. To this end, we use the california-housing-dataset from scikit-learn.\n\nfrom sklearn.datasets import fetch_california_housing\n\ncalifornia = fetch_california_housing(as_frame=True)\nprint(california.DESCR)\n\n.. _california_housing_dataset:\n\nCalifornia Housing dataset\n--------------------------\n\n**Data Set Characteristics:**\n\n:Number of Instances: 20640\n\n:Number of Attributes: 8 numeric, predictive attributes and the target\n\n:Attribute Information:\n    - MedInc        median income in block group\n    - HouseAge      median house age in block group\n    - AveRooms      average number of rooms per household\n    - AveBedrms     average number of bedrooms per household\n    - Population    block group population\n    - AveOccup      average number of household members\n    - Latitude      block group latitude\n    - Longitude     block group longitude\n\n:Missing Attribute Values: None\n\nThis dataset was obtained from the StatLib repository.\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n\nThe target variable is the median house value for California districts,\nexpressed in hundreds of thousands of dollars ($100,000).\n\nThis dataset was derived from the 1990 U.S. census, using one row per census\nblock group. A block group is the smallest geographical unit for which the U.S.\nCensus Bureau publishes sample data (a block group typically has a population\nof 600 to 3,000 people).\n\nA household is a group of people residing within a home. Since the average\nnumber of rooms and bedrooms in this dataset are provided per household, these\ncolumns may take surprisingly large values for block groups with few households\nand many empty houses, such as vacation resorts.\n\nIt can be downloaded/loaded using the\n:func:`sklearn.datasets.fetch_california_housing` function.\n\n.. rubric:: References\n\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n  Statistics and Probability Letters, 33 (1997) 291-297\n\n\n\n\nfrom IPython.display import display\nimport pandas as pd\n\ndf = california.frame\nseparator = pd.DataFrame([['...'] * len(df.columns)], columns=df.columns, index=['...'])\ndisplay(pd.concat([df.head(), separator, df.tail()]))\n# df.head()\n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\nMedHouseVal\n\n\n\n\n0\n8.3252\n41.0\n6.984127\n1.02381\n322.0\n2.555556\n37.88\n-122.23\n4.526\n\n\n1\n8.3014\n21.0\n6.238137\n0.97188\n2401.0\n2.109842\n37.86\n-122.22\n3.585\n\n\n2\n7.2574\n52.0\n8.288136\n1.073446\n496.0\n2.80226\n37.85\n-122.24\n3.521\n\n\n3\n5.6431\n52.0\n5.817352\n1.073059\n558.0\n2.547945\n37.85\n-122.25\n3.413\n\n\n4\n3.8462\n52.0\n6.281853\n1.081081\n565.0\n2.181467\n37.85\n-122.25\n3.422\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n1.5603\n25.0\n5.045455\n1.133333\n845.0\n2.560606\n39.48\n-121.09\n0.781\n\n\n20636\n2.5568\n18.0\n6.114035\n1.315789\n356.0\n3.122807\n39.49\n-121.21\n0.771\n\n\n20637\n1.7\n17.0\n5.205543\n1.120092\n1007.0\n2.325635\n39.43\n-121.22\n0.923\n\n\n20638\n1.8672\n18.0\n5.329513\n1.17192\n741.0\n2.123209\n39.43\n-121.32\n0.847\n\n\n20639\n2.3886\n16.0\n5.254717\n1.162264\n1387.0\n2.616981\n39.37\n-121.24\n0.894"
  },
  {
    "objectID": "predict-housing-prices.html#aim",
    "href": "predict-housing-prices.html#aim",
    "title": "Predicting California housing prices",
    "section": "",
    "text": "The goal of this report is to predict housing prices in California from property features. To this end, we use the california-housing-dataset from scikit-learn.\n\nfrom sklearn.datasets import fetch_california_housing\n\ncalifornia = fetch_california_housing(as_frame=True)\nprint(california.DESCR)\n\n.. _california_housing_dataset:\n\nCalifornia Housing dataset\n--------------------------\n\n**Data Set Characteristics:**\n\n:Number of Instances: 20640\n\n:Number of Attributes: 8 numeric, predictive attributes and the target\n\n:Attribute Information:\n    - MedInc        median income in block group\n    - HouseAge      median house age in block group\n    - AveRooms      average number of rooms per household\n    - AveBedrms     average number of bedrooms per household\n    - Population    block group population\n    - AveOccup      average number of household members\n    - Latitude      block group latitude\n    - Longitude     block group longitude\n\n:Missing Attribute Values: None\n\nThis dataset was obtained from the StatLib repository.\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n\nThe target variable is the median house value for California districts,\nexpressed in hundreds of thousands of dollars ($100,000).\n\nThis dataset was derived from the 1990 U.S. census, using one row per census\nblock group. A block group is the smallest geographical unit for which the U.S.\nCensus Bureau publishes sample data (a block group typically has a population\nof 600 to 3,000 people).\n\nA household is a group of people residing within a home. Since the average\nnumber of rooms and bedrooms in this dataset are provided per household, these\ncolumns may take surprisingly large values for block groups with few households\nand many empty houses, such as vacation resorts.\n\nIt can be downloaded/loaded using the\n:func:`sklearn.datasets.fetch_california_housing` function.\n\n.. rubric:: References\n\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n  Statistics and Probability Letters, 33 (1997) 291-297\n\n\n\n\nfrom IPython.display import display\nimport pandas as pd\n\ndf = california.frame\nseparator = pd.DataFrame([['...'] * len(df.columns)], columns=df.columns, index=['...'])\ndisplay(pd.concat([df.head(), separator, df.tail()]))\n# df.head()\n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\nMedHouseVal\n\n\n\n\n0\n8.3252\n41.0\n6.984127\n1.02381\n322.0\n2.555556\n37.88\n-122.23\n4.526\n\n\n1\n8.3014\n21.0\n6.238137\n0.97188\n2401.0\n2.109842\n37.86\n-122.22\n3.585\n\n\n2\n7.2574\n52.0\n8.288136\n1.073446\n496.0\n2.80226\n37.85\n-122.24\n3.521\n\n\n3\n5.6431\n52.0\n5.817352\n1.073059\n558.0\n2.547945\n37.85\n-122.25\n3.413\n\n\n4\n3.8462\n52.0\n6.281853\n1.081081\n565.0\n2.181467\n37.85\n-122.25\n3.422\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20635\n1.5603\n25.0\n5.045455\n1.133333\n845.0\n2.560606\n39.48\n-121.09\n0.781\n\n\n20636\n2.5568\n18.0\n6.114035\n1.315789\n356.0\n3.122807\n39.49\n-121.21\n0.771\n\n\n20637\n1.7\n17.0\n5.205543\n1.120092\n1007.0\n2.325635\n39.43\n-121.22\n0.923\n\n\n20638\n1.8672\n18.0\n5.329513\n1.17192\n741.0\n2.123209\n39.43\n-121.32\n0.847\n\n\n20639\n2.3886\n16.0\n5.254717\n1.162264\n1387.0\n2.616981\n39.37\n-121.24\n0.894"
  },
  {
    "objectID": "predict-housing-prices.html#data-exploration",
    "href": "predict-housing-prices.html#data-exploration",
    "title": "Predicting California housing prices",
    "section": "Data exploration",
    "text": "Data exploration\nBelow, we show the geographic distribution of house prices in California. In the scatter plot, each point represents a location colored and sized by its median house price.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(\n  data=df,\n  x='Longitude',\n  y='Latitude',\n  hue='MedHouseVal',\n  size='MedHouseVal',\n  palette='coolwarm',\n  alpha=0.5,\n)\n\nplt.legend(title='MedHouseVal', loc='best')\nplt.title('California Housing Prices')\nplt.show()\n\n\n\n\n\n\n\n\nTo visualize geographic trends in California housing price (e.g. higher prices near coastal areas and urban centers, and lower prices inland), we overlay prices with the California map.\n\nimport contextily as ctx\n\nplt.figure(figsize=(10, 8))\nax = plt.gca()\n\nsns.scatterplot(\n  data=df,\n  x='Longitude',\n  y='Latitude',\n  hue='MedHouseVal',\n  size='MedHouseVal',\n  palette='coolwarm',\n  alpha=0.8,\n  ax=ax\n)\n\n## other providers\n# ctx.providers.OpenStreetMap.Mapnik\n# ctx.providers.CartoDB.Positron\n# ctx.providers.CartoDB.Voyager\n# ctx.providers.Esri.WorldImagery\nctx.add_basemap(ax, crs='EPSG:4326', source=ctx.providers.CartoDB.Voyager)\n\nax.set_xlabel('Longitude')\nax.set_ylabel('Latitude')\nax.set_title('California House Prices')\nplt.legend(title='MedHouseVal', loc='best')\n# plt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFinally, we display results via an interactive map. The heatmap highlights areas with higher median house values, while clusters show the geographic distribution of all properties. In the heatmap, higher prices appear as warmer colors (yellow/red), lower prices as cooler colors (blue/purple) and intermediate prices as green.\n\nimport folium\nfrom folium.plugins import HeatMap,FastMarkerCluster\n\n# center map on California\nm = folium.Map(location=[36.7783, -119.4179], zoom_start=6)\n\n# coordinates\nlocations = df[['Latitude', 'Longitude']].values.tolist()\n\n# prepare data for heatmap: [lat, lon, weight]\nheat_data = [\n  [row['Latitude'], row['Longitude'], row['MedHouseVal']]\n  for _, row in df.iterrows()\n]\n\n# add heatmap layer\nHeatMap(heat_data,\n        radius=5,\n        blur=5\n).add_to(m)\n\n# add cluster layer \nFastMarkerCluster(locations).add_to(m)\n\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nSplitting data\nWe partition data in training (80% of the data) to fit the model and in test set (20% of the data) to evaluate the model.\n\nfrom sklearn.model_selection import train_test_split\n\nX = california.data\ny = california.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
  },
  {
    "objectID": "predict-housing-prices.html#predict-housing-prices",
    "href": "predict-housing-prices.html#predict-housing-prices",
    "title": "Predicting California housing prices",
    "section": "Predict housing prices",
    "text": "Predict housing prices\n\nFeature selection\nWe use mutual information to select the most relevant features for predicting house prices.\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_regression\n\nselector = SelectKBest(mutual_info_regression, k=3)\nselector.fit(X_train, y_train)\n\nfeature_index = selector.get_support(indices=True)\nall_features = X_train.columns\nselected_feature = all_features[feature_index]\n\nfeature_importance = pd.DataFrame({\n  'Feature': all_features,\n  'Score': selector.scores_,\n  'Selected': selector.get_support()\n}).sort_values('Score', ascending=False)\n# display(feature_importance)\n\nplt.figure(figsize=(10, 6))\ncolors = ['tab:blue' if selected else 'tab:orange' for selected in feature_importance['Selected']]\nplt.barh(feature_importance['Feature'], feature_importance['Score'], color=colors)\nplt.xlabel('Feature Score')\nplt.gca().invert_yaxis()\n\n\n\n\n\n\n\n\n\n\nLinear regression\nTo predict California housing prices, we train a simple linear regression model using the three most informative features identified through mutual information: median income, latitude, and longitude. This approach captures linear relationships between geographic location, income levels and housing prices. Model performance is evaluated using cross-validation and validated on a held-out test set (unseen data) to assess its generalization capability.\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\n\nmodel_pipeline = Pipeline(steps=[\n  ('feature_selection', SelectKBest(mutual_info_regression, k=3)),\n  ('regressor', LinearRegression())\n])\n\ncv_scores = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\nprint(f\"Cross-validation accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n\nmodel_pipeline.fit(X_train, y_train)\ny_pred = model_pipeline.predict(X_test)\n\npd.DataFrame({\n  \"actual price\": y_test,\n  \"predicted price\": y_pred,\n})\n\nCross-validation accuracy: -0.742 (+/- 0.024)\n\n\n\n\n\n\n\n\n\nactual price\npredicted price\n\n\n\n\n14740\n1.369\n2.392515\n\n\n10101\n2.413\n2.804025\n\n\n20566\n2.007\n1.920376\n\n\n2670\n0.725\n0.746945\n\n\n15709\n4.600\n2.869450\n\n\n...\n...\n...\n\n\n6655\n1.695\n1.552282\n\n\n3505\n2.046\n2.369003\n\n\n1919\n1.286\n0.939938\n\n\n1450\n2.595\n2.968927\n\n\n4148\n1.676\n1.919953\n\n\n\n\n4128 rows × 2 columns\n\n\n\n\n\nModel performance\nOn average, the model predictions are about $75,000 away from the actual house price (RMSE: $75,163). Since the median price is $179,700, the error is quite high (relative error is about 42%).\nThe average absolute error (MAE) is about $55,000. This means that half of the predictions are off by less than $55,000, and half by more. MAE is less affected by large outliers than RMSE, providing a more robust measure of typical prediction error.\nThe model explains about 57% of the variance in house prices (\\(R^2\\): 0.567). This is a moderate fit: the model captures more than half of the price variation, but there is still substantial unexplained variance.\n\nfrom sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n\nrmse = root_mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"Model Performance Metrics:\")\nprint(f\"RMSE: ${rmse*100000:.2f}\")  # Multiply by 100000 since prices are in this scale\nprint(f\"MAE: ${mae*100000:.2f}\")\nprint(f\"R²: {r2:.3f}\")\n\nModel Performance Metrics:\nRMSE: $75163.22\nMAE: $55266.91\nR²: 0.567"
  },
  {
    "objectID": "predict-housing-prices.html#conclusions-and-next-step",
    "href": "predict-housing-prices.html#conclusions-and-next-step",
    "title": "Predicting California housing prices",
    "section": "Conclusions and next step",
    "text": "Conclusions and next step\nWhile this linear model has moderate explanatory power, its prediction error is quite large compared to affordable house prices (for example, the 10th percentile price is $82,300). To improve performance, gradient boosting algorithms (such as XGBoost or LightGBM) could be used instead to capture complex and nonlinear relationships between features. Additionally, hyperparameter tuning using Bayesian methods - such as hyperopt - could further enhance model performance."
  },
  {
    "objectID": "ml-graph.html",
    "href": "ml-graph.html",
    "title": "Predicting salary and new connections from network data",
    "section": "",
    "text": "Note\n\n\n\nNote: data from the Coursera course Applied Social Network Analysis in Python\nimport networkx as nx\nimport pandas as pd\nimport numpy as np\nimport pickle\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nimport random"
  },
  {
    "objectID": "ml-graph.html#company-emails",
    "href": "ml-graph.html#company-emails",
    "title": "Predicting salary and new connections from network data",
    "section": "Company Emails",
    "text": "Company Emails\nHere I analzye a company’s email network where a node corresponds to a person and an edge indicates that at least one email has been sent between two people. The network also contains the node attributes Department and ManagmentSalary. Department indicates the department in the company which the person belongs to, and ManagmentSalary indicates whether that person is receiving a managment position salary.\n\nG = pickle.load(open('data/email_prediction.plk', 'rb'))\n\nprint(f\"Graph with {len(nx.nodes(G))} nodes and {len(nx.edges(G))} edges\")\n\nGraph with 1005 nodes and 16706 edges"
  },
  {
    "objectID": "ml-graph.html#salary-prediction",
    "href": "ml-graph.html#salary-prediction",
    "title": "Predicting salary and new connections from network data",
    "section": "Salary Prediction",
    "text": "Salary Prediction\nHere I aim at predicting if people whithout a ManagementSalary will receive a managment position salary. To this end, I train a classifier on people that have ManagementSalary and then I predict the probability of receiving a managment salary for those people where ManagementSalary is missing. Models are evaluated with different performance metrics, Area Under the ROC Curve (AUCROC), Area under the Precision Recall Curve (AUPRC) and Balanced Accuracy.\n\nlist(G.nodes(data=True))[:5] # print the first 5 nodes\n\n[(0, {'Department': 1, 'ManagementSalary': 0.0}),\n (1, {'Department': 1, 'ManagementSalary': nan}),\n (581, {'Department': 3, 'ManagementSalary': 0.0}),\n (6, {'Department': 25, 'ManagementSalary': 1.0}),\n (65, {'Department': 4, 'ManagementSalary': nan})]\n\n\n\ndef build_salary_dataset(G):\n    df = pd.DataFrame()\n    df['management_salary'] = nx.get_node_attributes(G, 'ManagementSalary')\n    df['department'] = nx.get_node_attributes(G, 'Department')\n    df['clustering'] = nx.clustering(G)\n    df['betweenness'] = nx.betweenness_centrality(G)\n    df['closenness'] = nx.closeness_centrality(G)\n    df['pagerank'] = nx.pagerank(G)\n    df['hubs'], df['auth'] = nx.hits(G)\n    df.sort_index(inplace=True)\n    return df\n\ndef get_feature_and_label(df, label='management_salary'):\n    X = df.drop(columns=[label]) ## df.iloc[:,1:]\n    y = df[label]                ## df.iloc[:,0]\n    return X,y\n\nclass GridDict(dict):\n    def __init__(self, *args, **kwargs):\n        super(GridDict, self).__init__(*args, **kwargs)\n        self.best_params_ = self\n\ndef get_best_parameters(X, y, tune=True):\n    # from sklearn.model_selection import train_test_split\n    ## with random_state=0 same as splitting below\n    # X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    X_train, y_train = X.loc[~y.isna(),:], y[~y.isna()]\n    X_test, y_test = X.loc[y.isna(),:], y[y.isna()]\n\n    # Create the pipeline: in this way the scaling is included in each cv, making the model selection more robust\n    pipeline = Pipeline([('scaler', StandardScaler()), # Step 1: Scale the data \n                         ('rfc', RandomForestClassifier(random_state=0)) # Step 2: Train the model \n                        ])\n    ## grid search\n    param_grid = {\n        'rfc__n_estimators': [50, 100, 200],\n        'rfc__max_depth': [10, 20, 30],\n        'rfc__min_samples_split': [2, 5, 10],\n        'rfc__min_samples_leaf': [1, 2, 4],\n        'rfc__max_features': ['sqrt', 'log2']\n    }\n\n    if tune:\n        rfc = RandomForestClassifier(random_state=0)\n        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n        grid_search.fit(X_train, y_train)\n        return grid_search\n    else:\n        ## random subsampling grid search to avoid grader's TimeoutError\n        ## to select the first elem: [value[0]]\n        param_grid = {key: random.choice(value) for key, value in param_grid.items()}\n        return GridDict(param_grid)\n\n\n## build dataset\ndf = build_salary_dataset(G)\nX, y = get_feature_and_label(df)\n\n# from sklearn.model_selection import train_test_split\n## with random_state=0 same as splitting below\n# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\nX_train, y_train = X.loc[~y.isna(),:], y[~y.isna()]\nX_test, y_test = X.loc[y.isna(),:], y[y.isna()]\n\n\ndef salary_predictions(X_train, y_train, X_test, y_test):\n    ### scale dataset\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    ## gest best parameter\n    best_param = get_best_parameters(X, y, tune=True)\n    \n    ## train model\n    clf = RandomForestClassifier(max_depth=best_param.best_params_['rfc__max_depth'], \n                                 max_features=best_param.best_params_['rfc__max_features'], \n                                 min_samples_leaf=best_param.best_params_['rfc__min_samples_leaf'], \n                                 min_samples_split=best_param.best_params_['rfc__min_samples_split'], \n                                 n_estimators=best_param.best_params_['rfc__n_estimators'], \n                                 n_jobs=-1, random_state=0)\n\n    clf.fit(X_train_scaled, y_train)\n    \n    ## return proba\n    y_pred = clf.predict_proba(X_test_scaled)\n    probs = y_pred[:,1]\n    return pd.Series(probs, index=X_test.index)\n\npred = salary_predictions(X_train, y_train, X_test, y_test)\npred\n\n1       0.082298\n2       0.900215\n5       0.990329\n8       0.062392\n14      0.095849\n          ...   \n992     0.000000\n994     0.001667\n996     0.000000\n1000    0.010440\n1001    0.026925\nLength: 252, dtype: float64\n\n\n\nPerformance evaluation\n\nmask = ~y.isna()\nX_known, y_known = X[mask], y[mask]\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('rfc', RandomForestClassifier(random_state=0))\n])\n\nmetrics = ['roc_auc', 'average_precision', 'balanced_accuracy']\nperfname = ['AUROC', 'AUPRC', 'Balanced Accuracy']\n\nfor perf, name in zip(metrics, perfname):\n  scores = cross_val_score(pipeline, X_known, y_known, cv=5, scoring=perf)\n  print(f\"Averaged {name}: {scores.mean():.3f}\")\n\nAveraged AUROC: 0.954\nAveraged AUPRC: 0.851\nAveraged Balanced Accuracy: 0.771"
  },
  {
    "objectID": "ml-graph.html#new-connections-prediction",
    "href": "ml-graph.html#new-connections-prediction",
    "title": "Predicting salary and new connections from network data",
    "section": "New Connections Prediction",
    "text": "New Connections Prediction\nHere I aim at predicting future connections between employees of the network. The future connections information is loaded into the variable future_connections. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the Future Connection column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection.\n\nfuture_connections = pd.read_csv('data/future_connections.csv', index_col=0, converters={0: eval})\nfuture_connections\n\n\n\n\n\n\n\n\nFuture Connection\n\n\n\n\n(6, 840)\n0.0\n\n\n(4, 197)\n0.0\n\n\n(620, 979)\n0.0\n\n\n(519, 872)\n0.0\n\n\n(382, 423)\n0.0\n\n\n...\n...\n\n\n(165, 923)\nNaN\n\n\n(673, 755)\nNaN\n\n\n(939, 940)\nNaN\n\n\n(555, 905)\nNaN\n\n\n(75, 101)\nNaN\n\n\n\n\n488446 rows × 1 columns\n\n\n\nHere I aim at predicting if people will have a future connections. To this end:\n\nI creat a matrix of features for the edges found in future_connections using Networkx\n\nI train a sklearn classifier on those edges in future_connections that have Future Connection data\n\nI predict a probability of the edge being a future connection for those edges in future_connections where Future Connection is missing.\nI evaluate the model with different metrics - AUROC, AUPRC and Balaced Accuracy\n\n\n## build data\ndef build_connection_dataset(future_connections, G):\n    df = future_connections.copy() ## create a deep copy of future_connections\n    df.rename(columns={'Future Connection': 'future_conn'}, inplace=True)\n    map_edges = lambda ed: dict({(x,y):z for x,y,z in ed})\n    df['common_neigh'] = map_edges([(e[0], e[1], len(list(nx.common_neighbors(G, e[0], e[1])))) for e in nx.non_edges(G)])\n    df['jaccard_coef'] = map_edges(nx.jaccard_coefficient(G))\n    df['alloc_index']  = map_edges(nx.resource_allocation_index(G))\n    df['adamic_adar']  = map_edges(nx.adamic_adar_index(G))\n    df['pref_attach']  = map_edges(nx.preferential_attachment(G))\n    df.sort_index(inplace=True)\n    return df\n\ndef get_feature_and_label(df, label='future_conn'):\n    X = df.drop(columns=[label]) ## df.iloc[:,1:]\n    y = df[label]                ## df.iloc[:,0]\n    return X,y\n\ndf = build_connection_dataset(future_connections, G)\nX, y = get_feature_and_label(df, label='future_conn')\n\n# from sklearn.model_selection import train_test_split\n## with random_state=0 same as splitting below\n# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\nX_train, y_train = X.loc[~y.isna(),:], y[~y.isna()]\nX_test, y_test = X.loc[y.isna(),:], y[y.isna()]\n\n\nclass GridDict(dict):\n    def __init__(self, *args, **kwargs):\n        super(GridDict, self).__init__(*args, **kwargs)\n        self.best_params_ = self\n\ndef get_best_parameters(X_train, y_train, tune=True):\n    # Create the pipeline: in this way the scaling is included in each cv, making the model selection more robust\n    pipeline = Pipeline([('scaler', StandardScaler()), # Step 1: Scale the data \n                         ('rfc', RandomForestClassifier(random_state=0)) # Step 2: Train the model \n                        ])\n    ## grid search\n    param_grid = {\n        'rfc__n_estimators': [50, 100, 200],\n        'rfc__max_depth': [10, 20, 30],\n        'rfc__min_samples_split': [2, 5, 10],\n        'rfc__min_samples_leaf': [1, 2, 4],\n        'rfc__max_features': ['sqrt', 'log2']\n    }\n    \n    if tune:\n        rfc = RandomForestClassifier(random_state=0)\n        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n        grid_search.fit(X_train, y_train)\n        return grid_search\n    else:\n        ## random subsampling grid search to avoid grader's TimeoutError\n        ## to select the first elem: [value[0]]\n        param_grid = {key: random.choice(value) for key, value in param_grid.items()}\n        return GridDict(param_grid)\n    \ndef new_connections_predictions(X_train, y_train, X_test, y_test, tune=False):\n    ### scale dataset\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n\n    ## get best parameters\n    best_param = get_best_parameters(X, y, tune=tune)\n\n    ## train model\n    clf = RandomForestClassifier(max_depth=best_param.best_params_['rfc__max_depth'], \n                                    max_features=best_param.best_params_['rfc__max_features'], \n                                    min_samples_leaf=best_param.best_params_['rfc__min_samples_leaf'], \n                                    min_samples_split=best_param.best_params_['rfc__min_samples_split'], \n                                    n_estimators=best_param.best_params_['rfc__n_estimators'], \n                                    n_jobs=-1, random_state=0)\n\n    clf.fit(X_train_scaled, y_train)\n\n    ## return proba\n    y_pred = clf.predict_proba(X_test_scaled)\n    probs = y_pred[:,1]\n    return pd.Series(probs, index=X_test.index)\n\npred = new_connections_predictions(X_train, y_train, X_test, y_test, tune=False)\npred\n\n(0, 9)          0.015451\n(0, 19)         0.052432\n(0, 20)         0.332290\n(0, 35)         0.006085\n(0, 38)         0.009872\n                  ...   \n(998, 999)      0.014456\n(1000, 1002)    0.011865\n(1000, 1003)    0.011865\n(1000, 1004)    0.011865\n(1001, 1002)    0.012798\nLength: 122112, dtype: float64\n\n\n\nPerformance evaluation\n\nmask = ~y.isna()\nX_known, y_known = X[mask], y[mask]\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('rfc', RandomForestClassifier(random_state=0))\n])\n\nmetrics = ['roc_auc', 'average_precision', 'balanced_accuracy']\nperfname = ['AUROC', 'AUPRC', 'Balanced Accuracy']\n\nfor perf, name in zip(metrics, perfname):\n  scores = cross_val_score(pipeline, X_known, y_known, cv=5, scoring=perf)\n  print(f\"Averaged {name}: {scores.mean():.3f}\")\n\nAveraged AUROC: 0.888\nAveraged AUPRC: 0.736\nAveraged Balanced Accuracy: 0.786"
  },
  {
    "objectID": "cnn_vs_fnn.html",
    "href": "cnn_vs_fnn.html",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "",
    "text": "Note\n\n\n\nData from the SIB course Diving into deep learning - theory and applications with PyTorch."
  },
  {
    "objectID": "cnn_vs_fnn.html#goal",
    "href": "cnn_vs_fnn.html#goal",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Goal",
    "text": "Goal\n\nImplementing a convolutional neural network (CNN) to predict protein subcellular localization relying on sequence information\nComparing the CNN with the feedforward neural network (FNN)\nExpected output: CNN should provide a performance improvement over FNN"
  },
  {
    "objectID": "cnn_vs_fnn.html#dataset-information",
    "href": "cnn_vs_fnn.html#dataset-information",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Dataset information",
    "text": "Dataset information\n\nThe dataset is from https://academic.oup.com/bioinformatics/article/33/21/3387/3931857\nEach sequence is encoded as a matrix where each position is a row of size 20, for each possible amino acid\nThe values within the matrix represent the amino acid frequency at the given position"
  },
  {
    "objectID": "cnn_vs_fnn.html#loading-libraries",
    "href": "cnn_vs_fnn.html#loading-libraries",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Loading libraries",
    "text": "Loading libraries\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report\n\nimport torch\nfrom torch import nn\nimport pytorch_model_summary as pms \nfrom torch.utils.data import TensorDataset, DataLoader\n\nfrom pytorchtools import EarlyStopping\n\nimport time \n\n# get cpu, gpu or mps device for training\ndevice = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")\n\nUsing cpu device"
  },
  {
    "objectID": "cnn_vs_fnn.html#loading-the-protein-sequences-and-labels",
    "href": "cnn_vs_fnn.html#loading-the-protein-sequences-and-labels",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Loading the protein sequences and labels",
    "text": "Loading the protein sequences and labels\n\n## training data\ntrain = np.load('data/reduced_train.npz')\nX_train = train['X_train']\ny_train = train['y_train']\nprint('train:', X_train.shape)\n\n## validation data\nvalidation = np.load('data/reduced_val.npz')\nX_valid = validation['X_val']\ny_valid = validation['y_val']\nprint('valid:', X_valid.shape)\n\ntrain: (2423, 400, 20)\nvalid: (635, 400, 20)"
  },
  {
    "objectID": "cnn_vs_fnn.html#defining-the-subcellular-localization",
    "href": "cnn_vs_fnn.html#defining-the-subcellular-localization",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Defining the subcellular localization",
    "text": "Defining the subcellular localization\n\nclasses = ['Nucleus',\n           'Cytoplasm',\n           'Extracellular',\n           'Mitochondrion',\n           'Cell membrane',\n           'ER',\n           'Chloroplast',\n           'Golgi apparatus',\n           'Lysosome',\n           'Vacuole']\n\ndico_classes_subcell={i:v for i,v in enumerate(classes)}\nfor i in dico_classes_subcell.keys():\n    print('Target', i, dico_classes_subcell[i])\n\nTarget 0 Nucleus\nTarget 1 Cytoplasm\nTarget 2 Extracellular\nTarget 3 Mitochondrion\nTarget 4 Cell membrane\nTarget 5 ER\nTarget 6 Chloroplast\nTarget 7 Golgi apparatus\nTarget 8 Lysosome\nTarget 9 Vacuole"
  },
  {
    "objectID": "cnn_vs_fnn.html#building-the-data-loaders",
    "href": "cnn_vs_fnn.html#building-the-data-loaders",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Building the data loaders",
    "text": "Building the data loaders\n\nbatch_size = 128\n\n# transform to torch tensor\nX_train_tensor = torch.Tensor(X_train) \ny_train_tensor = torch.LongTensor(y_train)\n\nX_valid_tensor = torch.Tensor(X_valid) \ny_valid_tensor = torch.LongTensor(y_valid)\n\n# create the dataset\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor) \nvalid_dataset = TensorDataset(X_valid_tensor,y_valid_tensor) \n\n## create the dataloader\ntrain_dataloader = DataLoader(train_dataset, batch_size = batch_size) \nvalid_dataloader = DataLoader(valid_dataset, batch_size = batch_size)\n\n\nBuilding the convolutional neural network (CNN)\nThis CNN uses two convolutional layers with a 3x3 kernel and a ReLU activation, followed by max pooling to downsample the sequence length while preserving the feature dimension. The resulting features are flattened and fed into a fully connected layer, which maps the extracted features to the 10 subcellular localizations.\n\nclass ProteinLoc_CNN(nn.Module):\n    def __init__(self, seq_len=400, n_feat=20, n_class=10, out_channels=10):\n        super().__init__()\n        \n        ## - two 2D (data are 2D (400 x 20)) convolutional layers with:\n        ##   - a 3x3 kernel to capture local features\n        ##   - a 1x1 padding to preserve spatial dimension (output feature map dimension = input feature map dimension)\n        ## - a max pooling with a 5x1 padding to reduce the sequence length by a factor of 5 preserving feature dimension\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(3, 3), padding=(1, 1)),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(5, 1), stride=(5, 1)),\n\n            nn.Conv2d(in_channels=out_channels, out_channels=out_channels*2, kernel_size=(3, 3), padding=(1, 1)),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(5, 1), stride=(5, 1))\n        )\n        \n        ## flatten the layer to transforms the 2D feature maps from the convolutional layers into a 1D vector\n        self.flatten = nn.Flatten()\n        \n        ## fully connected layer\n        ## map the features from the convolutional layers to the subcellular localizations\n        self.dense_layers = nn.Sequential(\n            nn.Linear(out_channels * 2 * (seq_len // (5 * 5)) * n_feat, n_class)\n        )\n                        \n    def forward(self, x):\n        ## add a channel to reshape the data in the form (batch_size, 1, 400, 20) and\n        ## make them compatible with the Conv2d shape (batch_size, channels, height, width)\n        x = x.unsqueeze(1)\n        x = self.conv(x)  \n        x = self.flatten(x)  \n        x = self.dense_layers(x)\n        return x\n\n# initialize the model\nmodel = ProteinLoc_CNN(seq_len=400, n_feat=20, n_class=10, out_channels=40).to(device)\nprint(model)\n\n# check model\nx, _ = train_dataset[0]\nprint(pms.summary(model, x.reshape(1, 400, 20).to(device), show_input=False))\n\nProteinLoc_CNN(\n  (conv): Sequential(\n    (0): Conv2d(1, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=(5, 1), stride=(5, 1), padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): ReLU()\n    (5): MaxPool2d(kernel_size=(5, 1), stride=(5, 1), padding=0, dilation=1, ceil_mode=False)\n  )\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (dense_layers): Sequential(\n    (0): Linear(in_features=25600, out_features=10, bias=True)\n  )\n)\n------------------------------------------------------------------------\n      Layer (type)         Output Shape         Param #     Tr. Param #\n========================================================================\n          Conv2d-1     [1, 40, 400, 20]             400             400\n            ReLU-2     [1, 40, 400, 20]               0               0\n       MaxPool2d-3      [1, 40, 80, 20]               0               0\n          Conv2d-4      [1, 80, 80, 20]          28,880          28,880\n            ReLU-5      [1, 80, 80, 20]               0               0\n       MaxPool2d-6      [1, 80, 16, 20]               0               0\n         Flatten-7           [1, 25600]               0               0\n          Linear-8              [1, 10]         256,010         256,010\n========================================================================\nTotal params: 285,290\nTrainable params: 285,290\nNon-trainable params: 0\n------------------------------------------------------------------------\n\n\n\n\nBuilding the feedforward neural network (FNN)\nTaken from the 2nd notebook of the course\n\nclass ProteinLoc_FNN(torch.nn.Module):\n    def __init__(self , input_dim = 8000, \n                         hidden_dim = [80],\n                         output_dim = 10, \n                         dropout_fraction = 0.25):\n        super().__init__()\n        \n        ## we transform the input from 2D to 1D\n        self.flatten = nn.Flatten()\n        \n        elements = []\n        # each layer is made of a linear layer with a ReLu activation and a DropOut Layer\n        for i in range(len(hidden_dim)):\n            \n            elements.append( nn.Linear(input_dim, hidden_dim[i]) )\n            elements.append( nn.ReLU() )\n            elements.append( nn.Dropout(dropout_fraction) ) ## add regulation\n            \n            input_dim = hidden_dim[i] ## update the input dimension for the next layer\n        \n        elements.append( nn.Linear(input_dim, output_dim) )\n\n        self.layers = nn.Sequential( *elements )\n        \n    def forward(self, x):\n        x = self.flatten(x)\n        ## NB: here, the output of the last layer are logits\n        logits = self.layers(x)\n        return logits\n\n# initialize model\nmodel = ProteinLoc_FNN(input_dim=8000, hidden_dim=[80], output_dim=10, dropout_fraction=0.25).to(device)\nprint(model)\n\n## check model\nprint(pms.summary(model, torch.zeros(1,400,20).to(device), show_input=True))\n\nProteinLoc_FNN(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (layers): Sequential(\n    (0): Linear(in_features=8000, out_features=80, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.25, inplace=False)\n    (3): Linear(in_features=80, out_features=10, bias=True)\n  )\n)\n-----------------------------------------------------------------------\n      Layer (type)         Input Shape         Param #     Tr. Param #\n=======================================================================\n         Flatten-1        [1, 400, 20]               0               0\n          Linear-2           [1, 8000]         640,080         640,080\n            ReLU-3             [1, 80]               0               0\n         Dropout-4             [1, 80]               0               0\n          Linear-5             [1, 80]             810             810\n=======================================================================\nTotal params: 640,890\nTrainable params: 640,890\nNon-trainable params: 0\n-----------------------------------------------------------------------"
  },
  {
    "objectID": "cnn_vs_fnn.html#trainingvalidation-and-plotting-functions",
    "href": "cnn_vs_fnn.html#trainingvalidation-and-plotting-functions",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Training/validation and plotting functions",
    "text": "Training/validation and plotting functions\n\ndef train(dataloader, model, loss_fn, optimizer, echo=True, echo_batch=False):\n    \n    size = len(dataloader.dataset) # how many batches do we have\n    model.train() # Sets the module in training mode.\n    \n       \n    for batch, (X, y) in enumerate(dataloader): # for each batch\n        X, y = X.to(device), y.to(device)       # send the data to the GPU or whatever device you use for training\n\n        # Compute prediction error\n        pred = model(X)              # prediction for the model -&gt; forward pass\n        loss = loss_fn(pred, y)      # loss function from these prediction\n                \n        # Backpropagation\n        loss.backward()              # backward propagation \n                                     # https://ml-cheatsheet.readthedocs.io/en/latest/backpropagation.html\n                                     # https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html\n        \n        optimizer.step()             \n        optimizer.zero_grad()        # reset the gradients\n                                     # https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n        \n        if echo_batch:\n            current =  (batch + 1) * len(X)\n            print(f\"Train loss: {loss.item():&gt;7f} [{current:&gt;5d}/{size:&gt;5d}]\")\n    \n    if echo:\n        current =  (batch + 1) * len(X)\n        print(f\"Train loss: {loss.item():&gt;7f}\")\n\n    # return the last batch loss\n    return loss.item()\n\ndef valid(dataloader, model, loss_fn, echo = True):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval() # Sets the module in evaluation mode\n        \n    valid_loss = 0\n    with torch.no_grad(): ## disables tracking of gradient: prevent accidental training + speeds up computation\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            valid_loss += loss_fn(pred, y).item()  ## accumulating the loss function over the batches\n              \n    valid_loss /= num_batches\n\n    if echo:\n        print(f\"\\tValid loss: {valid_loss:&gt;8f}\")\n   \n    return  valid_loss\n\n\nUtility functions\n\n## get predicted and target from the model\ndef get_model_predictions_and_y(model, dataloader):\n    target = np.array([], dtype= 'float32') ## []\n    predicted = np.array([], dtype= 'float32') ## []\n    with torch.no_grad():\n        for X,y in dataloader:\n            X = X.to(device)\n            pred = model(X)\n            target = np.concatenate([target, y.squeeze().numpy()]) ## extend -&gt; concatenate for list\n            predicted = np.concatenate([predicted, np.argmax(pred.to('cpu').detach().numpy() , axis=1) ] )\n\n    return predicted, target\n\n## utility function: compute additional metrics during training besides entropy loss \ndef get_additional_scores(predicted, target):   \n    return { 'balanced_accuracy': metrics.balanced_accuracy_score(target, predicted),\n             'accuracy': metrics.accuracy_score(target, predicted),\n             'f1': metrics.f1_score(target, predicted, average = 'macro') }\n\n## format elapsed time\ndef format_time(seconds):\n    if seconds &lt; 60:\n        return f\"{seconds:.2f}s\"\n    elif seconds &lt; 3600:\n        minutes = int(seconds // 60)\n        remaining_seconds = seconds % 60\n        return f\"{minutes}m {remaining_seconds:.2f}s ({seconds:.2f}s)\"\n    else:\n        hours = int(seconds // 3600)\n        remaining_minutes = int((seconds % 3600)) // 60\n        remaining_seconds = seconds % 60\n        return f\"{hours}h {remaining_minutes}m and {remaining_seconds:.2f}s ({seconds:.2f}s)\"\n\n\n\nPlotting functions\n\n## plot training metrics\ndef plot_model_training(train_scores, valid_scores):\n    fig, axes = plt.subplots(2,2,figsize = (14,8))    \n\n    for i,k in enumerate( ['loss', 'balanced_accuracy', 'accuracy', 'f1'] ) :\n        axes[i//2][i%2].plot(train_scores[k], label = 'train')\n        axes[i//2][i%2].plot(valid_scores[k], label = 'validation')\n        if k == 'loss':\n            axes[i//2][i%2].axvline(np.argmin(valid_scores[k]), linestyle='--', color='r',label='Early Stopping Checkpoint')\n        axes[i//2][i%2].legend()\n        axes[i//2][i%2].set_xlabel('epoch')\n        axes[i//2][i%2].set_ylabel(k)\n\n## plot confusion matrix\ndef plot_confusion_matrix(model, X_valid_tensor, y_valid):\n    ## we can also use get_model_predictions_and_y() instead \n    y_pred = model(X_valid_tensor.to(device))\n    y_pred = np.argmax(y_pred.detach().cpu().numpy(), axis=1)\n\n    df = pd.crosstab(y_valid, y_pred, rownames=['truth'], colnames=['prediction'])\n    df.columns = classes\n    df.index = classes\n\n    #trick to make the 0s dissapear\n    sns.heatmap(df, annot = df.astype(str).replace('0',''), fmt ='s', cmap = 'viridis')\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n## plotting accuracy\ndef plot_accuracy(accuracy, xlabel, ylabel='Accuracy', title='Accuracy comparison'):\n    plt.figure(figsize=(4,4))\n    acc_score = accuracy\n    x = np.arange(len(acc_score))\n    plt.bar(x, acc_score)\n    plt.title(title)\n    plt.ylabel(ylabel)\n    plt.xticks(x, xlabel, rotation=60)\n    for i, v in enumerate(acc_score):\n        plt.text(i, v-0.07, '%.3f'%v, color='white', fontweight='bold', ha='center')\n\n\n\nWrapper function\nTo train and evaluate CNN and FNN we use:\n\nCEloss as loss function\naccuracy, balanced_accuracy and F1_score as performance metrics\nAdam as optimizer. For both models we used the hyperparameters configuration adopted from the 2nd notebook\nearly stopping for regularization\n\n\n\ndef train_ProteinLoc(model = ProteinLoc_CNN().to(device), \n                     lr=10**-3, weight_decay=0, ## default Adam parameters setting\n                     epochs=100, patience=25):\n   \n    ## set the model\n    model = model\n\n    ## set the loss function counting class unbalancing\n    n_class=10\n    W = torch.Tensor(compute_class_weight(class_weight='balanced', \n                     classes = np.array(list(range(n_class))), ## map subcell locations to int\n                     y= y_train)).to(device)\n    CEloss = nn.CrossEntropyLoss(weight = W)\n    #print('weights_classes',W.cpu().numpy())\n\n    ## set the optimizer: https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n    optimizer = torch.optim.Adam(model.parameters(), \n                                 lr =  lr,\n                                 weight_decay = weight_decay)\n\n    ## early stopping: prevent overfitting and reduce training time\n    early_stopping = EarlyStopping(patience=patience, verbose=False)\n\n    ## keep the scores across epochs\n    train_scores = {'loss':[], 'balanced_accuracy':[], 'accuracy':[], 'f1':[]}\n    valid_scores = {'loss':[], 'balanced_accuracy':[], 'accuracy':[], 'f1':[]}\n    \n    ## train the model across epochs\n    for t in range(1,epochs+1):\n        echo = t%10==0\n        if echo:\n            print('Epoch',t )    \n        \n        ## training set\n        train_scores['loss'].append(train(train_dataloader, \n                                    model, \n                                    CEloss, \n                                    optimizer,                        \n                                    echo=echo, echo_batch=False))\n        pred_train, target_train = get_model_predictions_and_y(model, train_dataloader)\n        train_metric = get_additional_scores(pred_train, target_train)\n        \n        ## validation set\n        valid_scores['loss'].append(valid(valid_dataloader, \n                                    model, \n                                    CEloss,\n                                    echo=echo))\n        pred_valid, target_valid = get_model_predictions_and_y(model, valid_dataloader)\n        valid_metric = get_additional_scores(pred_valid, target_valid)\n        \n        ## add extra metric\n        for k in ['balanced_accuracy', 'accuracy', 'f1']:\n            train_scores[k].append(train_metric[k])\n            valid_scores[k].append(valid_metric[k])\n\n        early_stopping(valid_scores['loss'][-1], model) ## send last valid_score to early stop\n\n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break\n\n    print(\"Done!\")\n    \n    return train_scores, valid_scores, model, CEloss, optimizer\n\n\n\nHyperparmeters\nHyperparmeters configuration used for training/testing all the models - for a fair comparison\n\nepochs = 500\nlr = 10**-4\nweight_decay = 10**-2\npatience = 100"
  },
  {
    "objectID": "cnn_vs_fnn.html#training-the-cnn",
    "href": "cnn_vs_fnn.html#training-the-cnn",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Training the CNN",
    "text": "Training the CNN\n\nstart_time = time.time()\n\ntrain_scores_cnn, valid_scores_cnn, model_cnn, CEloss_cnn, optimizer_cnn = \\\n    train_ProteinLoc(ProteinLoc_CNN(seq_len=400, n_feat=20, n_class=10, out_channels=40).to(device),\n                     lr=lr, weight_decay=weight_decay,\n                     epochs=epochs, patience=patience);\n\nend_time = time.time()\n\n\nelapsed_time = end_time - start_time\nprint(f\"elapsed time: {format_time(elapsed_time)}\")\n\nelapsed time: 44m 33.71s (2673.71s)\n\n\n\nEvaluating the CNN\n\nplot_model_training(train_scores_cnn, valid_scores_cnn)"
  },
  {
    "objectID": "cnn_vs_fnn.html#training-the-fnn",
    "href": "cnn_vs_fnn.html#training-the-fnn",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Training the FNN",
    "text": "Training the FNN\n\nstart_time = time.time()\n\ntrain_scores_fnn, valid_scores_fnn, model_fnn, CEloss_fnn, optimizer_fnn = \\\n    train_ProteinLoc(ProteinLoc_FNN(input_dim=8000, hidden_dim=[80], output_dim=10, \n                                    dropout_fraction=0.25).to(device),\n                     lr=lr, weight_decay=weight_decay,\n                     epochs=epochs, patience=patience)\n\nend_time = time.time()\n\n\nelapsed_time = end_time - start_time\nprint(f\"elapsed time: {format_time(elapsed_time)}\")\n\nelapsed time: 1m 34.77s (94.77s)\n\n\n\nEvaluating the FNN\n\nplot_model_training(train_scores_fnn, valid_scores_fnn)"
  },
  {
    "objectID": "cnn_vs_fnn.html#performance-comparison-cnn-vs-fnn",
    "href": "cnn_vs_fnn.html#performance-comparison-cnn-vs-fnn",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Performance comparison: CNN vs FNN",
    "text": "Performance comparison: CNN vs FNN\n\ny_pred_cnn, y_cnn = get_model_predictions_and_y(model_cnn, valid_dataloader)\ny_pred_fnn, y_fnn = get_model_predictions_and_y(model_fnn, valid_dataloader)\n\n\nCNN\n\nplot_confusion_matrix(model_cnn, X_valid_tensor, y_valid)\n\n\n\n\n\n\n\n\n\nprint(classification_report(y_valid, y_pred_cnn, target_names=classes))\n\n                 precision    recall  f1-score   support\n\n        Nucleus       0.86      0.86      0.86        95\n      Cytoplasm       0.88      0.74      0.80       151\n  Extracellular       0.92      0.82      0.87       131\n  Mitochondrion       0.67      0.83      0.74        64\n  Cell membrane       0.79      0.91      0.85        69\n             ER       0.60      0.69      0.64        13\n    Chloroplast       0.85      0.78      0.82        60\nGolgi apparatus       0.81      0.72      0.76        18\n       Lysosome       0.79      0.79      0.79        19\n        Vacuole       0.37      0.73      0.49        15\n\n       accuracy                           0.81       635\n      macro avg       0.75      0.79      0.76       635\n   weighted avg       0.83      0.81      0.81       635\n\n\n\n\n\nFNN\n\nplot_confusion_matrix(model_fnn, X_valid_tensor, y_valid)\n\n\n\n\n\n\n\n\n\nprint(classification_report(y_valid, y_pred_fnn, target_names=classes))\n\n                 precision    recall  f1-score   support\n\n        Nucleus       0.82      0.81      0.81        95\n      Cytoplasm       0.76      0.84      0.80       151\n  Extracellular       0.87      0.87      0.87       131\n  Mitochondrion       0.75      0.83      0.79        64\n  Cell membrane       0.71      0.81      0.76        69\n             ER       0.50      0.15      0.24        13\n    Chloroplast       0.85      0.75      0.80        60\nGolgi apparatus       0.74      0.78      0.76        18\n       Lysosome       0.75      0.47      0.58        19\n        Vacuole       0.80      0.27      0.40        15\n\n       accuracy                           0.79       635\n      macro avg       0.75      0.66      0.68       635\n   weighted avg       0.79      0.79      0.78       635"
  },
  {
    "objectID": "cnn_vs_fnn.html#accuracy-comparison",
    "href": "cnn_vs_fnn.html#accuracy-comparison",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Accuracy comparison",
    "text": "Accuracy comparison\n\n## other way of computing accuracy\n# from sklearn.metrics import confusion_matrix\n# cm_fnn = confusion_matrix(y_valid, y_pred_fnn)\n# accuracy_fnn = np.trace(cm_fnn) / np.sum(cm_fnn)\n\naccuracy_cnn = get_additional_scores(y_pred_cnn, y_cnn)['accuracy']\naccuracy_fnn = get_additional_scores(y_pred_fnn, y_fnn)['accuracy']\n\n## plot accuracy \nplot_accuracy(accuracy=[accuracy_fnn, accuracy_cnn],\n              xlabel=['FNN','CNN'],\n              ylabel='Accuracy', title='')\n\n\n\n\n\n\n\n\n\nBalanced accuracy comparison\n\n## compute balanced accuracy over subcellular localizations (classes)\n\nbalanced_accuracy_cnn = get_additional_scores(y_pred_cnn, y_cnn)['balanced_accuracy']\nbalanced_accuracy_fnn = get_additional_scores(y_pred_fnn, y_fnn)['balanced_accuracy']\n\n## plot accuracy\n## note: p -&gt; padding and s -&gt; stride \nplot_accuracy(accuracy=[balanced_accuracy_fnn, balanced_accuracy_cnn],\n              xlabel=['FNN','CNN'],\n              ylabel='Balanced accuracy', title='')"
  },
  {
    "objectID": "cnn_vs_fnn.html#conclusions-and-considerations",
    "href": "cnn_vs_fnn.html#conclusions-and-considerations",
    "title": "Predicting protein subcellular localizations based on sequence information",
    "section": "Conclusions and considerations",
    "text": "Conclusions and considerations\n\nCNN slightly outperforms FNN, but at a much higher computational cost: CNN took 12min while FNN took 10sec in current configuration\nIncreasing the number of output channels (i.e. feature maps) boosts CNN performance, but at the cost of increased training time. For instance, a CNN with 80 output channels yielded an accuracy of around 0.82 after roughly 40 minutes of training (data not shown)."
  },
  {
    "objectID": "r3_clustering_seurat.html",
    "href": "r3_clustering_seurat.html",
    "title": "Identification of breast cancer subtypes and biomarkers using the Seurat workflow",
    "section": "",
    "text": "The goal of this report is to identify breast cancer subtypes by using the Seurat workflow. In particular, we aim at validating the results obtained in the report Identification of breast cancer subtypes, where molecular subtypes were idetified by using an in-house graph-based approach."
  },
  {
    "objectID": "r3_clustering_seurat.html#aims",
    "href": "r3_clustering_seurat.html#aims",
    "title": "Identification of breast cancer subtypes and biomarkers using the Seurat workflow",
    "section": "",
    "text": "The goal of this report is to identify breast cancer subtypes by using the Seurat workflow. In particular, we aim at validating the results obtained in the report Identification of breast cancer subtypes, where molecular subtypes were idetified by using an in-house graph-based approach."
  },
  {
    "objectID": "r3_clustering_seurat.html#loading-data-as-a-seurat-object",
    "href": "r3_clustering_seurat.html#loading-data-as-a-seurat-object",
    "title": "Identification of breast cancer subtypes and biomarkers using the Seurat workflow",
    "section": "Loading data as a Seurat object",
    "text": "Loading data as a Seurat object\n\nwriteMMgz &lt;- function(x, file, threads = 10){\n  mtype &lt;- \"real\"\n  if (is(x, \"ngCMatrix\")) {\n    mtype &lt;- \"integer\"\n  }\n  writeLines(\n    c(\n      sprintf(\"%%%%MatrixMarket matrix coordinate %s general\", mtype),\n      sprintf(\"%s %s %s\", x@Dim[1], x@Dim[2], length(x@x))\n    ),\n    gzfile(file)\n  )\n  data.table::fwrite(\n    x = summary(x),\n    file = file,\n    append = TRUE,\n    sep = \" \",\n    row.names = FALSE,\n    col.names = FALSE,\n    nThread = threads %||% data.table::getDTthreads()\n  )\n}\n\n\nsfile &lt;- 'data/seurat_object.qs2'\nif(!file.exists(sfile)){  \n  dt &lt;- fread(\"data/gene_expression_profile.csv.gz\")\n  genes &lt;- dt[[1]]  \n  dt[, 1 := NULL]   ## remove gene names column\n\n  # convert to matrix and then sparse\n  mx &lt;- as.matrix(dt)\n  rownames(mx) &lt;- genes\n  sm &lt;- as(mx, \"sparseMatrix\")\n\n  writeMMgz(sm, 'data/gene_expression_matrix.mtx.gz')\n  write_csv(as_tibble(colnames(sm)), col_names = FALSE, file = 'data/patients.tsv.gz')\n  write_csv(as_tibble(rownames(sm)), col_names = FALSE, file = 'data/genes.tsv.gz')\n\n  ## other way for writing the matrix on a file\n  # writeMM(sp, \"data/expression_matrix.mtx\")\n  # system(\"gzip data/gene_expression_matrix.mtx.gz\")\n  \n  ## load sparse matrix\n  mx &lt;- Seurat::ReadMtx(\n    mtx = 'data/gene_expression_matrix.mtx.gz', \n    features = 'data/genes.tsv.gz', \n    cells = 'data/patients.tsv.gz', \n    cell.column = 1, feature.column = 1\n  )\n\n  ## load metadata\n  meta &lt;- read_csv('data/metadata.csv', col_types = cols()) |&gt;\n    dplyr::rename(sampleID = values, sampleName = ind) |&gt;\n    dplyr::filter(sampleID %in% colnames(mx)) |&gt;\n    dplyr::mutate(\n      er_status = factor(er_status, levels = c(0, 1), labels = c(\"ER-\", \"ER+\")),\n      pgr_status = factor(pgr_status, levels = c(0, 1), labels = c(\"PgR-\", \"PgR+\")),\n      her2_status = factor(her2_status, levels = c(0, 1), labels = c(\"HER2-\", \"HER2+\")),\n      ki67_status = factor(ki67_status, levels = c(0, 1), labels = c(\"Ki67-\", \"Ki67+\")),\n      overall_survival_event = factor(overall_survival_event, levels = c(0, 1), labels = c(\"no survival\", \"survival\")),\n      endocrine_treated = factor(endocrine_treated, levels = c(0, 1), labels = c(\"no treated\", \"treated\")),\n      chemo_treated = factor(chemo_treated, levels = c(0, 1), labels = c(\"no treated\", \"treated\")),\n      lymph_node_group = factor(lymph_node_group),\n      lymph_node_status = factor(lymph_node_status),\n      pam50_subtype = factor(pam50_subtype),\n      nhg = factor(nhg)\n    ) |&gt;\n    tibble::column_to_rownames(var = 'sampleID')\n\n  ## create seurat object\n  sobj &lt;- CreateSeuratObject(mx)\n  sobj &lt;- AddMetaData(sobj, metadata = meta)\n\n  ## use sobj@assays$RNA$counts instead of mx to use all genes (otherwise 90 genes are filtered out)\n  ## seurat automatically replaces '_' with '-' in gene names to avoid r syntax issues\n  ## smx &lt;- SetAssayData(sobj, layer = \"data\", new.data = mx)\n  ## setdiff(rownames(mx), rownames(smx)) |&gt; length() ## 90\n  sobj &lt;- SetAssayData(sobj, layer = \"data\", new.data = sobj@assays$RNA$counts) ## already normalized data\n\n  ## save and clean data\n  qs2::qs_save(sobj, file = 'data/seurat_object.qs2', nthreads = 10)\n  file.remove('data/gene_expression_matrix.mtx.gz')\n  file.remove('data/genes.tsv.gz')\n  file.remove('data/patients.tsv.gz')\n}"
  },
  {
    "objectID": "r3_clustering_seurat.html#running-the-seurat-workflow",
    "href": "r3_clustering_seurat.html#running-the-seurat-workflow",
    "title": "Identification of breast cancer subtypes and biomarkers using the Seurat workflow",
    "section": "Running the Seurat workflow",
    "text": "Running the Seurat workflow\n\nsobj &lt;- qs2::qs_read(file = 'data/seurat_object.qs2', nthreads = 10)\n\nsobj &lt;- Seurat::ScaleData(sobj, features = rownames(sobj))\nsobj &lt;- Seurat::FindVariableFeatures(sobj, selection.method = \"vst\", nfeatures = 3000)\n\nsobj &lt;- Seurat::RunPCA(sobj)\nsobj &lt;- Seurat::FindNeighbors(sobj, dims = 1:25)\nsobj &lt;- Seurat::FindClusters(sobj, resolution = 1, verbose = FALSE)\nsobj &lt;- Seurat::RunUMAP(sobj, dims = 1:25)\n# sobj &lt;- RunTSNE(sobj, dims = 1:25)"
  },
  {
    "objectID": "r3_clustering_seurat.html#clustering-evaluation",
    "href": "r3_clustering_seurat.html#clustering-evaluation",
    "title": "Identification of breast cancer subtypes and biomarkers using the Seurat workflow",
    "section": "Clustering evaluation",
    "text": "Clustering evaluation\nWe compute a Silhouette score to evaluate how well a data point (i.e. a patient) is clustered. A positive Silhouette value means that a patient was correctly assigned to a cluster, whereas a negative value means that it is not. The larger the silhouette width, the better a patient is clustered.\n\n## compute silhouette scores: \n## https://github.com/satijalab/Integration2019/blob/master/analysis_code/integration/integration_metrics.R#L36\ndistance_matrix &lt;- dist(Seurat::Embeddings(sobj[['pca']])[, 1:15])\nclusters &lt;- sobj@meta.data$seurat_clusters\nsilhouette &lt;- cluster::silhouette(as.numeric(clusters), dist = distance_matrix)\nsobj@meta.data$silhouette_score &lt;- silhouette[,3]\n\nmean_silhouette_score &lt;- mean(sobj@meta.data$silhouette_score)\n\ndf &lt;- sobj@meta.data |&gt;\n  dplyr::arrange(seurat_clusters, -silhouette_score) |&gt;\n  dplyr::mutate(patient = factor(sampleName, levels = sampleName))\n\n\nggplot(df) +\n  geom_col(aes(patient, silhouette_score, fill = seurat_clusters), show.legend = TRUE) +\n  geom_hline(yintercept = mean_silhouette_score, color = 'gray50', linetype = 'dashed') +\n  scale_x_discrete(name = 'Patients') +\n  scale_y_continuous(name = 'Silhouette score') +\n  theme_bw() +\n  theme(\n    axis.title.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank(),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )"
  },
  {
    "objectID": "r3_clustering_seurat.html#clustering-all-patients",
    "href": "r3_clustering_seurat.html#clustering-all-patients",
    "title": "Identification of breast cancer subtypes and biomarkers using the Seurat workflow",
    "section": "Clustering all patients",
    "text": "Clustering all patients\n\nscplotter::CellDimPlot(\n  sobj, group_by = \"seurat_clusters\", reduction = \"umap\",\n  label = TRUE, label_insitu = TRUE, label_size = 5,\n  palette = \"seurat\",\n  theme = ggplot2::theme_classic\n)\n\n\n\n\n\n\n\nIn the plot below, ER- patients are highlighted and the frequency of the ER status is shown for each cluster.\n\nscplotter::CellDimPlot(\n  sobj, group_by = \"pam50_subtype\", reduction = \"umap\",\n  label = TRUE, label_insitu = TRUE, label_size = 5,\n  stat_by = \"er_status\", stat_plot_type = \"bar\", \n  stat_type = \"count\",\n  stat_plot_size = 0.10,\n  highlight = 'er_status == \"ER-\"',\n  # palette = \"seurat\",\n  palcolor = scales::hue_pal()(10)[c(2,3,4,6,8)],\n  theme = ggplot2::theme_classic\n  #stat_args = list(label = TRUE)\n)\n\n\n\n\n\n\n\nIn the plot below, PgR- patients are highlighted and the frequency of the PgR status is shown for each cluster.\n\nscplotter::CellDimPlot(\n  sobj, group_by = \"pam50_subtype\", reduction = \"umap\",\n  label = TRUE, label_insitu = TRUE, label_size = 5,\n  stat_by = \"pgr_status\", stat_plot_type = \"bar\", \n  stat_type = \"count\",\n  stat_plot_size = 0.10,\n  highlight = 'pgr_status == \"PgR-\"',\n  # palette = \"seurat\",\n  palcolor = scales::hue_pal()(10)[c(2,3,4,6,8)],\n  theme = ggplot2::theme_classic\n  #stat_args = list(label = TRUE)\n)"
  },
  {
    "objectID": "r3_clustering_seurat.html#finding-differentially-expressed-biomarkers",
    "href": "r3_clustering_seurat.html#finding-differentially-expressed-biomarkers",
    "title": "Identification of breast cancer subtypes and biomarkers using the Seurat workflow",
    "section": "Finding differentially expressed biomarkers",
    "text": "Finding differentially expressed biomarkers\nHere we aim at finding markers that define clusters via differential expression. To this end we:\n\nidentify upregulated (positive) and downregulated (negative) markers of the Basal cluster (cluster 5) compared to all the others;\nidentify up- and down-regulated markers for every cluster compared to all the others.\n\nMoreover, we visualize the gene expression profile of some breast cancer biomarkers taken from literature (reference1 and reference2)\nUpregulated biomarkers of the Basal cluster\n\nbasal_markers_up &lt;- Seurat::FindMarkers(\n  sobj, layer = \"data\", \n  ident.1 = 5,\n  only.pos = TRUE)\n\n\nSeurat::FeaturePlot(\n  sobj,  ncol = 2,\n  features = rownames(basal_markers_up)[1:10])\n\n\n\n\n\n\n\n\nSeurat::VlnPlot(sobj, ncol=2, features = rownames(basal_markers_up)[1:10])\n\n\n\n\n\n\n\nDownregulated biomarkers of the Basal cluster\n\nbasal_markers_down &lt;- Seurat::FindMarkers(\n  sobj, layer = \"data\", \n  ident.1 = 5,\n  only.pos = FALSE\n)\n\n\nSeurat::FeaturePlot(\n  sobj, ncol = 2,\n  features = rownames(basal_markers_down)[1:10]\n)\n\n\n\n\n\n\n\n\nSeurat::VlnPlot(sobj, ncol=2, features = rownames(basal_markers_down)[1:10])\n\n\n\n\n\n\n\nUpregulated biomarkers of all clusters\n\nup_markers &lt;- Seurat::FindAllMarkers(sobj, only.pos = TRUE)\n\ntop10up &lt;- up_markers |&gt;\n  group_by(cluster) |&gt;\n  dplyr::filter(avg_log2FC &gt; 1) |&gt;\n  dplyr::arrange(p_val_adj, avg_log2FC) |&gt;\n  slice_head(n = 10) |&gt;\n  ungroup()\n\n\nSeurat::DoHeatmap(sobj, features = top10up$gene)\n\n\n\n\n\n\n\nDownregulated biomarkers of all clusters\n\ndown_markers &lt;- Seurat::FindAllMarkers(sobj, only.pos = FALSE)\n\ntop10down &lt;- down_markers |&gt;\n  group_by(cluster) |&gt;\n  dplyr::filter(avg_log2FC &lt; -1) |&gt;\n  dplyr::arrange(p_val_adj, avg_log2FC) |&gt;\n  slice_head(n = 10) |&gt;\n  ungroup()\n\n\nSeurat::DoHeatmap(sobj, features = top10down$gene)\n\n\n\n\n\n\n\nKnown breast cancer biomarkers\n\n## biomarkers for breast cancer:\n##  - https://pmc.ncbi.nlm.nih.gov/articles/PMC3835118/\n##  - https://pmc.ncbi.nlm.nih.gov/articles/PMC7446376/\nSeurat::FeaturePlot(sobj, ncol=3,\n  features = c('SOX2', 'FOXC1', 'FOXC2', 'CD44', 'IMP3', 'ESR1', \n               'PGR', 'ERBB2', 'MKI67', 'FABP7', 'AQP1', 'PTEN', \n               'LYN', 'EGFR', 'LBX1')\n)\n\n\n\n\n\n\n\n\nSeurat::VlnPlot(sobj, ncol=3,\n  features = c('SOX2', 'FOXC1', 'FOXC2', 'CD44', 'IMP3', 'ESR1', \n               'PGR', 'ERBB2', 'MKI67', 'FABP7', 'AQP1', 'PTEN', \n               'LYN', 'EGFR', 'LBX1')\n)"
  },
  {
    "objectID": "r3_clustering_seurat.html#check-cluster-assignment",
    "href": "r3_clustering_seurat.html#check-cluster-assignment",
    "title": "Identification of breast cancer subtypes and biomarkers using the Seurat workflow",
    "section": "Check cluster assignment",
    "text": "Check cluster assignment\nTo validate the two workflows, we checked that patients with the most aggressive expression profile (i.e. those in the Basal cluster) clustered in the same group. As expected, patients assigned to the Basal cluster are the same except three. The cluster assignment of the in-house workflow was downloaded from here.\n\n## mtib downloaded from https://marconotaro.github.io/portfolio/r2_clustering.html#patient-cluster-assignment\n\nstib &lt;- rownames_to_column(sobj@meta.data, var = 'patient') |&gt; as_tibble()\nmtib &lt;-  read_csv('data/cluster_anno_my_wflow.csv', col_types = cols())\n\nmpat &lt;- mtib |&gt; filter(cluster==1) |&gt; pull(sample)\nspat &lt;- stib |&gt; filter(seurat_clusters==5) |&gt; pull(patient)\n\ncat('npat in mpat:', length(mpat), '\\n')\n\nnpat in mpat: 304 \n\ncat('npat in spat', length(spat), '\\n')\n\nnpat in spat 301 \n\nprint(summary(spat %in% mpat))\n\n   Mode   FALSE    TRUE \nlogical       3     298 \n\n\n\ndatatable &lt;- function(tib, row2display = 10) {\n  if(nrow(tib) &gt; 0){\n    DT::datatable(tib,\n      rownames   = FALSE,\n      extensions = \"Buttons\",\n      options    = list(\n        dom = \"Bfrtip\",\n        scrollX = TRUE,\n        pageLength = row2display,\n        buttons = list(\n          list(\n            extend  = \"collection\",\n            buttons = c(\"csv\", \"excel\"),\n            text    = \"Download\"\n          )\n        )\n      ),\n      class = \"display\",\n      style = \"bootstrap\"\n    )\n  }else{\n    print(\"No results\")\n  }\n}\n\nformatter &lt;- function(tib, cols_to_format = \"all\", digits = 3){\n  selector &lt;- if(length(cols_to_format) == 1 && cols_to_format == \"all\"){\n    where(is.numeric)\n  } else {\n    all_of(cols_to_format)\n  }\n\n  tib |&gt; \n    mutate(across({{ selector }},\n           ~format(., scientific = TRUE, digits = digits)))\n}\n\n# write_csv(stib, file = 'data/cluster_anno_seurat.csv')\nstib |&gt; \n  formatter(cols_to_format = c(\"nCount_RNA\", \"silhouette_score\")) |&gt;\n  datatable()"
  },
  {
    "objectID": "r3_clustering_seurat.html#conclusion",
    "href": "r3_clustering_seurat.html#conclusion",
    "title": "Identification of breast cancer subtypes and biomarkers using the Seurat workflow",
    "section": "Conclusion",
    "text": "Conclusion\nAs expected, the clustering results obtained with the Seurat workflow are consistent wih those shown in the report Identification of breast cancer subtypes."
  },
  {
    "objectID": "r3_clustering_seurat.html#next-step",
    "href": "r3_clustering_seurat.html#next-step",
    "title": "Identification of breast cancer subtypes and biomarkers using the Seurat workflow",
    "section": "Next step",
    "text": "Next step\nCluster assignment can be used to train supervised machine learning models to predict the ER status for those patients where the ER status is unknown."
  },
  {
    "objectID": "r1_eda.html",
    "href": "r1_eda.html",
    "title": "Exploratory data analysis: validation of technical replicates",
    "section": "",
    "text": "The GSE96058 patient cohort contains 3273 samples of which 136 have technical replicates. Some of these replicates were sequenced on a different sequencer (HiSeq2000 and NextSeq500). In this report, I analyze the gene expression profiles of these technical replicates to assess their similarity. This serves as a technical validation before averaging their gene expression values."
  },
  {
    "objectID": "r1_eda.html#aims",
    "href": "r1_eda.html#aims",
    "title": "Exploratory data analysis: validation of technical replicates",
    "section": "",
    "text": "The GSE96058 patient cohort contains 3273 samples of which 136 have technical replicates. Some of these replicates were sequenced on a different sequencer (HiSeq2000 and NextSeq500). In this report, I analyze the gene expression profiles of these technical replicates to assess their similarity. This serves as a technical validation before averaging their gene expression values."
  },
  {
    "objectID": "r1_eda.html#validation-of-technical-replicates",
    "href": "r1_eda.html#validation-of-technical-replicates",
    "title": "Exploratory data analysis: validation of technical replicates",
    "section": "Validation of technical replicates",
    "text": "Validation of technical replicates\n\n\n\n\n\n\nNote\n\n\n\nThe authors provided only transformed gene expression data, which I then used for downstream analysis.\n\n\nLoading data\n\ngexp &lt;- read_csv(\n  'data/GSE96058_gene_expression_3273_samples_and_136_replicates_transformed.csv.gz', \n  col_types = cols()\n) |&gt; rename(genes = `...1`)\n\nmeta &lt;- read_csv('data/metadata.csv', col_types = cols()) |&gt;\n  rename(sampleID = values, sampleName = ind)\n\n\nrep &lt;- gexp |&gt; select(contains('repl')) |&gt; colnames() |&gt; str_remove('repl')\n\nmxrep &lt;- gexp |&gt; \n  select(genes, all_of(rep) | contains('repl')) |&gt; \n  column_to_rownames(var = 'genes') \n\nmdrep &lt;- meta |&gt; \n  filter(sampleID %in% colnames(mxrep)) |&gt;\n  select(sampleID, instrument_model, age_at_diagnosis, \n         tumor_size, lymph_node_group, lymph_node_status, \n         her2_status, ki67_status, pgr_status, nhg, \n         endocrine_treated, chemo_treated) |&gt; \n  column_to_rownames(var = 'sampleID')\n\nPCA\nI apply a Principal Component Analysis (PCA) on the gene expression profiles of technical replicates (marked with the same color) to assess similarity in gene expression. As expected, technical replicates cluster together.\n\npc &lt;- PCAtools::pca(mxrep, metadata = mdrep, center = TRUE, scale = FALSE, removeVar = 0.1)\n\nstopifnot(rownames(mdrep) %in% rownames(pc$rotated))\n\nplot_pca &lt;- function(pc, pcx ='PC1', pcy = 'PC2'){\n  pc_data &lt;- cbind(pc$rotated[, c(pcx, pcy)], mdrep) |&gt;\n    rownames_to_column(var = 'sample')|&gt;\n    mutate(strip_rep = str_replace(sample, 'repl', ''))\n\n  pc_val &lt;- round(pc$variance[c(pcx, pcy)], 2) |&gt; unname()\n\n  ggplot(pc_data, aes(x = !!sym(pcx), y = !!sym(pcy), color = strip_rep, shape = instrument_model)) +\n    geom_point(size = 3) + \n    labs(title = \"\",\n         x = paste0(\"PC1 (\", pc_val[1], \"% variance)\"),\n         y = paste0(\"PC2 (\", pc_val[2], \"% variance)\"),\n         shape = \"Platform\",) +\n    geom_text_repel(data = pc_data, \n                    aes(label = sample), \n                    min.segment.length = 5, max.overlaps = Inf) +\n    theme_bw() +\n    theme(plot.title = element_text(hjust = 0.5)) +\n    guides(color = \"none\")\n}\n\nplot_pca(pc, pcx ='PC1', pcy = 'PC2')\n\n\n\n\n\n\n\nSample correlations\nFor a quantitative overview, I compute the Spearman’s rank correlation for each pair. As expected, technical replicates are strongly correlated (coefficient higher than 0.9) and their gene expression can be safely averaged for downstream analyses.\n\nmxrep_paired &lt;- mxrep[, str_sort(colnames(mxrep), numeric = TRUE)]\n\ntib &lt;- tibble(\n  comparison = character(),\n  correlation = numeric(),\n  p_value = numeric(),\n  informative = logical(),\n  significant = logical()\n)\n\nfor(i in seq(1, ncol(mxrep_paired)-1, by = 2)){\n  corr &lt;- cor.test(mxrep_paired[, i], \n                   mxrep_paired[, i+1], \n                   method = 'spearman',\n                   exact = FALSE\n                  )\n\n  tmp &lt;- tibble(\n    comparison = paste(colnames(mxrep_paired)[i:(i+1)], collapse=' vs '),\n    correlation = round(corr$estimate, 2),\n    p_value = corr$p.value,\n    informative =  round(corr$estimate, 2) &gt;= 0.90,\n    significant = corr$p.value &lt; 0.05\n  )\n\n  tib &lt;- rbind(tib, tmp)\n}\n\ndatatable &lt;- function(tib, row2display = 10) {\n  if(nrow(tib) &gt; 0){\n    DT::datatable(tib,\n      rownames   = FALSE,\n      options    = list(\n        dom = \"Bfrtip\",\n        scrollX = TRUE,\n        pageLength = row2display\n      )\n    )\n  }else{\n    print(\"No results\")\n  }\n}\ntib |&gt; datatable()\n\n\n\n\n\nAs an example, below I show the scatter plots of the first 12 pairs.\n\nscatter_plot &lt;- function(data, sample, replicate) {\n  ggplot(data, aes(x = !!sym(sample), y = !!sym(replicate))) +\n    geom_point(colour = \"#56B4E9\", alpha = 0.8, size = 1) +\n    geom_smooth(method = \"lm\", color = \"#D55E00\", formula = y ~ x, se = TRUE) +\n    labs(\n      title = paste(sample, \"vs\", replicate),\n      subtitle = paste(\"r =\", round(cor(data[[sample]], data[[replicate]], method = \"spearman\"), 3))\n    ) +\n    theme_bw() +\n    theme(\n      plot.title = element_text(size = 10),\n      plot.subtitle = element_text(size = 8)\n    )\n}\n\nget_pair &lt;- function(tib, npairs=10){\n  pairs &lt;- str_split(tib$comparison, \" vs \", simplify = TRUE)[1:npairs,]\n  sample &lt;- pairs[, 1]\n  replicate &lt;- pairs[, 2]\n  return(list(sample = sample, replicate = replicate))\n}\n\nsp &lt;- get_pair(tib, npairs = 12)\nplist &lt;- map2(sp$sample, sp$replicate, ~scatter_plot(mxrep, .x, .y))\nwrap_plots(plist, ncol = 4)"
  },
  {
    "objectID": "r1_eda.html#averaging-of-gene-expression-of-technical-replicates",
    "href": "r1_eda.html#averaging-of-gene-expression-of-technical-replicates",
    "title": "Exploratory data analysis: validation of technical replicates",
    "section": "Averaging of gene expression of technical replicates",
    "text": "Averaging of gene expression of technical replicates\n\nmxrep_averaged &lt;- c()\n\nfor(i in seq(1, ncol(mxrep_paired)-1, by = 2)){\n  mxrep_averaged &lt;- cbind(mxrep_averaged, rowMeans(mxrep_paired[,i:(i+1)]))\n  # cat(colnames(mxrep_paired)[i], colnames(mxrep_paired)[i+1], 'averaged\\n')\n}\n\nnorep &lt;- str_subset(colnames(mxrep_paired), 'repl', negate=TRUE)\ncolnames(mxrep_averaged) &lt;- norep\n\ngexp_rep &lt;- mxrep_averaged |&gt; \n  as.data.frame() |&gt; \n  rownames_to_column(var = 'genes') |&gt; \n  as_tibble()\n\nfout &lt;- 'data/gene_expression_profile.csv.gz'\nif(!file.exists(fout)){\n  gexp |&gt; \n    select(-all_of(colnames(gexp_rep)[-1])) |&gt; \n    left_join(gexp_rep, by = 'genes') |&gt; \n    select(-ends_with(\"repl\")) |&gt;\n    {\\(s)  ## lambda function ..\n      select(s, genes, all_of(str_sort(names(select(s, starts_with(\"F\"))), numeric = TRUE)))\n    }() |&gt;\n    ## %&gt;% select(., all_of(str_sort(colnames(select(., starts_with('F'))), numeric = TRUE)))\n    write_csv(fout) ## automatically compress by readr\n}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Personal Projects",
    "section": "",
    "text": "HEMDAG: a meta-learning tool for predicting novel biomedical associations from ontology data\nobogaf-parser: a Perl module to parse biomedical ontology and gene association files"
  },
  {
    "objectID": "index.html#developed-software-libraries",
    "href": "index.html#developed-software-libraries",
    "title": "Personal Projects",
    "section": "",
    "text": "HEMDAG: a meta-learning tool for predicting novel biomedical associations from ontology data\nobogaf-parser: a Perl module to parse biomedical ontology and gene association files"
  },
  {
    "objectID": "index.html#contribution-to-open-source-software-libraries",
    "href": "index.html#contribution-to-open-source-software-libraries",
    "title": "Personal Projects",
    "section": "Contribution to open-source software libraries",
    "text": "Contribution to open-source software libraries\n\nIntegration of nextflow pipelines in the FGCZ’s cloud platform SUSHI (ATAC-Seq and CUT&RUN)\nDevelopment of a Ruby on Rails interface for CUT&RUN data analysis"
  },
  {
    "objectID": "index.html#genomics",
    "href": "index.html#genomics",
    "title": "Personal Projects",
    "section": "Genomics",
    "text": "Genomics\n\nIdentification of breast cancer subtypes via a graph-based approach"
  },
  {
    "objectID": "index.html#machine-learning",
    "href": "index.html#machine-learning",
    "title": "Personal Projects",
    "section": "Machine learning",
    "text": "Machine learning\n\nIdentifying biomarkers associated with weight loss using a Bayesian-optimized classifier\nPredicting housing prices in California\nPredicting biomarker status imputing missing values\nPredicting salary and new connections from network data\nPredicting viewer engagement with educational videos"
  },
  {
    "objectID": "index.html#deep-learning",
    "href": "index.html#deep-learning",
    "title": "Personal Projects",
    "section": "Deep learning",
    "text": "Deep learning\n\nPredicting protein subcellular localization from aminoacid sequences with PyTorch"
  },
  {
    "objectID": "index.html#ai-powered-tools",
    "href": "index.html#ai-powered-tools",
    "title": "Personal Projects",
    "section": "AI-powered tools",
    "text": "AI-powered tools\n\nDeveloping a RAG framework for bioinformatics applications"
  },
  {
    "objectID": "index.html#dataviz",
    "href": "index.html#dataviz",
    "title": "Personal Projects",
    "section": "DataViz",
    "text": "DataViz\n\nVisualization of Michigan’s temperature records\nVisualization of Detroit’s sports teams win percentages"
  },
  {
    "objectID": "cancer-subtypes.html",
    "href": "cancer-subtypes.html",
    "title": "Identification of breast cancer subtypes from bulk RNA-Seq data via a graph-based approach",
    "section": "",
    "text": "Getting data\nExploratory data analysis and preprocessing\nClustering analysis - an in-house approach\nClustering analysis - the Seurat way\nPredicting biomarker status imputing missing values"
  },
  {
    "objectID": "r0_getdata.html",
    "href": "r0_getdata.html",
    "title": "Downloading GEO data",
    "section": "",
    "text": "In this report, I download the 3409 breast cancer bulk RNA-seq samples and the corresponding clinical annotations, associated with the study: Clinical Value of RNA Sequencing-Based Classifiers for Prediction of the Five Conventional Breast Cancer Biomarkers: A Report From the Population-Based Multicenter Sweden Cancerome Analysis Network—Breast Initiative (GSE96058).\n\n\nif(!dir.exists(here::here('data')))\n  dir.create(here::here('data'))\n\n\n## get geo obj\ngeo &lt;- getGEO(GEO = \"GSE96058\", GSEMatrix = FALSE)\n\n## fetch metadata\nmeta &lt;- purrr::map(geo@gsms, ~.x@header$characteristics_ch1) |&gt;\n  stack() |&gt;\n  tidyr::separate(values, into = c(\"feature\", \"value\"), sep= \": \") |&gt;\n  tidyr::pivot_wider(names_from= feature, values_from = value) |&gt;\n  janitor::clean_names()\n\n## map samples\nsample &lt;- purrr::map(geo@gsms, ~.x@header$title) |&gt;\n  stack() |&gt;\n  as_tibble() |&gt;\n  mutate(ind = as.character(ind))\n\n## store metadata\nmeta &lt;- left_join(sample, meta, by = 'ind') |&gt;\n  write_csv(here::here(\"data/metadata.csv\"))\n\n\n\nsuccess &lt;- FALSE\nattempt &lt;- 1\nwhile (!success && attempt &lt;= 5) {\n  tryCatch({\n    getGEOSuppFiles(\"GSE96058\", makeDirectory = FALSE,\n                    baseDir = here::here('data'),\n                    fetch_files = TRUE, filter_regex = 'gene_expression')\n    success &lt;- TRUE\n    message(\"Download successful on attempt \", attempt)\n  }, error = function(e) {\n    message(\"Download failed on attempt \", attempt, \": \", e$message)\n    attempt &lt;&lt;- attempt + 1\n    Sys.sleep(5) # wait before retrying\n  })\n}\nif (!success)\n  stop(sprintf(\"Download failed after %s attempts\", attempt))"
  },
  {
    "objectID": "r0_getdata.html#aims",
    "href": "r0_getdata.html#aims",
    "title": "Downloading GEO data",
    "section": "",
    "text": "In this report, I download the 3409 breast cancer bulk RNA-seq samples and the corresponding clinical annotations, associated with the study: Clinical Value of RNA Sequencing-Based Classifiers for Prediction of the Five Conventional Breast Cancer Biomarkers: A Report From the Population-Based Multicenter Sweden Cancerome Analysis Network—Breast Initiative (GSE96058).\n\n\nif(!dir.exists(here::here('data')))\n  dir.create(here::here('data'))\n\n\n## get geo obj\ngeo &lt;- getGEO(GEO = \"GSE96058\", GSEMatrix = FALSE)\n\n## fetch metadata\nmeta &lt;- purrr::map(geo@gsms, ~.x@header$characteristics_ch1) |&gt;\n  stack() |&gt;\n  tidyr::separate(values, into = c(\"feature\", \"value\"), sep= \": \") |&gt;\n  tidyr::pivot_wider(names_from= feature, values_from = value) |&gt;\n  janitor::clean_names()\n\n## map samples\nsample &lt;- purrr::map(geo@gsms, ~.x@header$title) |&gt;\n  stack() |&gt;\n  as_tibble() |&gt;\n  mutate(ind = as.character(ind))\n\n## store metadata\nmeta &lt;- left_join(sample, meta, by = 'ind') |&gt;\n  write_csv(here::here(\"data/metadata.csv\"))\n\n\n\nsuccess &lt;- FALSE\nattempt &lt;- 1\nwhile (!success && attempt &lt;= 5) {\n  tryCatch({\n    getGEOSuppFiles(\"GSE96058\", makeDirectory = FALSE,\n                    baseDir = here::here('data'),\n                    fetch_files = TRUE, filter_regex = 'gene_expression')\n    success &lt;- TRUE\n    message(\"Download successful on attempt \", attempt)\n  }, error = function(e) {\n    message(\"Download failed on attempt \", attempt, \": \", e$message)\n    attempt &lt;&lt;- attempt + 1\n    Sys.sleep(5) # wait before retrying\n  })\n}\nif (!success)\n  stop(sprintf(\"Download failed after %s attempts\", attempt))"
  },
  {
    "objectID": "r2_clustering.html",
    "href": "r2_clustering.html",
    "title": "Identification of breast cancer subtypes",
    "section": "",
    "text": "The goal of this report is to identify breast cancer subtypes by using a graph-based approach. To this end, I built a K-nearest neighbor (KNN) graph, where each node is a patient connected to its nearest neighbors, in the high-dimensional space (i.e. I used the top 25 principal components and the top 3000 variable genes). Edges between patients are weighted based on the Jaccard similarity, the higher the weight the larger is their overlap in their local neighborhoods. I then applied the Louvain algorithm to identify patient communities, where patients in the same group are more strongly connected to each others compared to those in different groups (on the basis of gene expression profiles). Finally, I visualized the cluster distribution with t-SNE and UMAP and I labeled patients on the basis of status of 5 biomarkers (estrogen receptor (ER), progesterone receptor (PgR), human epidermal growth factor receptor 2 (HER2), Ki67, and Nottingham histologic grade (NHG)) to see if there are associations between patients communities and biomarker status."
  },
  {
    "objectID": "r2_clustering.html#aims",
    "href": "r2_clustering.html#aims",
    "title": "Identification of breast cancer subtypes",
    "section": "",
    "text": "The goal of this report is to identify breast cancer subtypes by using a graph-based approach. To this end, I built a K-nearest neighbor (KNN) graph, where each node is a patient connected to its nearest neighbors, in the high-dimensional space (i.e. I used the top 25 principal components and the top 3000 variable genes). Edges between patients are weighted based on the Jaccard similarity, the higher the weight the larger is their overlap in their local neighborhoods. I then applied the Louvain algorithm to identify patient communities, where patients in the same group are more strongly connected to each others compared to those in different groups (on the basis of gene expression profiles). Finally, I visualized the cluster distribution with t-SNE and UMAP and I labeled patients on the basis of status of 5 biomarkers (estrogen receptor (ER), progesterone receptor (PgR), human epidermal growth factor receptor 2 (HER2), Ki67, and Nottingham histologic grade (NHG)) to see if there are associations between patients communities and biomarker status."
  },
  {
    "objectID": "r2_clustering.html#methods",
    "href": "r2_clustering.html#methods",
    "title": "Identification of breast cancer subtypes",
    "section": "Methods",
    "text": "Methods\nDue to the presence of missing values (NA) in biomarker status (see Biomarkers Annotation), I explore these scenarios:\n\nClustering of all 3273 patients and annotation according to PAM50 subtypes (consensus histopathology labels​) provided in the metadata\nClustering of patients with complete annotations for all 5 biomarkers (1373 patients)\nClustering of patients separately for each biomarker (excluding NA)\n\nFor each clustering scenario, I considered the top 3000 genes that exhibit the highest patient-to-patient variation in the dataset (i.e, those genes that are highly expressed in some patients, and lowly expressed in others)."
  },
  {
    "objectID": "r2_clustering.html#results",
    "href": "r2_clustering.html#results",
    "title": "Identification of breast cancer subtypes",
    "section": "Results",
    "text": "Results\nOverall, the analysis suggests that patients stratify according to the 5 biomarkers, in particular according to ER and PgR status.\nLoading data\n\ngexp &lt;- read_csv(\n  'data/gene_expression_profile.csv.gz',\n  col_types = cols()\n)\n\nmeta &lt;- read_csv('data/metadata.csv', col_types = cols()) |&gt;\n  rename(sampleID = values, sampleName = ind) |&gt;\n  filter(sampleID %in% names(gexp)) |&gt;\n  mutate(\n    er_status = factor(er_status, levels = c(0, 1), labels = c(\"ER-\", \"ER+\")),\n    pgr_status = factor(pgr_status, levels = c(0, 1), labels = c(\"PgR-\", \"PgR+\")),\n    her2_status = factor(her2_status, levels = c(0, 1), labels = c(\"HER2-\", \"HER2+\")),\n    ki67_status = factor(ki67_status, levels = c(0, 1), labels = c(\"Ki67-\", \"Ki67+\")),\n    overall_survival_event = factor(overall_survival_event, levels = c(0, 1), labels = c(\"no survival\", \"survival\")),\n    endocrine_treated = factor(endocrine_treated, levels = c(0, 1), labels = c(\"no treated\", \"treated\")),\n    chemo_treated = factor(chemo_treated, levels = c(0, 1), labels = c(\"no treated\", \"treated\")),\n    lymph_node_group = factor(lymph_node_group),\n    lymph_node_status = factor(lymph_node_status),\n    pam50_subtype = factor(pam50_subtype),\n    nhg = factor(nhg)\n  )\n\n\nmd &lt;- meta |&gt; \n  column_to_rownames(var = 'sampleID')\n\nmx &lt;- gexp |&gt; \n  select(genes, rownames(md)) |&gt;\n  column_to_rownames(var = 'genes')\n\nBiomarkers Annotation\nPercentage of patients with a given annotation is reported for each biomarker.\n\nmeta_long &lt;- meta |&gt;\n  select(er_status, pgr_status, her2_status, ki67_status, nhg) |&gt;\n  pivot_longer(cols = everything(), names_to = \"biomarker\", values_to = \"status\")\n\ndf_counts &lt;- meta_long |&gt;\n  group_by(biomarker, status) |&gt;\n  summarise(n = n(), .groups = \"drop\") |&gt;\n  group_by(biomarker) |&gt;\n  mutate(perc = n / sum(n))\n\nggplot(df_counts, aes(x = biomarker, y = perc, fill = status)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(\n    aes(label = scales::percent(perc, accuracy = 1)),\n    position = position_stack(vjust = 0.5)\n  ) +\n  labs(x = \"\", y = \"\") +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  guides(fill = guide_legend(title = NULL)) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank()\n  )\n\n\n\n\n\n\n\nFunctions\nFunctions used to build the pipeline.\n\ntop_genes &lt;- function(mat, n_top = 500){\n  # use smallest between n_top and number of genes\n  n_top &lt;- min(n_top, nrow(mat))\n  # order by decreasing gene variance and slice\n  rv &lt;- matrixStats::rowVars(as.matrix(mat))\n  select_n &lt;- order(rv, decreasing = TRUE)[seq_len(n_top)]\n  mat &lt;- mat[select_n, ]\n  return(mat)\n}\n\nget_pc &lt;- function(mx, md){\n  pc &lt;- PCAtools::pca(mx, metadata = md, center = TRUE, scale = FALSE, removeVar = 0.1)\n  return(pc)\n}\n\nbuild_graph &lt;- function(pc, npc = 25, k = 20){\n  ## pc space\n  pcm &lt;- pc$rotated[, 1:npc]\n\n  # find k-nearest neighbors\n  knn_result &lt;- RANN::nn2(pcm, k = k)\n  knn_idx &lt;- knn_result$nn.idx\n  \n  # store sparse matrix triplets (i, j, value)\n  i_indices &lt;- c()\n  j_indices &lt;- c()\n  values &lt;- c()\n\n  npat &lt;- nrow(pcm)\n  # adj &lt;- matrix(0, npat, npat)\n\n  for (i in 1:npat){\n    for (j in knn_idx[i, ]){\n      if (i != j){ ## avoid self-loop\n        neighbors_i &lt;- knn_idx[i,]\n        neighbors_j &lt;- knn_idx[j,]\n        jaccard_sim &lt;- length(intersect(neighbors_i, neighbors_j)) / \n                       length(union(neighbors_i, neighbors_j)) ## union takes unique values\n\n        # Store indices and values for sparse matrix\n        i_indices &lt;- c(i_indices, i)\n        j_indices &lt;- c(j_indices, j)\n        values &lt;- c(values, jaccard_sim)\n        \n        # dense matrix \n        # adjt[i, j] &lt;- jaccard_sim\n      }\n    }\n  }\n\n  # Create sparse matrix using triplet format\n  adj &lt;- sparseMatrix(i = i_indices, j = j_indices, x = values, dims = c(npat, npat))\n\n  # build graph\n  g &lt;- graph_from_adjacency_matrix(adj,\n    mode = \"max\", ## preserve the strongest connections, same of adj &lt;- pmax(adj, t(adj))\n    weighted = TRUE\n  )\n  return(g)\n}\n\nfind_clusters &lt;- function(g, mx, resolution = 1){\n  # Louvain algorithm for community detection\n  louvain_communities &lt;- cluster_louvain(g, resolution = resolution)\n\n  # cluster assignment\n  clusters &lt;- membership(louvain_communities)\n\n  return(clusters)\n}\n\n## umap wrapper\numap &lt;- function(mx, ...){\n  defaults &lt;- list(\n    n_components = 2,\n    n_neighbors = 20,     ## as perplexity in t-SNE\n    min_dist = 0.1,       ## how tightly points cluster together\n    metric = \"euclidean\",\n    spread = 1,           ## global structure preservation\n    n_threads = 10\n  )\n  user_args &lt;- modifyList(defaults, list(...))\n  purrr::exec(uwot::umap, X = t(mx), !!!user_args)\n}\n\n## tsne wrapper\ntsne &lt;- function(mx, ...){\n  defaults &lt;- list(\n    dims = 2,\n    perplexity = 20,\n    num_threads = 10\n  )\n  user_args &lt;- modifyList(defaults, list(...))\n  purrr::exec(Rtsne::Rtsne, X = t(mx), !!!user_args)\n}\n\njoin_results &lt;- function(tib, pc, clusters){\n  if(is.list(tib)){ ## tsne returns a list ..\n    restib &lt;- tibble(\n      sample = rownames(pc$rotated),\n      cluster = as.factor(clusters),\n      tsne1 = tib$Y[, 1],\n      tsne2 = tib$Y[, 2]) |&gt;\n      left_join(meta, by = c('sample' = 'sampleID'))\n  }else{ ## .. umap a dataframe\n    restib &lt;- tibble(\n      sample = rownames(pc$rotated),\n      cluster = as.factor(clusters),\n      umap1 = tib[, 1],\n      umap2 = tib[, 2]) |&gt;\n      left_join(meta, by = c('sample' = 'sampleID'))\n  }\n  return(restib)\n}\n\nplot_clusters &lt;- function(tib, cluster = 'cluster', animate = FALSE){\n  dim1 &lt;- colnames(tib)[3]\n  dim2 &lt;- colnames(tib)[4]\n  \n  p &lt;- ggplot(tib, aes(x = !!sym(dim1), y = !!sym(dim2), color = !!sym(cluster))) +\n    geom_point(alpha = 0.7, size = 2) +\n    labs(title = str_replace(cluster, '_', ' '), x = dim1, y = dim2) +\n    theme_minimal()\n\n  if(!animate & cluster == 'cluster'){\n    # Calculate cluster centroids for label positioning\n    cluster_centers &lt;- tib |&gt;\n      group_by(!!sym(cluster)) |&gt;\n      summarise(\n        x_center = mean(!!sym(dim1), na.rm = TRUE),\n        y_center = mean(!!sym(dim2), na.rm = TRUE),\n        .groups = 'drop'\n      )\n    \n    p &lt;- p +\n      geom_text_repel(\n        data = cluster_centers,\n        aes(x = x_center, y = y_center, label = !!sym(cluster)),\n        color = \"black\",\n        size = 8,\n        fontface = \"bold\",\n        vjust = 0.5,\n        hjust = 0.5\n      )\n  }\n  return(p)\n}\n\nformatter &lt;- function(tib, cols_to_format = \"all\", digits = 3){\n  selector &lt;- if(length(cols_to_format) == 1 && cols_to_format == \"all\"){\n    where(is.numeric)\n  } else {\n    all_of(cols_to_format)\n  }\n\n  tib |&gt; \n    mutate(across({{ selector }},\n           ~format(., scientific = TRUE, digits = digits)))\n}\n\ndatatable &lt;- function(tib, row2display = 10) {\n  if(nrow(tib) &gt; 0){\n    DT::datatable(tib,\n      rownames   = FALSE,\n      extensions = \"Buttons\",\n      options    = list(\n        dom = \"Bfrtip\",\n        scrollX = TRUE,\n        pageLength = row2display,\n        buttons = list(\n          list(\n            extend  = \"collection\",\n            buttons = c(\"csv\", \"excel\"),\n            text    = \"Download\"\n          )\n        )\n      ),\n      class = \"display\",\n      style = \"bootstrap\"\n    )\n  }else{\n    print(\"No results\")\n  }\n}\n\nA. Clustering all patients\n\nmxtop &lt;- top_genes(mx, n_top = 3000)\npc &lt;- get_pc(mxtop, md)\ng &lt;- build_graph(pc, npc = 25, k = 20)\ncls &lt;- find_clusters(g, mxtop, resolution = 1)\n\nt-SNE\n\ntsneres &lt;- tsne(mxtop, perplexity = 20)\ntsnetib &lt;- join_results(tsneres, pc, cls)\n\nvars &lt;- c('cluster', 'pam50_subtype')\nplist &lt;- map(vars, ~plot_clusters(tsnetib, .x))\nwrap_plots(plist, ncol = 2)\n\n\n\n\n\n\n\nUMAP\n\numapres &lt;- umap(mxtop, n_neighbors = 20, spread = 1)\numaptib &lt;- join_results(umapres, pc, cls)\n\nvars &lt;- c('cluster', 'pam50_subtype')\nplist &lt;- map(vars, ~plot_clusters(umaptib, .x))\nwrap_plots(plist, ncol = 2)\n\n\n\n\n\n\n\nPatient cluster assignment\nThe table below shows the obtained cluster assignment for each patient.\n\ntsnetib |&gt; \n  left_join(umaptib, by = 'sample', suffix=c('_tsne', '_umap')) |&gt;\n  select(sample, sampleName_tsne, cluster_tsne, \n    tsne1, tsne2, umap1, umap2,\n    tumor_size_tsne, lymph_node_group_tsne,\n    lymph_node_status_tsne, er_status_tsne,\n    pgr_status_tsne, her2_status_tsne,\n    ki67_status_tsne, nhg_tsne, pam50_subtype_tsne,\n    overall_survival_days_tsne, overall_survival_event_tsne,\n    endocrine_treated_tsne, chemo_treated_tsne) |&gt;\n  rename_with(~ str_remove(.x, \"_tsne$\")) |&gt;\n  formatter(cols_to_format = c(\"tsne1\", \"tsne2\", \"umap1\", \"umap2\")) |&gt;\n  datatable()\n\n\n\n\n\nB. Clustering of patients with complete annotations for all 5 biomarkers\n\n## reduce dataset to complete cases \nmd_complete &lt;- meta |&gt;\n  filter(!is.na(er_status)   & !is.na(pgr_status) & \n         !is.na(her2_status) & !is.na(ki67_status) &\n         !is.na(nhg)) |&gt;\n  column_to_rownames(var = 'sampleID')       \n\nmx_complete &lt;- gexp |&gt; \n    select(genes, rownames(md_complete)) |&gt;\n    column_to_rownames(var = 'genes')\n\n\n## run pipeline\nmxtop_complete &lt;- top_genes(mx_complete, n_top = 3000)\npc_complete &lt;- get_pc(mxtop_complete, md_complete)\ng_complete &lt;- build_graph(pc_complete, npc = 25, k = 20)\ncls_complete &lt;- find_clusters(g_complete, mxtop_complete, resolution = 1)\n\nt-SNE\n\nvars &lt;- c('cluster', 'er_status', 'pgr_status', 'her2_status', 'ki67_status', 'nhg')\n\n## tsne\ntsneres_complete &lt;- tsne(mxtop_complete, perplexity = 20)\ntsnetib_complete &lt;- join_results(tsneres_complete, pc_complete, cls_complete)\n\nplist &lt;- map(vars, ~plot_clusters(tsnetib_complete, .x))\nwrap_plots(plist, ncol = 2)\n\n\n\n\n\n\n\nUMAP\n\numapres_complete &lt;- umap(mxtop_complete, n_neighbors = 20, spread = 1)\numaptib_complete &lt;- join_results(umapres_complete, pc_complete, cls_complete)\n\nplist &lt;- map(vars, ~plot_clusters(umaptib_complete, .x))\nwrap_plots(plist, ncol = 2)\n\n\n\n\n\n\n\nC. Clustering of patients separately for each biomarker\n\nbiomarkers &lt;- c('er_status', 'pgr_status', 'her2_status', 'ki67_status', 'nhg')\n\ntsnetib_bm &lt;- list()\numaptib_bm &lt;- list()\n\nptsne &lt;- list()\npumap &lt;- list()\n\nfor(biomarker in biomarkers){\n  ## remove not annotated patients\n  md_bm &lt;- meta |&gt;\n    filter(!is.na(!!sym(biomarker))) |&gt;\n    column_to_rownames(var = 'sampleID')\n\n  mx_bm &lt;- gexp |&gt; \n    select(genes, rownames(md_bm)) |&gt;\n    column_to_rownames(var = 'genes')\n\n  ## clustering\n  mxtop_bm &lt;- top_genes(mx_bm, n_top = 3000)\n  pc_bm &lt;- get_pc(mxtop_bm, md_bm)\n  g_bm &lt;- build_graph(pc_bm, npc = 25, k = 20)\n  cls_bm &lt;- find_clusters(g_bm, mxtop_bm, resolution = 1)\n\n  ## save results\n  tsneres_bm &lt;- tsne(mxtop_bm, perplexity = 20)\n  tsnetib_bm[[biomarker]] &lt;- join_results(tsneres_bm, pc_bm, cls_bm)\n\n  umapres_bm &lt;- umap(mxtop_bm,  n_neighbors = 20)\n  umaptib_bm[[biomarker]] &lt;- join_results(umapres_bm, pc_bm, cls_bm)\n\n  vars &lt;- c('cluster', biomarker)\n  ptsne[[biomarker]] &lt;- map(vars, ~plot_clusters(tsnetib_bm[[biomarker]], .x))\n  pumap[[biomarker]] &lt;- map(vars, ~plot_clusters(umaptib_bm[[biomarker]], .x))\n}\n\nt-SNE\n\npwrap &lt;- map(ptsne, ~.x[[1]] + .x[[2]])\nwrap_plots(pwrap, ncol = 1)\n\n\n\n\n\n\n\nUMAP\n\npwrap &lt;- map(pumap, ~.x[[1]] + .x[[2]])\nwrap_plots(pwrap, ncol = 1)\n\n\n\n\n\n\n\nClustering at different resolutions\nClusters detected at each resolutions are marked in different colors. Patients in the community colored in red tend to cluster together at different resolutions, suggesting that patients within this community are strongly connected (similar expression profiles).\n\n# loop for resolutions\nresolutions &lt;- c(0.1, 0.3, 0.6, 1, 1.5)\n\ntsne_tune &lt;- map_dfr(resolutions, function(resolution){\n  cls &lt;- find_clusters(g, mxtop, resolution = resolution) \n  tsne &lt;- tsne(mxtop, dims = 2, perplexity = 20)\n  tibble(\n    sample = colnames(mxtop),\n    cluster = as.factor(cls),\n    tsne1 = tsne$Y[, 1],\n    tsne2 = tsne$Y[, 2],\n    resolution = resolution,\n    ncl = length(unique(cls)) ## number of clusters at a given resolution\n  ) |&gt;\n  left_join(meta, by = c('sample' = 'sampleID'))\n})\n\n# {unique(tsne_tune$ncl[tsne_tune$resolution == closest_state])}\nncl_lookup &lt;- tsne_tune |&gt; distinct(resolution, ncl) |&gt; deframe()\n\nplot &lt;- plot_clusters(tsne_tune, cluster = 'cluster', animate = TRUE) +\n  # theme(legend.position=\"none\") +\n  labs(subtitle = \"Resolution: {closest_state} | Clusters: {ncl_lookup[as.character(closest_state)]}\") +\n  transition_states(resolution, transition_length = 5, state_length = 3) +\n  ease_aes(\"linear\")\n\nanimate(\n  plot,\n  width = 8,\n  height = 6,\n  res = 100,\n  nframes = 300,\n  fps = 30,\n  device = \"ragg_png\",\n  renderer = gifski_renderer()\n)\n\n\n\n\n\n\n\nWhen specifically coloring patients based on ER status, we observe that the expression profiles of ER- patients cluster well. Furthermore, it is worth noting that the status of some patients within this cluster is unknown (gray patients). These might be considered as ER- patients since they cluster strongly with patients annotated as ER-.\n\nplot &lt;- plot_clusters(tsne_tune, cluster = 'er_status', animate = TRUE) +\n  labs(subtitle = \"Resolution: {closest_state} | Clusters: {ncl_lookup[as.character(closest_state)]}\") +\n  transition_states(resolution, transition_length = 5, state_length = 3) +\n  ease_aes(\"linear\")\n\nanimate(\n  plot,\n  width = 8,\n  height = 6,\n  res = 100,\n  nframes = 300,\n  fps = 30,\n  device = \"ragg_png\",\n  renderer = gifski_renderer()\n)"
  },
  {
    "objectID": "r2_clustering.html#conclusions",
    "href": "r2_clustering.html#conclusions",
    "title": "Identification of breast cancer subtypes",
    "section": "Conclusions",
    "text": "Conclusions\nI identified breast cancer subtypes based on gene expression data via a graph-based approach. Two main distinct clusters of patients are detected. The smaller cluster is enriched for ER- patients and likely represent the most aggressive expression profile (basal PAM50 subtype, e.g. G3, PgR-, ER-, HER-)."
  },
  {
    "objectID": "r2_clustering.html#next-step",
    "href": "r2_clustering.html#next-step",
    "title": "Identification of breast cancer subtypes",
    "section": "Next step",
    "text": "Next step\nCluster assignment can be used as features in a supervised learning approach to predict biomarker status (such as random forest, support vector machine, label propagation). Furthermore, we can use LLMs to further validate biological insights using AI-powered tools tailored for bioinformatics resources such as ExpasyGPT."
  },
  {
    "objectID": "biomarker-discovery-ornish.html",
    "href": "biomarker-discovery-ornish.html",
    "title": "Identifying gene expression biomarkers associated with weight loss using Bayesian-optimized XGBoost",
    "section": "",
    "text": "The goal of this project is to find gene biomarker for weight loss response."
  },
  {
    "objectID": "biomarker-discovery-ornish.html#goal",
    "href": "biomarker-discovery-ornish.html#goal",
    "title": "Identifying gene expression biomarkers associated with weight loss using Bayesian-optimized XGBoost",
    "section": "",
    "text": "The goal of this project is to find gene biomarker for weight loss response."
  },
  {
    "objectID": "biomarker-discovery-ornish.html#dataset",
    "href": "biomarker-discovery-ornish.html#dataset",
    "title": "Identifying gene expression biomarkers associated with weight loss using Bayesian-optimized XGBoost",
    "section": "Dataset",
    "text": "Dataset\nI downloaded the Ornish dataset from the MEvA-X tool. This dataset is already normalized and contains microarry gene expression, with information of Age, Gender, COPD, Diabetes, and WeightLoss, making 13’520 features on 89 participants. WeightLoss is a binary variable: Responders for participants with a weight loss higher than 10% and Non_responders otherwise.\n\nimport pandas as pd\n\n## diet dataset\nornish_url = 'https://raw.githubusercontent.com/PanKonstantinos/MEvA-X/refs/heads/main/Data/Ornish/diet_dataset.txt'\n\ndf = pd.read_csv(ornish_url, sep='\\t', index_col=0).T\n\nif (df.isna().any().any()):\n  df.dropna(axis=0, inplace=True)\n\n## response variables\nlabels_url = 'https://raw.githubusercontent.com/PanKonstantinos/MEvA-X/refs/heads/main/Data/Ornish/diet_labels.txt'\n\nlabels = pd.read_csv(labels_url, sep='\\t', header=None, index_col=None).T\nlabels.columns = ['WeightLoss']\nlabels.set_index(df.index, inplace=True)\n\n## concatenate\ndf = df.join(labels)\n\ndf\n\n\n\n\n\n\n\n\nA1CF\nA2M\nA4GALT\nA4GNT\nAAAS\nAACS\nAADAC\nAAGAB\nAAK1\nAAMDC\n...\nZXDB\nZXDC\nZYX\nZZEF1\nZZZ3\nAge\nSex\nCOPD\nDiabetes\nWeightLoss\n\n\n\n\nGSM1123226\n1.997137\n2.927813\n3.379954\n3.118075\n4.511405\n4.087969\n2.214993\n4.288835\n3.572398\n3.250973\n...\n2.020369\n5.075711\n6.088010\n4.226737\n5.179565\n-0.648705\n0.0\n1.0\n0.0\nNon_responders\n\n\nGSM1123229\n1.977951\n2.815217\n3.554587\n3.421110\n3.975408\n3.698030\n2.135038\n4.303349\n3.600629\n3.562200\n...\n2.151221\n4.695243\n5.209147\n4.173184\n4.658188\n-0.988535\n1.0\n0.0\n0.0\nResponders\n\n\nGSM1123232\n2.000448\n2.699376\n3.859986\n3.109845\n4.412049\n3.750196\n1.999807\n4.254621\n3.444927\n3.533278\n...\n2.090296\n4.818034\n6.367867\n3.945843\n4.634515\n-0.412100\n0.0\n0.0\n0.0\nResponders\n\n\nGSM1123235\n2.163751\n2.597491\n3.735692\n3.248038\n4.336756\n3.884665\n2.133586\n3.978215\n3.238115\n3.383351\n...\n2.000901\n4.682398\n6.498289\n3.810110\n4.363320\n-0.714815\n1.0\n1.0\n1.0\nResponders\n\n\nGSM1123238\n2.264534\n2.766004\n3.839986\n3.389460\n4.405672\n3.635781\n2.041702\n4.077370\n3.724022\n3.518026\n...\n2.227170\n4.376936\n5.653432\n4.091409\n3.860758\n-0.064151\n0.0\n0.0\n0.0\nResponders\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nGSM1616361\n2.608056\n2.817870\n3.858801\n3.601149\n4.439976\n4.121827\n2.517568\n4.439015\n3.657229\n3.683177\n...\n1.713461\n4.850360\n6.023210\n4.395596\n4.460750\n-0.634787\n1.0\n1.0\n0.0\nNon_responders\n\n\nGSM1616364\n2.208693\n3.098871\n4.042131\n3.798330\n4.405658\n4.081275\n1.812455\n4.774171\n4.071347\n3.866862\n...\n2.295336\n4.973385\n6.293176\n4.548602\n4.769321\n0.175933\n1.0\n1.0\n1.0\nNon_responders\n\n\nGSM1616370\n1.971933\n2.823615\n3.955895\n3.419127\n4.502783\n3.839190\n2.568179\n4.230036\n3.708654\n3.529116\n...\n1.678471\n4.427966\n5.851469\n4.268339\n4.546185\n-0.417899\n1.0\n1.0\n1.0\nResponders\n\n\nGSM1616373\n1.921041\n2.939931\n3.601237\n2.947529\n4.007231\n3.736109\n1.795098\n3.795344\n3.311513\n3.109000\n...\n1.836781\n4.494768\n5.271502\n3.805281\n4.191898\n-0.434137\n1.0\n0.0\n1.0\nNon_responders\n\n\nGSM1616377\n1.729271\n2.051417\n2.832809\n3.151458\n3.748911\n3.486162\n2.390095\n3.956252\n3.044997\n2.497994\n...\n2.468296\n4.472736\n5.200838\n3.603701\n3.475989\n0.428776\n0.0\n1.0\n0.0\nNon_responders\n\n\n\n\n89 rows × 13520 columns\n\n\n\nThen I encode WeightLoss to numeric [0,1] values\n\nX = df.drop(columns=['WeightLoss'])\n\nmapping = {'Non_responders': 0, 'Responders':1}\nY = df['WeightLoss'].map(mapping)\n\nprint(X.shape)\nprint(Y.value_counts())\n\n(89, 13519)\nWeightLoss\n1    54\n0    35\nName: count, dtype: int64"
  },
  {
    "objectID": "biomarker-discovery-ornish.html#exploratory-data-analysis",
    "href": "biomarker-discovery-ornish.html#exploratory-data-analysis",
    "title": "Identifying gene expression biomarkers associated with weight loss using Bayesian-optimized XGBoost",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nGene expression profile over participants\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(12, 6))\n\n# plot density for each sample\nfor i in range(X.shape[0]):\n  sns.kdeplot(X.iloc[i,:], bw_adjust=0.5, fill=True, alpha=0.5)\n\nplt.title('Density of Gene expression')\nplt.xlabel('Gene expression level')\nplt.ylabel('Density')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nPCA on gene expression data showing the distribution of participants colored by response status along the first two principal components.\n\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# PCA\npca = PCA()\nX_pca = pca.fit_transform(X_scaled)\n\n# scatter plot of the first two principal components\nplt.figure(figsize=(10, 8))\n\nlabels = Y\ninv_mapping = {v: k for k, v in mapping.items()}\nplt.scatter(X_pca[labels==0, 0], X_pca[labels==0, 1], color='steelblue', label=inv_mapping[0])\nplt.scatter(X_pca[labels==1, 0], X_pca[labels==1, 1], color='orange', label=inv_mapping[1])\nplt.legend()\n\nplt.xlabel('PC1 ({:.2f}%)'.format(pca.explained_variance_ratio_[0] * 100))\nplt.ylabel('PC2 ({:.2f}%)'.format(pca.explained_variance_ratio_[1] * 100))\n\nplt.show()"
  },
  {
    "objectID": "biomarker-discovery-ornish.html#quick-and-dirty-approach",
    "href": "biomarker-discovery-ornish.html#quick-and-dirty-approach",
    "title": "Identifying gene expression biomarkers associated with weight loss using Bayesian-optimized XGBoost",
    "section": "Quick and dirty approach",
    "text": "Quick and dirty approach\nI built a ‘vanilla’ XGBoost model without exploring the hyperparameter space to see how a baseline model behaves. The workflow included:\n\nfeature selection using mutual information (MI) to identify the top 300 genes most correlated with weight loss\nperformance evaluation with AUROC and AUPRC\nmodel interpretation with SHAP values\n\nNote: I did not scale data because MI and tree-based methods (as XGBoost) are invariant to scale. Moreover, the dataset is already normalized.\n\nSplitting the dataset in training and test set\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n\n\n\nFeature selection by MI\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif\n\n# get top genes\nselector = SelectKBest(mutual_info_classif, k=300)\nselector.fit(X_train, y_train)\n\n# get top features\nfeature_index = selector.get_support(indices=True)\nall_features = X_train.columns\nselected_features = all_features[feature_index]\n\n# build datasets with top features\nX_train_filtered = pd.DataFrame(selector.transform(X_train),\n                                columns=selected_features,\n                                index=X_train.index)\n\nX_test_filtered = pd.DataFrame(selector.transform(X_test),\n                               columns=selected_features,\n                               index=X_test.index)\n\n\n\nTraining and evaluating XGBoost\n\nfrom sklearn.metrics import roc_auc_score, average_precision_score\nimport xgboost as xgb \n\n# train XGBoost\nxgb_model = xgb.XGBClassifier(\n  n_estimators=100, \n  max_depth=3,\n  eta=0.5,\n  # early_stopping_rounds=10,\n  eval_metric='aucpr' ## auc\n)\n\n# fit model\nxgb_model.fit(\n  X_train_filtered, y_train, \n  # eval_set=[(X_train_filtered, y_train),(X_test_filtered, y_test)],\n  verbose=False\n)\n\nauroc = roc_auc_score(y_test, xgb_model.predict_proba(X_test_filtered)[:, 1])\nprint(f\"AUROC: {auroc:.4f}\")\n\nauprc = average_precision_score(y_test, xgb_model.predict_proba(X_test_filtered)[:, 1])\nprint(f\"AUPRC: {auprc:.4f}\")\n\nAUROC: 0.5921\nAUPRC: 0.8260\n\n\n\n\nXGBoost interpretability\nThe plot below shows the contribute of the top biomarkers to weight loss.\nEach dot represents a participant, while the color indicates gene expression level. Darker blue indicates lower expression, while darker red indicates higher expression.\nPositive SHAP values indicate a higher probability of a participant of being a responder (weight loss), while negative SHAP values indicate a higher probability of being a non-responder (no weight loss).\nLooking at the plot, we can conclude for example that participants with low levels of CDH13 and high levels of PIK3R2 and PSMC2 are associated with weight loss.\n\nimport shap\n\nexplainer = shap.Explainer(xgb_model)\nshap_values = explainer(X_train_filtered)\nshap.plots.beeswarm(shap_values)\n\n\n\n\n\n\n\n\n\nshap.plots.violin(shap_values, max_display=10)\n\n\n\n\n\n\n\n\nBelow we show the importance of the top biomarkers in predicting weight loss response.\n\nshap.plots.bar(shap_values)"
  },
  {
    "objectID": "biomarker-discovery-ornish.html#tuning-xgboost-hyperparameters",
    "href": "biomarker-discovery-ornish.html#tuning-xgboost-hyperparameters",
    "title": "Identifying gene expression biomarkers associated with weight loss using Bayesian-optimized XGBoost",
    "section": "Tuning XGBoost hyperparameters",
    "text": "Tuning XGBoost hyperparameters\nStarting from the ‘vanilla’ XGBoost model, I tuned the relevant hyperparameters using Bayesian optimization. To prevent data leakage, the supervised feature selection was performed within the cross-validation. Folds were stratified to balance participants labeled with the responder and non-responder class. As expected, the tuned XGBoost version outperformed the ‘vanilla’ baseline.\n\nimport warnings\n## ignore: UserWarning: pkg_resources is deprecated as an API\nwarnings.filterwarnings('ignore', category=UserWarning, module='hyperopt.atpe') \n\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nimport multiprocessing\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, pyll, STATUS_OK, Trials, space_eval\n\ndef build_pipeline(params):\n  pipeline = Pipeline([\n    ('feature_selection', SelectKBest(mutual_info_classif, k=300)),\n    ('classifier',\n      xgb.XGBClassifier( \n        n_jobs=multiprocessing.cpu_count()-2,\n        random_state=0,\n        **params\n      )\n    )\n  ])\n  return pipeline\n\ndef hyperopt_pipeline(params):\n  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n        \n  model = build_pipeline(params)\n  \n  losses = -cross_val_score(model, X_train, y_train,\n                            scoring='average_precision', cv=skf) ## roc_auc\n\n  return {\n    'loss': np.mean(losses),\n    'loss_variance': np.var(losses),\n    'status': STATUS_OK\n  }\n\n\nhyperspace = {\n  'eta': hp.loguniform('eta' , np.log(10**-2) , np.log(1)),\n  'subsample': hp.uniform('subsample', 0.3, 1),\n  'n_estimators': pyll.scope.int(hp.quniform('n_estimators', 1, 1000, 1)),\n  'max_depth': pyll.scope.int(hp.quniform('max_depth', 3, 15, 1))\n}\n\ntrials = Trials()\n\nbest = fmin(hyperopt_pipeline, hyperspace, \n            algo=tpe.suggest, \n            max_evals=10,\n            trials=trials,\n            # https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.random.html\n            rstate=np.random.default_rng(0))  ## important for reproducibility \n\n100%|██████████| 10/10 [12:49&lt;00:00, 76.98s/trial, best loss: -0.8078696700125271]\n\n\n\nFit the best model\n\nbest_params = space_eval(hyperspace, best)\nbest_model = build_pipeline(best_params)\nbest_model.fit(X_train, y_train)\n\nauroc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\nprint(f\"AUROC: {auroc:.4f}\")\n\nauprc = average_precision_score(y_test, best_model.predict_proba(X_test)[:, 1])\nprint(f\"AUPRC: {auprc:.4f}\")\n\nAUROC: 0.6118\nAUPRC: 0.8358\n\n\n\n\nXGBoost interpretability\nMost of the top biomarkers identified by the baseline and tuned models overlap (CDH13, HADHAP1, PIK3R2, RRP15, PSMC2, MYLK3), though their rankings differ (except for CDH13 which ranks first in both). However, the tuned model better clusters participants with high versus low gene expression, suggesting more robust predictions.\n\nselector = best_model.named_steps['feature_selection']\nclassifier = best_model.named_steps['classifier']\n\ntop_feat_idx = X_train.columns[selector.get_support()]\nX_train_filtered = pd.DataFrame(selector.transform(X_train), \n                                columns=top_feat_idx,\n                                index=X_train.index)\n\nexplainer = shap.Explainer(classifier)\nshap_values = explainer(X_train_filtered)\n\nshap.plots.beeswarm(shap_values)\n\n\n\n\n\n\n\n\n\nshap.plots.violin(shap_values, max_display=10)\n\n\n\n\n\n\n\n\n\nshap.plots.bar(shap_values)"
  },
  {
    "objectID": "biomarker-discovery-ornish.html#xgboost-versus-random-forest",
    "href": "biomarker-discovery-ornish.html#xgboost-versus-random-forest",
    "title": "Identifying gene expression biomarkers associated with weight loss using Bayesian-optimized XGBoost",
    "section": "XGBoost versus Random Forest",
    "text": "XGBoost versus Random Forest\nI also compared two tree-based approaches XGBoost and Random Forest. In this dataset, XGBoost outperformed Random Forest as it showed lower loss over trials.\n\nimport sklearn.ensemble as rf\n\ndef build_model_pipeline(classifier='xgboost', params=hyperspace):\n    \n  if classifier == 'xgboost':\n    model = Pipeline([\n    ('feature_selection', SelectKBest(mutual_info_classif, k=300)),\n    ('classifier',\n      xgb.XGBClassifier( \n        n_jobs=multiprocessing.cpu_count()-2,\n        random_state=0,\n        **params\n      )\n    )\n  ])\n  else:\n    model = Pipeline([\n      ('feature_selection', SelectKBest(mutual_info_classif, k=300)),\n      ('classifier',\n        rf.RandomForestClassifier( \n          n_jobs=multiprocessing.cpu_count()-2,\n          random_state=0,\n          **params\n        )\n      )\n    ])\n\n  return model\n\ndef hyperopt_model_pipeline(params):\n    \n  skf = StratifiedKFold(n_splits=5, shuffle=True , random_state=0)\n  \n  classifier = params.pop('classifier_type')\n  model = None\n\n  if classifier == 'xgboost':\n    model = build_model_pipeline(classifier='xgboost', params=params)\n  else:\n    model = build_model_pipeline(classifier='rf', params=params)\n  \n  losses = -cross_val_score(model, X_train, y_train,\n                            scoring = 'average_precision', cv = skf) ## roc_auc\n      \n  return{\n    'loss': np.mean(losses),\n    'loss_variance' : np.var(losses),\n    'status': STATUS_OK\n  }\n\n\n%%time\n\nhyperspace = hp.choice('classifier_type',\n  [{'classifier_type': 'xgboost',\n    'n_estimators': pyll.scope.int(hp.quniform('xgb_n_estimators', 1 , 1000, 1)),\n    'max_depth': pyll.scope.int(hp.quniform('xgb_max_depth', 1, 16, 1)),\n    'eta': hp.loguniform('eta' , np.log(10**-4) , np.log(1)),\n    'subsample': hp.uniform('subsample', 0.3, 1)\n  },\n\n  {'classifier_type': 'rf',\n    'n_estimators': pyll.scope.int(hp.quniform('rf_n_estimators', 1 , 1000, 1)),\n    'max_depth': pyll.scope.int(hp.quniform('rf_max_depth', 1, 16, 1)),\n    'min_samples_split': pyll.scope.int(hp.quniform('min_samples_split', 2, 8, 1)),\n    'min_samples_leaf': pyll.scope.int(hp.quniform('min_samples_leaf', 1, 32, 1))\n  }\n])\n\ntrials = Trials()\n\nbest = fmin(hyperopt_model_pipeline, \n            hyperspace, \n            algo=tpe.suggest, \n            max_evals=10, \n            trials=trials,\n            rstate=np.random.default_rng(0))\n\n100%|██████████| 10/10 [13:27&lt;00:00, 80.76s/trial, best loss: -0.808512677798392]\nCPU times: user 14min 4s, sys: 3.24 s, total: 14min 7s\nWall time: 13min 27s\n\n\n\nax = sns.scatterplot(x =  range(len(trials.losses())) ,  \n                     y =  trials.losses() , \n                     hue = np.array(['xgboost','random forest'])[trials.vals['classifier_type']] )\nax.set_xlabel('trials')\nax.set_ylabel('loss')\n\nText(0, 0.5, 'loss')"
  },
  {
    "objectID": "detroit-wiki.html",
    "href": "detroit-wiki.html",
    "title": "Visualization of Detroit’s sports teams win percentages",
    "section": "",
    "text": "How have the win percentages for Detroit’s major sports teams (Pistons, Red Wings, Tigers, and Lions) changed over the past 80 years using a 10-year sliding window?\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom packaging.version import Version\n\n\n\n\ndatasets={\n    'pistons':  'https://en.wikipedia.org/wiki/List_of_Detroit_Pistons_seasons',\n    'redwings': 'https://en.wikipedia.org/wiki/List_of_Detroit_Red_Wings_seasons',\n    'tiger':    'https://en.wikipedia.org/wiki/List_of_Detroit_Tigers_seasons',\n    'lions':    'https://en.wikipedia.org/wiki/List_of_Detroit_Lions_seasons'\n}\n\n\n\n\n\ndef get_window_and_winratio(df, window=10, team='Pistons'):\n    df['Window'] = (df['Year'] // window) * window\n    if team == 'RedWings' or team == 'Lions':\n        df = df.groupby('Window').agg({'Wins': 'sum', 'Losses': 'sum', 'Ties': 'sum'}).reset_index()\n        df['WinRatio'] = (df['Wins'] + 0.5 * df['Ties']) / (df['Wins'] + df['Losses'] + df['Ties'])\n    else:\n        df = df.groupby('Window').agg({'Wins': 'sum', 'Losses': 'sum'}).reset_index()\n        df['WinRatio'] = df['Wins'] / (df['Wins'] + df['Losses'])\n    df.columns = [col + '_' + team if col != 'Window' else col for col in df.columns]\n    return df\n\n\n\n\n\n# pd.set_option('display.max_rows', None)\n# pd.reset_option('display.max_rows')\n\nwiki_pistons = pd.read_html(datasets['pistons'])[1][1:]\n\npistons = pd.DataFrame()\npistons['Year'] = wiki_pistons['Team'].str[:4]\npistons[['Wins','Losses']] = wiki_pistons[['Wins','Losses']]\npistons = pistons[~(pistons['Year'].str.contains('Fort|Detr'))]\npistons[['Year', 'Wins', 'Losses']] = pistons[['Year', 'Wins', 'Losses']].astype(int)\npistons\n\n\n\n\n\n\n\n\nYear\nWins\nLosses\n\n\n\n\n1\n1941\n15\n9\n\n\n2\n1942\n17\n6\n\n\n3\n1943\n18\n4\n\n\n4\n1944\n25\n5\n\n\n5\n1945\n26\n8\n\n\n...\n...\n...\n...\n\n\n82\n2020\n20\n52\n\n\n83\n2021\n23\n59\n\n\n84\n2022\n17\n65\n\n\n85\n2023\n14\n68\n\n\n86\n2024\n44\n38\n\n\n\n\n84 rows × 3 columns\n\n\n\n\n\n\n\n# pd.set_option('display.max_rows', None)\n# pd.reset_option('display.max_rows')\n\nwiki_redwings = pd.read_html(datasets['redwings'])[2][1:]\n\nredwings = pd.DataFrame()\nredwings['Year'] = wiki_redwings['NHL season']['NHL season'].str[:4]\nredwings[['GP', 'Wins','Losses', 'Ties', 'OT']] = wiki_redwings['Regular season[3][6][7][8]'][['GP','W','L','T','OT']]\nredwings = redwings[~((redwings['Year'].str.contains('^Detr|^Tota')) |\n                      (redwings['Wins'].str.contains('^—')) |\n                      (redwings['Losses'].str.contains('^—')) |\n                      (redwings['Ties'].str.contains('^—\\[m\\]')))]\n\nredwings['OT'] = redwings['OT'].str.replace('\\[k\\]','', regex=True)\nredwings['Ties'] = redwings['Ties'].apply(lambda x: 0 if x == '—' else x) # redwings.loc[redwings['Ties'] == '—', 'Ties'] = 0\nredwings['OT']   = redwings['OT'].apply(lambda x: 0 if x == '—' else x)   # redwings.loc[redwings['OT'] == '—', 'OT'] = 0\n\nredwings[['Year', 'Wins', 'Losses', 'Ties', 'OT']] = redwings[['Year', 'Wins', 'Losses', 'Ties', 'OT']].astype(int)\nredwings['Ties'] = redwings['Ties'] + redwings['OT']\nredwings = redwings[['Year', 'Wins', 'Losses', 'Ties']]\nredwings\n\n\n\n\n\n\n\n\nYear\nWins\nLosses\nTies\n\n\n\n\n1\n1926\n12\n28\n4\n\n\n2\n1927\n19\n19\n6\n\n\n3\n1928\n19\n16\n9\n\n\n4\n1929\n14\n24\n6\n\n\n6\n1930\n16\n21\n7\n\n\n...\n...\n...\n...\n...\n\n\n97\n2020\n19\n27\n10\n\n\n98\n2021\n32\n40\n10\n\n\n99\n2022\n35\n37\n10\n\n\n100\n2023\n41\n32\n9\n\n\n101\n2024\n39\n35\n8\n\n\n\n\n97 rows × 4 columns\n\n\n\n\n\n\n\n# pd.set_option('display.max_rows', None)\n# pd.reset_option('display.max_rows')\n\nwiki_tiger = pd.read_html(datasets['tiger'])[1]\n\ntiger = pd.DataFrame()\ntiger['Year'] = wiki_tiger['Season']\ntiger[['Wins','Losses']] = wiki_tiger[['Wins','Losses']]\n\ntiger = tiger[~(tiger['Year'].str.contains('Total'))]\ntiger[['Year', 'Wins', 'Losses']] = tiger[['Year', 'Wins', 'Losses']].astype(int)\n\ntiger\n\n\n\n\n\n\n\n\nYear\nWins\nLosses\n\n\n\n\n0\n1901\n74\n61\n\n\n1\n1902\n52\n83\n\n\n2\n1903\n65\n71\n\n\n3\n1904\n62\n90\n\n\n4\n1905\n79\n74\n\n\n...\n...\n...\n...\n\n\n120\n2020\n23\n35\n\n\n121\n2021\n77\n85\n\n\n122\n2022\n66\n96\n\n\n123\n2023\n78\n84\n\n\n124\n2024\n86\n76\n\n\n\n\n125 rows × 3 columns\n\n\n\n\n\n\n\n# pd.set_option('display.max_rows', None)\n# pd.reset_option('display.max_rows')\n\npd_version = Version(pd.__version__)\n\nwiki_lions = pd.read_html(datasets['lions'])[1]\n\nlions = pd.DataFrame()\nlions['Year'] = wiki_lions['Season'][['Season']]\nif pd_version &lt;=  Version(\"1.5.2\"):\n    lions[['Wins','Losses', 'Ties']] = wiki_lions['Regular season'][['.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}W', 'L', 'T']]\nelse:\n    lions[['Wins','Losses', 'Ties']] = wiki_lions['Regular season'][['W', 'L', 'T']]\nlions = lions[~(lions['Year'].str.startswith('Totals'))]\nlions[['Year', 'Wins', 'Losses', 'Ties']] = lions[['Year', 'Wins', 'Losses', 'Ties']].astype(int)\n\nlions\n\n\n\n\n\n\n\n\nYear\nWins\nLosses\nTies\n\n\n\n\n0\n1928\n9\n3\n2\n\n\n1\n1929\n12\n2\n1\n\n\n2\n1930\n5\n6\n3\n\n\n3\n1931\n11\n3\n0\n\n\n4\n1932\n6\n2\n4\n\n\n...\n...\n...\n...\n...\n\n\n92\n2020\n5\n11\n0\n\n\n93\n2021\n3\n13\n1\n\n\n94\n2022\n9\n8\n0\n\n\n95\n2023\n12\n5\n0\n\n\n96\n2024\n15\n2\n0\n\n\n\n\n97 rows × 4 columns\n\n\n\n\n\n\n\nwindow=10 ## change window\n\npistons_agg = get_window_and_winratio(pistons, window=window, team='Pistons')\nredwings_agg = get_window_and_winratio(redwings, window=window, team='RedWings')\ntiger_agg = get_window_and_winratio(tiger, window=window, team='Tiger')\nlions_agg = get_window_and_winratio(lions, window=window, team='Lions')\n\ndf = pd.merge(pistons_agg, redwings_agg, on='Window').merge(tiger_agg, on='Window').merge(lions_agg, on='Window')\n\ndf.set_index('Window', inplace=True)\ndf\n\n\n\n\n\n\n\n\nWins_Pistons\nLosses_Pistons\nWinRatio_Pistons\nWins_RedWings\nLosses_RedWings\nTies_RedWings\nWinRatio_RedWings\nWins_Tiger\nLosses_Tiger\nWinRatio_Tiger\nWins_Lions\nLosses_Lions\nTies_Lions\nWinRatio_Lions\n\n\nWindow\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1940\n228\n137\n0.624658\n265\n190\n91\n0.568681\n834\n705\n0.541910\n35\n71\n4\n0.336364\n\n\n1950\n342\n368\n0.481690\n351\n218\n131\n0.595000\n738\n802\n0.479221\n68\n48\n4\n0.583333\n\n\n1960\n314\n492\n0.389578\n308\n292\n116\n0.511173\n882\n729\n0.547486\n66\n61\n11\n0.518116\n\n\n1970\n367\n453\n0.447561\n267\n410\n115\n0.409722\n789\n820\n0.490367\n66\n75\n3\n0.468750\n\n\n1980\n466\n354\n0.568293\n273\n410\n117\n0.414375\n839\n727\n0.535760\n61\n90\n1\n0.404605\n\n\n1990\n394\n394\n0.500000\n438\n248\n100\n0.620865\n702\n852\n0.451737\n79\n81\n0\n0.493750\n\n\n2000\n482\n338\n0.587805\n395\n163\n98\n0.676829\n729\n891\n0.450000\n42\n118\n0\n0.262500\n\n\n2010\n326\n462\n0.413706\n354\n316\n105\n0.524516\n782\n835\n0.483612\n72\n87\n1\n0.453125\n\n\n2020\n118\n282\n0.295000\n166\n171\n47\n0.493490\n330\n376\n0.467422\n44\n39\n1\n0.529762\n\n\n\n\n\n\n\n\n## check tiger aggregation with wiki data\n\ntigercheck = get_window_and_winratio(tiger, window=10, team='').rename(columns={'Window':'Decade'}).set_index('Decade')\ntigercheck.columns = [col.strip('_') for col in tigercheck.columns]\n\nwikidec = pd.read_html(datasets['tiger'])[2]\nwikidec['Decade'] = wikidec['Decade'].str.replace('s', '')\nwikidec = wikidec[:-1]\nwikidec = wikidec[['Decade', 'Wins','Losses']]\nwikidec[['Decade', 'Wins', 'Losses']] = wikidec[['Decade', 'Wins', 'Losses']].astype(int)\nwikidec.set_index('Decade', inplace=True)\n\nwikidec[['Wins','Losses']] == tigercheck[['Wins','Losses']] \npd.merge(tigercheck, wikidec, on='Decade')\ntiger[tiger['Window'] == 2020]\n\n# note: test passed for all windows except for 2020,\n#       because wikidec does not count wins/losses for 2024\n\n\n\n\n\n\n\n\nYear\nWins\nLosses\nWindow\n\n\n\n\n120\n2020\n23\n35\n2020\n\n\n121\n2021\n77\n85\n2020\n\n\n122\n2022\n66\n96\n2020\n\n\n123\n2023\n78\n84\n2020\n\n\n124\n2024\n86\n76\n2020\n\n\n\n\n\n\n\n\n\n\n\nfrom matplotlib.ticker import FixedLocator, FuncFormatter\nfrom scipy.interpolate import make_interp_spline\n\n# Teams and their win ratio columns \nteams = {'Pistons': 'WinRatio_Pistons', \n         'RedWings': 'WinRatio_RedWings', \n         'Tiger': 'WinRatio_Tiger', \n         'Lions': 'WinRatio_Lions'}\n\n# Generate new x values for smooth curves\nx_new = np.linspace(df.index.min(), df.index.max(), 300)\n\n# Create big4 smooth curves and plot\n# nb: it's better to smooth lines when you have several data points \nk=1 ## k&gt;=2 to smooth lines\nfig, ax = plt.subplots(figsize=(14, 8))\nfor team, col in teams.items():\n    spl = make_interp_spline(df.index, df[col], k=k)\n    y_smooth = spl(x_new)\n    plt.plot(x_new, y_smooth, label=team, linewidth=2)\n\nplt.yticks(size=11)\nplt.xticks(size=11)\nplt.xlabel('Season', size = 12)\nplt.ylabel('Average Win Percentage', size = 12)\nplt.title('Detroit Sports Team Win Perentage in a '+str(window)+'-year window', size = 14)\n\nyticks = np.arange(0.2, 0.8, 0.1) \nax.yaxis.set_major_locator(FixedLocator(yticks)) \nax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: f'{int(round(y * 100))}%')) \nax.set_ylim(0.20, 0.73)\n\nax.yaxis.grid(which='major', color='gray', linestyle='--', linewidth=0.5)\nax.spines[['right', 'top']].set_visible(False)\nplt.legend(loc='best', fontsize=13)\n\n# if k&gt;=2:\n#     plt.savefig('detroit-avg-win-smoothed.png')\n# else:\n#     plt.savefig('detroit-avg-win.png')\n    \nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe plot answers the question of how the winning percentages of the four major Detroit sports teams (Pistons, Red Wings, Tigers and Lions) have changed over the last 80 years. Wikipedia was scraped for data on wins, losses and ties by season for each team. For a fair comparison across sports, we computed the winning percentage as the number of wins divided by the total number of games played (i.e. wins plus ties plus losses). We assumed that a tie is 1/2 of a win, so the winning percentage was computed as \\(\\frac{(wins + 0.5×ties)}{(wins+ties+losses)}\\). For Pistons and Tigers (basketball and baseball) ties do not occur so the winning percentage was simply computed as \\(\\frac{(wins)}{(wins+losses)}\\). A 10 year moving average was plotted to identify trends in the team’s win percentages.\nThe Pistons saw high performance in 1940, 1980, and 2000, followed by periods of decline. The Red Wings experienced a notable rise from 1980 to 2000, with a subsequent downward trend. The Tigers’ win percentage remains relatively stable around 50% with minor fluctuations with lowest performance between 1990 and 2000. The Lions show an up and down trend, starting low, peaking in 1950, 1990 and 2010 and then declining again."
  },
  {
    "objectID": "detroit-wiki.html#goal",
    "href": "detroit-wiki.html#goal",
    "title": "Visualization of Detroit’s sports teams win percentages",
    "section": "",
    "text": "How have the win percentages for Detroit’s major sports teams (Pistons, Red Wings, Tigers, and Lions) changed over the past 80 years using a 10-year sliding window?\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nfrom packaging.version import Version\n\n\n\n\ndatasets={\n    'pistons':  'https://en.wikipedia.org/wiki/List_of_Detroit_Pistons_seasons',\n    'redwings': 'https://en.wikipedia.org/wiki/List_of_Detroit_Red_Wings_seasons',\n    'tiger':    'https://en.wikipedia.org/wiki/List_of_Detroit_Tigers_seasons',\n    'lions':    'https://en.wikipedia.org/wiki/List_of_Detroit_Lions_seasons'\n}\n\n\n\n\n\ndef get_window_and_winratio(df, window=10, team='Pistons'):\n    df['Window'] = (df['Year'] // window) * window\n    if team == 'RedWings' or team == 'Lions':\n        df = df.groupby('Window').agg({'Wins': 'sum', 'Losses': 'sum', 'Ties': 'sum'}).reset_index()\n        df['WinRatio'] = (df['Wins'] + 0.5 * df['Ties']) / (df['Wins'] + df['Losses'] + df['Ties'])\n    else:\n        df = df.groupby('Window').agg({'Wins': 'sum', 'Losses': 'sum'}).reset_index()\n        df['WinRatio'] = df['Wins'] / (df['Wins'] + df['Losses'])\n    df.columns = [col + '_' + team if col != 'Window' else col for col in df.columns]\n    return df\n\n\n\n\n\n# pd.set_option('display.max_rows', None)\n# pd.reset_option('display.max_rows')\n\nwiki_pistons = pd.read_html(datasets['pistons'])[1][1:]\n\npistons = pd.DataFrame()\npistons['Year'] = wiki_pistons['Team'].str[:4]\npistons[['Wins','Losses']] = wiki_pistons[['Wins','Losses']]\npistons = pistons[~(pistons['Year'].str.contains('Fort|Detr'))]\npistons[['Year', 'Wins', 'Losses']] = pistons[['Year', 'Wins', 'Losses']].astype(int)\npistons\n\n\n\n\n\n\n\n\nYear\nWins\nLosses\n\n\n\n\n1\n1941\n15\n9\n\n\n2\n1942\n17\n6\n\n\n3\n1943\n18\n4\n\n\n4\n1944\n25\n5\n\n\n5\n1945\n26\n8\n\n\n...\n...\n...\n...\n\n\n82\n2020\n20\n52\n\n\n83\n2021\n23\n59\n\n\n84\n2022\n17\n65\n\n\n85\n2023\n14\n68\n\n\n86\n2024\n44\n38\n\n\n\n\n84 rows × 3 columns\n\n\n\n\n\n\n\n# pd.set_option('display.max_rows', None)\n# pd.reset_option('display.max_rows')\n\nwiki_redwings = pd.read_html(datasets['redwings'])[2][1:]\n\nredwings = pd.DataFrame()\nredwings['Year'] = wiki_redwings['NHL season']['NHL season'].str[:4]\nredwings[['GP', 'Wins','Losses', 'Ties', 'OT']] = wiki_redwings['Regular season[3][6][7][8]'][['GP','W','L','T','OT']]\nredwings = redwings[~((redwings['Year'].str.contains('^Detr|^Tota')) |\n                      (redwings['Wins'].str.contains('^—')) |\n                      (redwings['Losses'].str.contains('^—')) |\n                      (redwings['Ties'].str.contains('^—\\[m\\]')))]\n\nredwings['OT'] = redwings['OT'].str.replace('\\[k\\]','', regex=True)\nredwings['Ties'] = redwings['Ties'].apply(lambda x: 0 if x == '—' else x) # redwings.loc[redwings['Ties'] == '—', 'Ties'] = 0\nredwings['OT']   = redwings['OT'].apply(lambda x: 0 if x == '—' else x)   # redwings.loc[redwings['OT'] == '—', 'OT'] = 0\n\nredwings[['Year', 'Wins', 'Losses', 'Ties', 'OT']] = redwings[['Year', 'Wins', 'Losses', 'Ties', 'OT']].astype(int)\nredwings['Ties'] = redwings['Ties'] + redwings['OT']\nredwings = redwings[['Year', 'Wins', 'Losses', 'Ties']]\nredwings\n\n\n\n\n\n\n\n\nYear\nWins\nLosses\nTies\n\n\n\n\n1\n1926\n12\n28\n4\n\n\n2\n1927\n19\n19\n6\n\n\n3\n1928\n19\n16\n9\n\n\n4\n1929\n14\n24\n6\n\n\n6\n1930\n16\n21\n7\n\n\n...\n...\n...\n...\n...\n\n\n97\n2020\n19\n27\n10\n\n\n98\n2021\n32\n40\n10\n\n\n99\n2022\n35\n37\n10\n\n\n100\n2023\n41\n32\n9\n\n\n101\n2024\n39\n35\n8\n\n\n\n\n97 rows × 4 columns\n\n\n\n\n\n\n\n# pd.set_option('display.max_rows', None)\n# pd.reset_option('display.max_rows')\n\nwiki_tiger = pd.read_html(datasets['tiger'])[1]\n\ntiger = pd.DataFrame()\ntiger['Year'] = wiki_tiger['Season']\ntiger[['Wins','Losses']] = wiki_tiger[['Wins','Losses']]\n\ntiger = tiger[~(tiger['Year'].str.contains('Total'))]\ntiger[['Year', 'Wins', 'Losses']] = tiger[['Year', 'Wins', 'Losses']].astype(int)\n\ntiger\n\n\n\n\n\n\n\n\nYear\nWins\nLosses\n\n\n\n\n0\n1901\n74\n61\n\n\n1\n1902\n52\n83\n\n\n2\n1903\n65\n71\n\n\n3\n1904\n62\n90\n\n\n4\n1905\n79\n74\n\n\n...\n...\n...\n...\n\n\n120\n2020\n23\n35\n\n\n121\n2021\n77\n85\n\n\n122\n2022\n66\n96\n\n\n123\n2023\n78\n84\n\n\n124\n2024\n86\n76\n\n\n\n\n125 rows × 3 columns\n\n\n\n\n\n\n\n# pd.set_option('display.max_rows', None)\n# pd.reset_option('display.max_rows')\n\npd_version = Version(pd.__version__)\n\nwiki_lions = pd.read_html(datasets['lions'])[1]\n\nlions = pd.DataFrame()\nlions['Year'] = wiki_lions['Season'][['Season']]\nif pd_version &lt;=  Version(\"1.5.2\"):\n    lions[['Wins','Losses', 'Ties']] = wiki_lions['Regular season'][['.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}W', 'L', 'T']]\nelse:\n    lions[['Wins','Losses', 'Ties']] = wiki_lions['Regular season'][['W', 'L', 'T']]\nlions = lions[~(lions['Year'].str.startswith('Totals'))]\nlions[['Year', 'Wins', 'Losses', 'Ties']] = lions[['Year', 'Wins', 'Losses', 'Ties']].astype(int)\n\nlions\n\n\n\n\n\n\n\n\nYear\nWins\nLosses\nTies\n\n\n\n\n0\n1928\n9\n3\n2\n\n\n1\n1929\n12\n2\n1\n\n\n2\n1930\n5\n6\n3\n\n\n3\n1931\n11\n3\n0\n\n\n4\n1932\n6\n2\n4\n\n\n...\n...\n...\n...\n...\n\n\n92\n2020\n5\n11\n0\n\n\n93\n2021\n3\n13\n1\n\n\n94\n2022\n9\n8\n0\n\n\n95\n2023\n12\n5\n0\n\n\n96\n2024\n15\n2\n0\n\n\n\n\n97 rows × 4 columns\n\n\n\n\n\n\n\nwindow=10 ## change window\n\npistons_agg = get_window_and_winratio(pistons, window=window, team='Pistons')\nredwings_agg = get_window_and_winratio(redwings, window=window, team='RedWings')\ntiger_agg = get_window_and_winratio(tiger, window=window, team='Tiger')\nlions_agg = get_window_and_winratio(lions, window=window, team='Lions')\n\ndf = pd.merge(pistons_agg, redwings_agg, on='Window').merge(tiger_agg, on='Window').merge(lions_agg, on='Window')\n\ndf.set_index('Window', inplace=True)\ndf\n\n\n\n\n\n\n\n\nWins_Pistons\nLosses_Pistons\nWinRatio_Pistons\nWins_RedWings\nLosses_RedWings\nTies_RedWings\nWinRatio_RedWings\nWins_Tiger\nLosses_Tiger\nWinRatio_Tiger\nWins_Lions\nLosses_Lions\nTies_Lions\nWinRatio_Lions\n\n\nWindow\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1940\n228\n137\n0.624658\n265\n190\n91\n0.568681\n834\n705\n0.541910\n35\n71\n4\n0.336364\n\n\n1950\n342\n368\n0.481690\n351\n218\n131\n0.595000\n738\n802\n0.479221\n68\n48\n4\n0.583333\n\n\n1960\n314\n492\n0.389578\n308\n292\n116\n0.511173\n882\n729\n0.547486\n66\n61\n11\n0.518116\n\n\n1970\n367\n453\n0.447561\n267\n410\n115\n0.409722\n789\n820\n0.490367\n66\n75\n3\n0.468750\n\n\n1980\n466\n354\n0.568293\n273\n410\n117\n0.414375\n839\n727\n0.535760\n61\n90\n1\n0.404605\n\n\n1990\n394\n394\n0.500000\n438\n248\n100\n0.620865\n702\n852\n0.451737\n79\n81\n0\n0.493750\n\n\n2000\n482\n338\n0.587805\n395\n163\n98\n0.676829\n729\n891\n0.450000\n42\n118\n0\n0.262500\n\n\n2010\n326\n462\n0.413706\n354\n316\n105\n0.524516\n782\n835\n0.483612\n72\n87\n1\n0.453125\n\n\n2020\n118\n282\n0.295000\n166\n171\n47\n0.493490\n330\n376\n0.467422\n44\n39\n1\n0.529762\n\n\n\n\n\n\n\n\n## check tiger aggregation with wiki data\n\ntigercheck = get_window_and_winratio(tiger, window=10, team='').rename(columns={'Window':'Decade'}).set_index('Decade')\ntigercheck.columns = [col.strip('_') for col in tigercheck.columns]\n\nwikidec = pd.read_html(datasets['tiger'])[2]\nwikidec['Decade'] = wikidec['Decade'].str.replace('s', '')\nwikidec = wikidec[:-1]\nwikidec = wikidec[['Decade', 'Wins','Losses']]\nwikidec[['Decade', 'Wins', 'Losses']] = wikidec[['Decade', 'Wins', 'Losses']].astype(int)\nwikidec.set_index('Decade', inplace=True)\n\nwikidec[['Wins','Losses']] == tigercheck[['Wins','Losses']] \npd.merge(tigercheck, wikidec, on='Decade')\ntiger[tiger['Window'] == 2020]\n\n# note: test passed for all windows except for 2020,\n#       because wikidec does not count wins/losses for 2024\n\n\n\n\n\n\n\n\nYear\nWins\nLosses\nWindow\n\n\n\n\n120\n2020\n23\n35\n2020\n\n\n121\n2021\n77\n85\n2020\n\n\n122\n2022\n66\n96\n2020\n\n\n123\n2023\n78\n84\n2020\n\n\n124\n2024\n86\n76\n2020\n\n\n\n\n\n\n\n\n\n\n\nfrom matplotlib.ticker import FixedLocator, FuncFormatter\nfrom scipy.interpolate import make_interp_spline\n\n# Teams and their win ratio columns \nteams = {'Pistons': 'WinRatio_Pistons', \n         'RedWings': 'WinRatio_RedWings', \n         'Tiger': 'WinRatio_Tiger', \n         'Lions': 'WinRatio_Lions'}\n\n# Generate new x values for smooth curves\nx_new = np.linspace(df.index.min(), df.index.max(), 300)\n\n# Create big4 smooth curves and plot\n# nb: it's better to smooth lines when you have several data points \nk=1 ## k&gt;=2 to smooth lines\nfig, ax = plt.subplots(figsize=(14, 8))\nfor team, col in teams.items():\n    spl = make_interp_spline(df.index, df[col], k=k)\n    y_smooth = spl(x_new)\n    plt.plot(x_new, y_smooth, label=team, linewidth=2)\n\nplt.yticks(size=11)\nplt.xticks(size=11)\nplt.xlabel('Season', size = 12)\nplt.ylabel('Average Win Percentage', size = 12)\nplt.title('Detroit Sports Team Win Perentage in a '+str(window)+'-year window', size = 14)\n\nyticks = np.arange(0.2, 0.8, 0.1) \nax.yaxis.set_major_locator(FixedLocator(yticks)) \nax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: f'{int(round(y * 100))}%')) \nax.set_ylim(0.20, 0.73)\n\nax.yaxis.grid(which='major', color='gray', linestyle='--', linewidth=0.5)\nax.spines[['right', 'top']].set_visible(False)\nplt.legend(loc='best', fontsize=13)\n\n# if k&gt;=2:\n#     plt.savefig('detroit-avg-win-smoothed.png')\n# else:\n#     plt.savefig('detroit-avg-win.png')\n    \nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe plot answers the question of how the winning percentages of the four major Detroit sports teams (Pistons, Red Wings, Tigers and Lions) have changed over the last 80 years. Wikipedia was scraped for data on wins, losses and ties by season for each team. For a fair comparison across sports, we computed the winning percentage as the number of wins divided by the total number of games played (i.e. wins plus ties plus losses). We assumed that a tie is 1/2 of a win, so the winning percentage was computed as \\(\\frac{(wins + 0.5×ties)}{(wins+ties+losses)}\\). For Pistons and Tigers (basketball and baseball) ties do not occur so the winning percentage was simply computed as \\(\\frac{(wins)}{(wins+losses)}\\). A 10 year moving average was plotted to identify trends in the team’s win percentages.\nThe Pistons saw high performance in 1940, 1980, and 2000, followed by periods of decline. The Red Wings experienced a notable rise from 1980 to 2000, with a subsequent downward trend. The Tigers’ win percentage remains relatively stable around 50% with minor fluctuations with lowest performance between 1990 and 2000. The Lions show an up and down trend, starting low, peaking in 1950, 1990 and 2010 and then declining again."
  },
  {
    "objectID": "ml-video.html",
    "href": "ml-video.html",
    "title": "Predicting viewer engagement with educational videos",
    "section": "",
    "text": "Note\n\n\n\nNote: data from the Coursera course Applied Machine Learning in Python"
  },
  {
    "objectID": "ml-video.html#about-the-prediction-problem",
    "href": "ml-video.html#about-the-prediction-problem",
    "title": "Predicting viewer engagement with educational videos",
    "section": "About the prediction problem",
    "text": "About the prediction problem\nWith the accelerating popularity of online educational experiences, the role of online lectures and other educational video continues to increase in scope and importance. Open access educational repositories such as videolectures.net, as well as Massive Open Online Courses (MOOCs) on platforms like Coursera, have made access to many thousands of lectures and tutorials an accessible option for millions of people around the world. Yet this impressive volume of content has also led to a challenge in how to find, filter, and match these videos with learners.\nOne critical property of a video is engagement: how interesting or “engaging” it is for viewers, so that they decide to keep watching. Engagement is critical for learning, whether the instruction is coming from a video or any other source. There are many ways to define engagement with video, but one common approach is to estimate it by measuring how much of the video a user watches. If the video is not interesting and does not engage a viewer, they will typically abandon it quickly, e.g. only watch 5 or 10% of the total.\nA first step towards providing the best-matching educational content is to understand which features of educational material make it engaging for learners in general. This is where predictive modeling can be applied, via supervised machine learning. Here the task is to predict how engaging an educational video is likely to be for viewers, based on a set of features extracted from the video’s transcript, audio track, hosting site, and other sources."
  },
  {
    "objectID": "ml-video.html#about-the-dataset",
    "href": "ml-video.html#about-the-dataset",
    "title": "Predicting viewer engagement with educational videos",
    "section": "About the dataset",
    "text": "About the dataset\nWe extracted training and test datasets of educational video features from the VLE Dataset put together by researcher Sahan Bulathwela at University College London.\nTwo data files are provided: train.csv and test.csv. Each row in these two files corresponds to a single educational video, and includes information about diverse properties of the video content as described further below. The target variable is engagement which was defined as True if the median percentage of the video watched across all viewers was at least 30%, and False otherwise.\nFile descriptions\n\ntrain.csv - the training set\ntest.csv - the test set\n\nData fields\ntrain.csv & test.csv:\n\ntitle_word_count - the number of words in the title of the video.\ndocument_entropy - a score indicating how varied the topics are covered in the video, based on the transcript. Videos with smaller entropy scores will tend to be more cohesive and more focused on a single topic.\nfreshness - The number of days elapsed between 01/01/1970 and the lecture published date. Videos that are more recent will have higher freshness values.\neasiness - A text difficulty measure applied to the transcript. A lower score indicates more complex language used by the presenter.\nfraction_stopword_presence - A stopword is a very common word like ‘the’ or ‘and’. This feature computes the fraction of all words that are stopwords in the video lecture transcript.\nspeaker_speed - The average speaking rate in words per minute of the presenter in the video.\nsilent_period_rate - The fraction of time in the lecture video that is silence (no speaking).\n\ntrain.csv only:\n\nengagement - Target label for training. True if learners watched a substantial portion of the video (see description), or False otherwise.\n\nMore details on the original VLE dataset and others related to video engagement here.\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\nnp.random.seed(0)"
  },
  {
    "objectID": "ml-video.html#load-dataset",
    "href": "ml-video.html#load-dataset",
    "title": "Predicting viewer engagement with educational videos",
    "section": "Load dataset",
    "text": "Load dataset\n\ndf_train = pd.read_csv('data/train.csv')\ndf_test = pd.read_csv('data/test.csv')\ndf_train['engagement'] = df_train['engagement'].astype(int)"
  },
  {
    "objectID": "ml-video.html#exploratoy-data-analysis",
    "href": "ml-video.html#exploratoy-data-analysis",
    "title": "Predicting viewer engagement with educational videos",
    "section": "Exploratoy Data Analysis",
    "text": "Exploratoy Data Analysis\n\nFeature Distribution\n\nimport seaborn as sns\nfig, subaxes = plt.subplots(3, 3, figsize=(10, 10))\ni = 1\nfor row in subaxes:\n    for this_axis in row:\n        sns.histplot(df_train.iloc[:, i], ax=this_axis)\n        this_axis.set_title('{}'.format(df_train.columns[i]))\n        i += 1\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFeature Correlation\nFrom the heatmap we can observe that there’s not large correlations between the variables, except for easiness and normalization_rate.\n\ndf_corr = df_train.iloc[:,1:].corr()\nplt.figure(figsize=(8,8))\nsns.heatmap(df_corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 7},\n           xticklabels= df_corr.columns, \n           yticklabels= df_corr.columns,\n           cmap=sns.diverging_palette(120, 10, as_cmap=True))\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFeature Selection\nHere the most important features are document_entropy, freshness and easiness.\n\nfrom sklearn.feature_selection import SelectKBest, f_classif\nimport seaborn as sns\n\nX = df_train.iloc[:,1:-1]\ny = df_train.iloc[:,-1] ## engagement\n\nthis_k = 8\nselector = SelectKBest(f_classif, k='all')\nselector.fit(X, y)\n\n# get the score for each feature\nscores = selector.scores_\n\nfeature_scores = pd.DataFrame({'Feature': X.columns, 'Score': scores})\ntotal = feature_scores['Score'].sum()\nfeature_scores['Score'] = feature_scores['Score']/total\nfeature_scores.sort_values('Score', ascending=False, inplace=True)\n\nplt.figure(figsize=(6,3))\nsns.barplot(x='Score', y='Feature', data=feature_scores)\nplt.xlabel('Score')\nplt.ylabel('Features')\nplt.title('Features importance (Normalized)')\n# plt.xticks(rotation=20, ha='right')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nRandom Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\ntop_features = ['document_entropy', 'freshness', 'easiness']\nX_train, y_train = df_train[top_features], df_train['engagement'].astype(int)\nX_test = df_test[top_features]\n    \nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2']\n}\n\nrfc = RandomForestClassifier(random_state=0)\n\ngrid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\nprint(grid_search.best_params_)\nprint(grid_search.best_score_)\n\n{'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n0.8750181867018478\n\n\n\n\nGradient Boosting\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2']\n}\n\nrfc = GradientBoostingClassifier(random_state=0)\n\ngrid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\nprint(grid_search.best_params_)\nprint(grid_search.best_score_)\n\n{'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n0.8646361089042813\n\n\n\n\nGaussian Naive Bayes\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {'var_smoothing': [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5]}\n\ngnb = GaussianNB()\n\ngrid_search = GridSearchCV(gnb, param_grid=param_grid, cv=5, n_jobs=-1, scoring='roc_auc')\ngrid_search.fit(X_train, y_train)\n\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)\n\n0.8271618585290608\n{'var_smoothing': 1e-10}\n\n\n\n\nExplore model performance\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nclfs = ['GaussianNB', 'GradientBoostingClassifier', 'RandomForestClassifier']\n\nfig, subaxes = plt.subplots(1, 3, figsize=(12, 4))\nfor clf, this_axis in zip(clfs, subaxes):\n    nbclf = eval(clf)().fit(X_train, y_train)\n    y_probabilities = nbclf.predict_proba(X_test)\n    fpr_lr, tpr_lr, _ = roc_curve(y_test, y_probabilities[:,1])\n    roc_auc_lr = auc(fpr_lr, tpr_lr)\n    this_axis.plot(fpr_lr, tpr_lr, lw=3, label='{}'.format(clf) + ' ROC curve (area = {:0.2f})'.format(roc_auc_lr))\n    this_axis.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n    this_axis.legend(loc='lower right', fontsize=7)\n    this_axis.set_xlabel('False Positive Rate', fontsize=8)\n    this_axis.set_ylabel('True Positive Rate', fontsize=8)\n    this_axis.set_title('ROC curve {}'.format(clf), fontsize=8)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nfor clf in clfs:\n    nbclf = eval(clf)().fit(X_train, y_train)\n    y_probabilities = nbclf.predict_proba(X_test)\n    fpr_lr, tpr_lr, _ = roc_curve(y_test, y_probabilities[:,1])\n    roc_auc_lr = auc(fpr_lr, tpr_lr)\n    plt.plot(fpr_lr, tpr_lr, lw=3, label='{}'.format(clf) + ' ROC curve (area = {:0.2f})'.format(roc_auc_lr))\n    plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n    plt.legend(loc='lower right', fontsize=7)\n    plt.xlabel('False Positive Rate', fontsize=8)\n    plt.ylabel('True Positive Rate', fontsize=8)"
  },
  {
    "objectID": "ml-video.html#peformance-evaluation-on-the-best-models",
    "href": "ml-video.html#peformance-evaluation-on-the-best-models",
    "title": "Predicting viewer engagement with educational videos",
    "section": "Peformance evaluation on the best models",
    "text": "Peformance evaluation on the best models\nSince labels for the 2309 test set videos are not provided, I evalaute performance of models on the validation set.\n\ntop_features = ['document_entropy', 'freshness', 'easiness']\n\nX = df_train[top_features]\ny = df_train['engagement'].astype(int)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n\n## results from grid search\n#  {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\nclf_rf = RandomForestClassifier(max_depth=10, max_features='sqrt', min_samples_leaf=1, \n                               min_samples_split=5, n_estimators=100, n_jobs=-1, \n                               random_state=0)\n\n## results from grid search\n# {'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\nclf_gb = GradientBoostingClassifier(max_depth=30, max_features='sqrt', min_samples_leaf=2, \n                                   min_samples_split=5, n_estimators=200, random_state=0)\n\nclf_rf.fit(X_train, y_train)\nclf_gb.fit(X_train, y_train)\n\ny_pred = clf_rf.predict_proba(X_val)[:, 1]\nroc_auc = roc_auc_score(y_val, y_pred)\nprint(f\"Random Forest AUROC: {roc_auc:.3f}\")\n\nclf_gb.fit(X_train, y_train)\ny_pred = clf_gb.predict_proba(X_val)[:, 1]\nroc_auc = roc_auc_score(y_val, y_pred)\nprint(f\"Gradient Boost AUROC: {roc_auc:.3f}\")\n\nRandom Forest AUROC: 0.854\nGradient Boost AUROC: 0.837\n\n\nCross validatated performance …\n\nmetrics = ['roc_auc', 'average_precision', 'balanced_accuracy']\nperfname = ['AUROC', 'AUPRC', 'Balanced Accuracy']\n\nclfs = [clf_rf, clf_gb]\nclfsname = ['Random Forest', 'Gradient Boost']\n\nfor clf, clfname in zip(clfs, clfsname):\n  for perf, name in zip(metrics, perfname):\n    scores = cross_val_score(clf, X, y, cv=5, scoring=perf)\n    print(f\"{clfname} - Averaged {name}: {scores.mean():.3f}\")\n\nRandom Forest - Averaged AUROC: 0.875\nRandom Forest - Averaged AUPRC: 0.610\nRandom Forest - Averaged Balanced Accuracy: 0.699\nGradient Boost - Averaged AUROC: 0.849\nGradient Boost - Averaged AUPRC: 0.562\nGradient Boost - Averaged Balanced Accuracy: 0.712"
  },
  {
    "objectID": "ml-video.html#prediction-on-the-2309-test-set-videos",
    "href": "ml-video.html#prediction-on-the-2309-test-set-videos",
    "title": "Predicting viewer engagement with educational videos",
    "section": "Prediction on the 2309 test set videos",
    "text": "Prediction on the 2309 test set videos\n\ntop_features = ['document_entropy', 'freshness', 'easiness']\n\nX_train, y_train = df_train[top_features], df_train.iloc[:,-1].astype(int)\nX_test = df_test[top_features]\n\n## results from grid search\n#  {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\nclf = RandomForestClassifier(max_depth=10, max_features='sqrt', min_samples_leaf=1, \n                              min_samples_split=5, n_estimators=100, n_jobs=-1, \n                              random_state=0)\n\n## results from grid search\n# {'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n# clf = GradientBoostingClassifier(max_depth=30, max_features='sqrt', min_samples_leaf=2, \n#                                  min_samples_split=5, n_estimators=200, random_state=0)\n\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict_proba(X_test)\n\nindexes = df_test['id'].values\nprobabilities = y_pred[:,1]\n\npred = pd.Series(probabilities, index=indexes)\npred\n\n9240     0.010444\n9241     0.031429\n9242     0.066196\n9243     0.751450\n9244     0.012729\n           ...   \n11544    0.018296\n11545    0.023312\n11546    0.015856\n11547    0.863286\n11548    0.053050\nLength: 2309, dtype: float64"
  },
  {
    "objectID": "r4_predict_erstatus.html",
    "href": "r4_predict_erstatus.html",
    "title": "Predicting ER status imputing missing values",
    "section": "",
    "text": "The goal of this report is to predict the ER status for those patients where the ER status is unknown. To this end I used the GEO metadata downloaded in Downloading GEO data and the cluster assignments obtained in the report Identification of breast cancer subtypes and biomarkers using the Seurat workflow."
  },
  {
    "objectID": "r4_predict_erstatus.html#aim",
    "href": "r4_predict_erstatus.html#aim",
    "title": "Predicting ER status imputing missing values",
    "section": "",
    "text": "The goal of this report is to predict the ER status for those patients where the ER status is unknown. To this end I used the GEO metadata downloaded in Downloading GEO data and the cluster assignments obtained in the report Identification of breast cancer subtypes and biomarkers using the Seurat workflow."
  },
  {
    "objectID": "r4_predict_erstatus.html#workflow",
    "href": "r4_predict_erstatus.html#workflow",
    "title": "Predicting ER status imputing missing values",
    "section": "Workflow",
    "text": "Workflow\n\nI compared three supervised learning method (logist regression, random forest, support vector machine) optimizing their hyperparameters using a grid search with balanced accuracy as evaluation metric.\nTo handle missing data, I used the KNNimputer, which imputes values based on the nearest neighbors in the feature space.\nFor feature selection, I applied mutual_info_classif to retain the most informative features with respect to the target variable (ER status).\nTo address class imbalance, I set the parameter class_weight=balanced to ensure that the model gives appropriate attention to minority classes during training."
  },
  {
    "objectID": "r4_predict_erstatus.html#conclusion",
    "href": "r4_predict_erstatus.html#conclusion",
    "title": "Predicting ER status imputing missing values",
    "section": "Conclusion",
    "text": "Conclusion\nIn terms of balanced accuracy, random forest slightly outperformed logistic regression and SVM.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import KNNImputer\nfrom sklearn.feature_selection import SelectKBest, mutual_info_classif\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder\nfrom IPython.display import display, HTML"
  },
  {
    "objectID": "r4_predict_erstatus.html#exploring-dataset",
    "href": "r4_predict_erstatus.html#exploring-dataset",
    "title": "Predicting ER status imputing missing values",
    "section": "Exploring dataset",
    "text": "Exploring dataset\n\nLoading dataset\n\ndf = pd.read_table('data/cluster_anno_seurat.csv', sep=',')\n\ndf = df[['patient', 'age_at_diagnosis', 'tumor_size',\n         'lymph_node_status','er_status', 'pgr_status', 'her2_status',\n         'pam50_subtype', 'overall_survival_days', 'overall_survival_event',\n         'endocrine_treated', 'chemo_treated', 'ki67_status', 'nhg',\n         'seurat_clusters']]\n\ndf = df.set_index('patient')\n\ndf = df.replace({'endocrine_treated': {'no treated': 'untreated'}})\ndf = df.replace({'chemo_treated': {'no treated': 'untreated'}})\ndf = df.replace({'overall_survival_event': {'no survival': 'nosurvival'}})\n\ndf\n\n\n\n\n\n\n\n\nage_at_diagnosis\ntumor_size\nlymph_node_status\ner_status\npgr_status\nher2_status\npam50_subtype\noverall_survival_days\noverall_survival_event\nendocrine_treated\nchemo_treated\nki67_status\nnhg\nseurat_clusters\n\n\npatient\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF1\n43\n9.0\nNodeNegative\nNaN\nNaN\nHER2-\nBasal\n2367\nnosurvival\nuntreated\ntreated\nNaN\nG3\n5\n\n\nF2\n48\n14.0\nNodePositive\nER+\nPgR+\nHER2-\nLumA\n2367\nnosurvival\ntreated\ntreated\nNaN\nG2\n0\n\n\nF3\n69\n27.0\nNodePositive\nER+\nPgR+\nHER2-\nLumB\n2168\nsurvival\ntreated\ntreated\nNaN\nG3\n1\n\n\nF4\n39\n51.0\nNodePositive\nER+\nNaN\nHER2+\nLumA\n2416\nnosurvival\ntreated\ntreated\nNaN\nG3\n4\n\n\nF5\n73\n60.0\nNodePositive\nER+\nNaN\nHER2-\nNormal\n2389\nnosurvival\ntreated\nuntreated\nNaN\nG2\n3\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nF3269\n72\n13.0\nNodeNegative\nER+\nPgR+\nHER2-\nLumB\n856\nnosurvival\ntreated\ntreated\nKi67+\nG2\n7\n\n\nF3270\n69\n30.0\nNodePositive\nER+\nPgR+\nHER2-\nLumA\n861\nnosurvival\ntreated\ntreated\nKi67+\nG2\n8\n\n\nF3271\n73\n18.0\nNodeNegative\nER+\nPgR-\nNaN\nLumB\n862\nnosurvival\ntreated\ntreated\nKi67+\nG3\n4\n\n\nF3272\n67\n33.0\nNodePositive\nER+\nPgR+\nHER2-\nLumA\n844\nnosurvival\ntreated\nuntreated\nKi67+\nG2\n0\n\n\nF3273\n60\n17.0\nNodePositive\nER+\nPgR+\nHER2-\nLumA\n843\nnosurvival\ntreated\ntreated\nKi67+\nG2\n3\n\n\n\n\n3273 rows × 14 columns\n\n\n\n\n\nMissing data Distribution\n\nfeatures = df.columns\n\ndf_miss = df[features].isnull().sum()\ndf_miss = df_miss[df_miss &gt; 0].sort_values(ascending=False)\n\nfig, ax = plt.subplots(figsize=(10, 6))\ndf_miss.plot(kind='bar', ax=ax, color='skyblue', edgecolor='black')\n\nplt.ylabel('Missing Values', fontsize=12)\nplt.xticks(rotation=45, ha='right')\nplt.grid(axis='y', alpha=0.3)\n\n# Add value labels\nfor i, v in enumerate(df_miss.values):\n  ax.text(i, v + 0.1, str(v), ha='center', va='bottom', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nmissperc = (len(df_miss)/len(features))*100\nprint(f\"Tot features: {len(features)}\")\nprint(f\"Tot features with missing values: {len(df_miss)} ({missperc:0.1f}%)\")\nprint(f\"Feature with missing values: {[col for col in df_miss.index]}\")\nprint(f\"Feature without missing values: {[col for col in df.columns if col not in df_miss.index]}\")\n\n\n\n\n\n\n\n\n\nTot features: 14\nTot features with missing values: 9 (64.3%)\nFeature with missing values: ['ki67_status', 'pgr_status', 'er_status', 'her2_status', 'lymph_node_status', 'nhg', 'tumor_size', 'endocrine_treated', 'chemo_treated']\nFeature without missing values: ['age_at_diagnosis', 'pam50_subtype', 'overall_survival_days', 'overall_survival_event', 'seurat_clusters']\n\n\n\n\nER status distribution\n\nfig, ax = plt.subplots(figsize=(10, 6))\ndf['er_status'].value_counts(dropna=False).plot(kind='bar', ax=ax, color='skyblue', edgecolor='black')\n\nfor i, v in enumerate(df['er_status'].value_counts(dropna=False)):\n  ax.text(i, v + 0.1, str(v), ha='center', va='bottom', fontweight='bold')"
  },
  {
    "objectID": "r4_predict_erstatus.html#splitting-data-in-training-and-test-set",
    "href": "r4_predict_erstatus.html#splitting-data-in-training-and-test-set",
    "title": "Predicting ER status imputing missing values",
    "section": "Splitting data in training and test set",
    "text": "Splitting data in training and test set\n\ny = df['er_status']\nX_train, y_train = df.loc[~y.isna(),:].drop('er_status', axis=1), y[~y.isna()]\nX_test, y_test = df.loc[y.isna(),:].drop('er_status', axis=1), y[y.isna()]"
  },
  {
    "objectID": "r4_predict_erstatus.html#imputation-pipeline",
    "href": "r4_predict_erstatus.html#imputation-pipeline",
    "title": "Predicting ER status imputing missing values",
    "section": "Imputation pipeline",
    "text": "Imputation pipeline\n\ndef imputation_pipeline(X_train, classifier, nfeat = 5):\n  # identify feature type\n  categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n  numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n\n  # build imputation pipeline\n  # OrdinalEncoder: designed for feature encoding, accept 2d array (X,y)\n  # LabelEncoder: designed for target encoding, accept 1d array (y)\n  categorical_imputer = Pipeline(steps=[\n    ('encoder', OrdinalEncoder()),\n    ('imputer', KNNImputer(n_neighbors=50))\n  ])\n\n  numerical_imputer = Pipeline(steps=[\n    ('imputer', KNNImputer(n_neighbors=20)),\n    ('scaler', StandardScaler())\n  ])\n\n  imputation = ColumnTransformer(transformers=[\n    ('categorical', categorical_imputer, categorical_features),\n    ('numerical', numerical_imputer, numerical_features)\n  ])\n\n  # return pipeline\n  return Pipeline(steps=[\n    ('imputation', imputation),\n    ('feature_selection', SelectKBest(mutual_info_classif, k=nfeat)),\n    ('classifier', classifier)\n  ])\n\n  ## using smote instead of class_weight='balanced'\n  # from imblearn.over_sampling import SMOTE\n  # from imblearn.pipeline import Pipeline as ImbPipeline\n  # return ImbPipeline(steps=[\n  #   ('imputation', imputation),\n  #   ('smote', SMOTE(random_state=0)),  # add SMOTE after imputation\n  #   ('classifier', classifier)  # remove class_weight='balanced' from classifiers\n  # ])\n\nUtility function to format results\n\n## utils to show results\ndef show_results(fitted_pipeline, X_test, y_pred_proba):\n  results = pd.DataFrame({\n    'Patient_ID': X_test.index,\n    f'Prob_{fitted_pipeline.classes_[0]}': y_pred_proba[:, 0],\n    f'Prob_{fitted_pipeline.classes_[1]}': y_pred_proba[:, 1],\n    'Max_Probability': np.max(y_pred_proba, axis=1),\n    'Predicted_ER_Status': y_pred,\n    'Confidence_Level': np.where(np.max(y_pred_proba, axis=1) &gt; 0.8, 'High',\n                        np.where(np.max(y_pred_proba, axis=1) &gt; 0.6, 'Medium',\n                      'Low'))\n  }).set_index('Patient_ID')\n\n  er_df = pd.DataFrame({\n      'Label': {class_label: idx for idx, class_label in enumerate(fitted_pipeline.classes_)},\n      'Count': pd.Series(y_pred).value_counts()\n  }).rename_axis('ER_Status')\n\n  confidence_df = pd.DataFrame({\n      'Count': results['Confidence_Level'].value_counts(),\n      'Percentage': (results['Confidence_Level'].value_counts(normalize=True) * 100).round(2)\n  })\n\n  # create side-by-side HTML\n  html_str = f\"\"\"\n  &lt;div style=\"display: flex; gap: 50px;\"&gt;\n    &lt;div&gt;\n      &lt;h4&gt;ER Status Distribution&lt;/h4&gt;\n      {er_df.to_html()}\n    &lt;/div&gt;          \n    &lt;div&gt;\n      &lt;h4&gt;Confidence Level Distribution&lt;/h4&gt;\n      {confidence_df.to_html()}\n    &lt;/div&gt;\n  &lt;/div&gt;\n  \"\"\"\n  return results, html_str"
  },
  {
    "objectID": "r4_predict_erstatus.html#logistic-regression",
    "href": "r4_predict_erstatus.html#logistic-regression",
    "title": "Predicting ER status imputing missing values",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nmodel_pipeline = imputation_pipeline(X_train, \n                                     classifier=LogisticRegression(random_state=0, max_iter=1000, class_weight='balanced'),\n                                     nfeat=5)\n\ncv_scores = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring='balanced_accuracy')\nprint(f\"Cross-validation accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n\nCross-validation accuracy: 0.952 (+/- 0.062)\n\n\n\n# Fit the final model\nmodel_pipeline.fit(X_train, y_train)\n\nPipeline(steps=[('imputation',\n                 ColumnTransformer(transformers=[('categorical',\n                                                  Pipeline(steps=[('encoder',\n                                                                   OrdinalEncoder()),\n                                                                  ('imputer',\n                                                                   KNNImputer(n_neighbors=50))]),\n                                                  ['lymph_node_status',\n                                                   'pgr_status', 'her2_status',\n                                                   'pam50_subtype',\n                                                   'overall_survival_event',\n                                                   'endocrine_treated',\n                                                   'chemo_treated',\n                                                   'ki67_status', 'nhg']),\n                                                 ('numerical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   KNNImputer(n_neighbors=20)),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['age_at_diagnosis',\n                                                   'tumor_size',\n                                                   'overall_survival_days',\n                                                   'seurat_clusters'])])),\n                ('feature_selection',\n                 SelectKBest(k=5,\n                             score_func=&lt;function mutual_info_classif at 0x7f5f0cf41990&gt;)),\n                ('classifier',\n                 LogisticRegression(class_weight='balanced', max_iter=1000,\n                                    random_state=0))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFittedPipeline(steps=[('imputation',\n                 ColumnTransformer(transformers=[('categorical',\n                                                  Pipeline(steps=[('encoder',\n                                                                   OrdinalEncoder()),\n                                                                  ('imputer',\n                                                                   KNNImputer(n_neighbors=50))]),\n                                                  ['lymph_node_status',\n                                                   'pgr_status', 'her2_status',\n                                                   'pam50_subtype',\n                                                   'overall_survival_event',\n                                                   'endocrine_treated',\n                                                   'chemo_treated',\n                                                   'ki67_status', 'nhg']),\n                                                 ('numerical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   KNNImputer(n_neighbors=20)),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['age_at_diagnosis',\n                                                   'tumor_size',\n                                                   'overall_survival_days',\n                                                   'seurat_clusters'])])),\n                ('feature_selection',\n                 SelectKBest(k=5,\n                             score_func=&lt;function mutual_info_classif at 0x7f5f0cf41990&gt;)),\n                ('classifier',\n                 LogisticRegression(class_weight='balanced', max_iter=1000,\n                                    random_state=0))]) imputation: ColumnTransformer?Documentation for imputation: ColumnTransformerColumnTransformer(transformers=[('categorical',\n                                 Pipeline(steps=[('encoder', OrdinalEncoder()),\n                                                 ('imputer',\n                                                  KNNImputer(n_neighbors=50))]),\n                                 ['lymph_node_status', 'pgr_status',\n                                  'her2_status', 'pam50_subtype',\n                                  'overall_survival_event', 'endocrine_treated',\n                                  'chemo_treated', 'ki67_status', 'nhg']),\n                                ('numerical',\n                                 Pipeline(steps=[('imputer',\n                                                  KNNImputer(n_neighbors=20)),\n                                                 ('scaler', StandardScaler())]),\n                                 ['age_at_diagnosis', 'tumor_size',\n                                  'overall_survival_days',\n                                  'seurat_clusters'])]) categorical['lymph_node_status', 'pgr_status', 'her2_status', 'pam50_subtype', 'overall_survival_event', 'endocrine_treated', 'chemo_treated', 'ki67_status', 'nhg'] OrdinalEncoder?Documentation for OrdinalEncoderOrdinalEncoder() KNNImputer?Documentation for KNNImputerKNNImputer(n_neighbors=50) numerical['age_at_diagnosis', 'tumor_size', 'overall_survival_days', 'seurat_clusters'] KNNImputer?Documentation for KNNImputerKNNImputer(n_neighbors=20) StandardScaler?Documentation for StandardScalerStandardScaler() SelectKBest?Documentation for SelectKBestSelectKBest(k=5, score_func=&lt;function mutual_info_classif at 0x7f5f0cf41990&gt;) LogisticRegression?Documentation for LogisticRegressionLogisticRegression(class_weight='balanced', max_iter=1000, random_state=0) \n\n\n\n# Make predictions on test set\ny_pred = model_pipeline.predict(X_test)\ny_pred_proba = model_pipeline.predict_proba(X_test)\n\nresults, html_str = show_results(model_pipeline, X_test, y_pred_proba)\n\ndisplay(results)\ndisplay(HTML(html_str))\n\n\n\n\n\n\n\n\nProb_ER+\nProb_ER-\nMax_Probability\nPredicted_ER_Status\nConfidence_Level\n\n\nPatient_ID\n\n\n\n\n\n\n\n\n\nF1\n0.017625\n0.982375\n0.982375\nER-\nHigh\n\n\nF6\n0.017625\n0.982375\n0.982375\nER-\nHigh\n\n\nF15\n0.416440\n0.583560\n0.583560\nER-\nLow\n\n\nF16\n0.017625\n0.982375\n0.982375\nER-\nHigh\n\n\nF27\n0.026501\n0.973499\n0.973499\nER-\nHigh\n\n\n...\n...\n...\n...\n...\n...\n\n\nF2962\n0.819012\n0.180988\n0.819012\nER+\nHigh\n\n\nF2965\n0.013485\n0.986515\n0.986515\nER-\nHigh\n\n\nF2967\n0.987457\n0.012543\n0.987457\nER+\nHigh\n\n\nF2976\n0.982419\n0.017581\n0.982419\nER+\nHigh\n\n\nF3242\n0.030064\n0.969936\n0.969936\nER-\nHigh\n\n\n\n\n200 rows × 5 columns\n\n\n\n\n    \n      ER Status Distribution\n      \n\n\n\n\nLabel\nCount\n\n\nER_Status\n\n\n\n\n\n\nER+\n0\n33\n\n\nER-\n1\n167\n\n\n\n\n              \n    \n      Confidence Level Distribution\n      \n\n\n\n\nCount\nPercentage\n\n\nConfidence_Level\n\n\n\n\n\n\nHigh\n174\n87.0\n\n\nMedium\n18\n9.0\n\n\nLow\n8\n4.0\n\n\n\n\n    \n  \n\n\n\nFeature selection\nIn blue the top 5 features used in the model, in orange the discarded ones.\n\ncategorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\nnumerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\nall_features = np.array(categorical_features + numerical_features)\n\nfeature_selector = model_pipeline.named_steps['feature_selection']\nfeature_index = feature_selector.get_support(indices=True)\nselected_feature = all_features[feature_index]\n\nfeature_importance = pd.DataFrame({\n  'Feature': all_features,\n  'Score': feature_selector.scores_,\n  'Selected': feature_selector.get_support()\n}).sort_values('Score', ascending=False)\n# display(feature_importance)\n\nplt.figure(figsize=(10, 6))\ncolors = ['tab:blue' if selected else 'tab:orange' for selected in feature_importance['Selected']]\nplt.barh(feature_importance['Feature'], feature_importance['Score'], color=colors)\nplt.xlabel('Feature Score')\nplt.gca().invert_yaxis()\n\n# fig, ax = plt.subplots(figsize=(10, 6))\n# colors = ['tab:green' if selected else 'tab:orange' for selected in feature_importance['Selected']]\n# ax.barh(feature_importance['Feature'], feature_importance['Score'], color=colors)\n# ax.set_xlabel('Feature Score')\n# ax.invert_yaxis()\n\n\n\n\n\n\n\n\n\n\nParameter tuning\n\n%%time\n\nmodel_pipeline = imputation_pipeline(X_train,\n                                     classifier= LogisticRegression(random_state=0, max_iter=1000, class_weight='balanced'),\n                                     nfeat = 5)\n\nparam_grid = [\n  {\n    'classifier__C': [0.01, 0.1, 1, 10, 100],\n    'classifier__penalty': ['l2'],\n    'classifier__solver': ['lbfgs', 'newton-cholesky']\n  },\n  {\n    'classifier__C': [0.01, 0.1, 1, 10, 100],\n    'classifier__penalty': ['l1', 'l2'],\n    'classifier__solver': ['liblinear', 'saga']\n  },\n  {\n    'classifier__C': [0.01, 0.1, 1, 10, 100],\n    'classifier__penalty': ['elasticnet'],\n    'classifier__solver': ['saga'],  # saga is the only solver that supports elasticnet\n    'classifier__l1_ratio': [0.1, 0.5, 0.7, 0.9]\n  }\n]\n\nprint(\"Starting Grid Search for Logistic Regression...\")\ngrid_lr = GridSearchCV(\n  model_pipeline, \n  param_grid, \n  cv=5, \n  scoring='balanced_accuracy', \n  n_jobs=-1, \n  verbose=1\n)\n\n# Fit the grid search\ngrid_lr.fit(X_train, y_train)\n\n# Display results\nprint(\"\\nBest parameters:\")\nprint(grid_lr.best_params_)\nprint(f\"\\nAveraged cross-validation balanced accuracy score: {grid_lr.best_score_:.3f}\")\n\nStarting Grid Search for Logistic Regression...\nFitting 5 folds for each of 50 candidates, totalling 250 fits\n\nBest parameters:\n{'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n\nAveraged cross-validation balanced accuracy score: 0.955\nCPU times: user 4.77 s, sys: 612 ms, total: 5.39 s\nWall time: 27.8 s\n\n\n\n# Use the best model for predictions\nbest_model_lr = grid_lr.best_estimator_\ny_pred = best_model_lr.predict(X_test)\ny_pred_proba = best_model_lr.predict_proba(X_test)\n\nresults_lr, html_str = show_results(best_model_lr, X_test, y_pred_proba)\n\ndisplay(results_lr)\ndisplay(HTML(html_str))\n\n\n\n\n\n\n\n\nProb_ER+\nProb_ER-\nMax_Probability\nPredicted_ER_Status\nConfidence_Level\n\n\nPatient_ID\n\n\n\n\n\n\n\n\n\nF1\n0.015638\n0.984362\n0.984362\nER-\nHigh\n\n\nF6\n0.015638\n0.984362\n0.984362\nER-\nHigh\n\n\nF15\n0.403025\n0.596975\n0.596975\nER-\nLow\n\n\nF16\n0.015638\n0.984362\n0.984362\nER-\nHigh\n\n\nF27\n0.023326\n0.976674\n0.976674\nER-\nHigh\n\n\n...\n...\n...\n...\n...\n...\n\n\nF2962\n0.827821\n0.172179\n0.827821\nER+\nHigh\n\n\nF2965\n0.011873\n0.988127\n0.988127\nER-\nHigh\n\n\nF2967\n0.988520\n0.011480\n0.988520\nER+\nHigh\n\n\nF2976\n0.984569\n0.015431\n0.984569\nER+\nHigh\n\n\nF3242\n0.026950\n0.973050\n0.973050\nER-\nHigh\n\n\n\n\n200 rows × 5 columns\n\n\n\n\n    \n      ER Status Distribution\n      \n\n\n\n\nLabel\nCount\n\n\nER_Status\n\n\n\n\n\n\nER+\n0\n32\n\n\nER-\n1\n168\n\n\n\n\n              \n    \n      Confidence Level Distribution\n      \n\n\n\n\nCount\nPercentage\n\n\nConfidence_Level\n\n\n\n\n\n\nHigh\n175\n87.5\n\n\nMedium\n16\n8.0\n\n\nLow\n9\n4.5\n\n\n\n\n    \n  \n\n\n\n\nComparing tuned and untuned model\nThe tuned model slightly outperformed the untuned one.\n\nprint(\"Default model parameters:\", model_pipeline.named_steps['classifier'].get_params())\nprint(\"Best tuned parameters:\", best_model_lr.named_steps['classifier'].get_params())\n\n# Compare probability distributions\nprint(\"\\nDefault model confidence distribution:\")\nprint(results['Confidence_Level'].value_counts())\nprint(\"\\nTuned model confidence distribution:\")  \nprint(results_lr['Confidence_Level'].value_counts())\n\n## compare averaged cross-validated balanced accuracy \nprint(f\"\\nAveraged cross-validated balanced accuracy (untuned model): {cv_scores.mean():.3f}\")\nprint(f\"Averaged cross-validation balanced accuracy score (tuned model): {grid_lr.best_score_:.3f}\")\n\nDefault model parameters: {'C': 1.0, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 0, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\nBest tuned parameters: {'C': 100, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 0, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n\nDefault model confidence distribution:\nConfidence_Level\nHigh      174\nMedium     18\nLow         8\nName: count, dtype: int64\n\nTuned model confidence distribution:\nConfidence_Level\nHigh      175\nMedium     16\nLow         9\nName: count, dtype: int64\n\nAveraged cross-validated balanced accuracy (untuned model): 0.952\nAveraged cross-validation balanced accuracy score (tuned model): 0.955"
  },
  {
    "objectID": "r4_predict_erstatus.html#random-frorest",
    "href": "r4_predict_erstatus.html#random-frorest",
    "title": "Predicting ER status imputing missing values",
    "section": "Random Frorest",
    "text": "Random Frorest\n\n%%time\n\nmodel_pipeline = imputation_pipeline(X_train,\n                                     classifier = RandomForestClassifier(random_state=0, class_weight='balanced'),\n                                     nfeat=5)\n\nparam_grid = {\n  'classifier__n_estimators': [50, 100, 200],\n  'classifier__max_depth': [5, 10, 20, 30],\n  'classifier__min_samples_split': [2, 5, 10, 20],\n  'classifier__min_samples_leaf': [1, 2, 4, 8],\n  'classifier__max_features': ['sqrt', 'log2']\n}\n\n# from sklearn.tree import DecisionTreeClassifier\n# DecisionTreeClassifier(random_state=0)\n# param_grid = {\n#     'classifier__max_depth': [5, 10, 20, 30],\n#     'classifier__min_samples_split': [2, 5, 10, 20],\n#     'classifier__min_samples_leaf': [1, 2, 4, 8],\n#     'classifier__criterion': ['gini', 'entropy'],\n#     'classifier__max_features': ['sqrt', 'log2']\n# }\n\nprint(\"Starting Grid Search for Random Forest...\")\ngrid_rf = GridSearchCV(\n  model_pipeline, \n  param_grid, \n  cv=5, \n  scoring='balanced_accuracy', \n  n_jobs=-1, \n  verbose=1\n)\n\n# Fit the grid search\ngrid_rf.fit(X_train, y_train)\n\n# Display results\nprint(\"\\nBest parameters:\")\nprint(grid_rf.best_params_)\nprint(f\"\\nAveraged cross-validation balanced accuracy score: {grid_rf.best_score_:.3f}\")\n\nStarting Grid Search for Random Forest...\nFitting 5 folds for each of 384 candidates, totalling 1920 fits\n\nBest parameters:\n{'classifier__max_depth': 5, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 8, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 50}\n\nAveraged cross-validation balanced accuracy score: 0.963\nCPU times: user 19 s, sys: 954 ms, total: 19.9 s\nWall time: 3min 27s\n\n\n\n# Use the best model for predictions\nbest_model_rf = grid_rf.best_estimator_\ny_pred = best_model_rf.predict(X_test)\ny_pred_proba = best_model_rf.predict_proba(X_test)\n\nresults_rf, html_str = show_results(best_model_rf, X_test, y_pred_proba)\n\ndisplay(results_rf)\ndisplay(HTML(html_str))\n\n\n\n\n\n\n\n\nProb_ER+\nProb_ER-\nMax_Probability\nPredicted_ER_Status\nConfidence_Level\n\n\nPatient_ID\n\n\n\n\n\n\n\n\n\nF1\n0.081427\n0.918573\n0.918573\nER-\nHigh\n\n\nF6\n0.081427\n0.918573\n0.918573\nER-\nHigh\n\n\nF15\n0.790802\n0.209198\n0.790802\nER+\nMedium\n\n\nF16\n0.081427\n0.918573\n0.918573\nER-\nHigh\n\n\nF27\n0.105113\n0.894887\n0.894887\nER-\nHigh\n\n\n...\n...\n...\n...\n...\n...\n\n\nF2962\n0.837857\n0.162143\n0.837857\nER+\nHigh\n\n\nF2965\n0.080274\n0.919726\n0.919726\nER-\nHigh\n\n\nF2967\n0.999465\n0.000535\n0.999465\nER+\nHigh\n\n\nF2976\n0.999871\n0.000129\n0.999871\nER+\nHigh\n\n\nF3242\n0.163633\n0.836367\n0.836367\nER-\nHigh\n\n\n\n\n200 rows × 5 columns\n\n\n\n\n    \n      ER Status Distribution\n      \n\n\n\n\nLabel\nCount\n\n\nER_Status\n\n\n\n\n\n\nER+\n0\n38\n\n\nER-\n1\n162\n\n\n\n\n              \n    \n      Confidence Level Distribution\n      \n\n\n\n\nCount\nPercentage\n\n\nConfidence_Level\n\n\n\n\n\n\nHigh\n176\n88.0\n\n\nMedium\n23\n11.5\n\n\nLow\n1\n0.5"
  },
  {
    "objectID": "r4_predict_erstatus.html#svm",
    "href": "r4_predict_erstatus.html#svm",
    "title": "Predicting ER status imputing missing values",
    "section": "SVM",
    "text": "SVM\n\n%%time\n\nmodel_pipeline = imputation_pipeline(X_train, \n                                     classifier= SVC(probability=True, class_weight='balanced'),\n                                     nfeat=5) \n\n\nparam_grid = [\n  # Grid for Linear kernel\n  {\n    'classifier__kernel': ['linear'],\n    'classifier__C': [0.01, 0.1, 1, 10, 100]\n  },\n  # Grid for RBF kernel\n  {\n    'classifier__kernel': ['rbf'],\n    'classifier__C': [0.01, 0.1, 1, 10, 100],\n    'classifier__gamma': [0.01, 0.1, 1, 10, 100]\n  },\n  # Grid for Polynomial kernel\n  {\n    'classifier__kernel': ['poly'],\n    'classifier__C': [0.01, 0.1, 1, 10, 100],\n    'classifier__degree': [2, 3, 4, 5]\n  }\n]\n\nprint(\"Starting Grid Search for SVM...\")\ngrid_svm = GridSearchCV(\n  model_pipeline, \n  param_grid, \n  cv=5, \n  scoring='balanced_accuracy', \n  n_jobs=-1, \n  verbose=1\n)\n\n# Fit the grid search\ngrid_svm.fit(X_train, y_train)\n\n# Display results\nprint(\"\\nBest parameters:\")\nprint(grid_svm.best_params_)\nprint(f\"\\nAveraged cross-validation balanced accuracy score: {grid_svm.best_score_:.3f}\")\n\nStarting Grid Search for SVM...\nFitting 5 folds for each of 50 candidates, totalling 250 fits\n\nBest parameters:\n{'classifier__C': 0.1, 'classifier__gamma': 0.1, 'classifier__kernel': 'rbf'}\n\nAveraged cross-validation balanced accuracy score: 0.961\nCPU times: user 5.21 s, sys: 419 ms, total: 5.63 s\nWall time: 40.1 s\n\n\n\n# Use the best model for predictions\nbest_model_svm = grid_svm.best_estimator_\ny_pred = best_model_svm.predict(X_test)\ny_pred_proba = best_model_svm.predict_proba(X_test)\n\nresults_svm, html_str = show_results(best_model_svm, X_test, y_pred_proba)\n\ndisplay(results_svm)\ndisplay(HTML(html_str))\n\n\n\n\n\n\n\n\nProb_ER+\nProb_ER-\nMax_Probability\nPredicted_ER_Status\nConfidence_Level\n\n\nPatient_ID\n\n\n\n\n\n\n\n\n\nF1\n0.144080\n0.855920\n0.855920\nER-\nHigh\n\n\nF6\n0.144080\n0.855920\n0.855920\nER-\nHigh\n\n\nF15\n0.972072\n0.027928\n0.972072\nER+\nHigh\n\n\nF16\n0.144080\n0.855920\n0.855920\nER-\nHigh\n\n\nF27\n0.370919\n0.629081\n0.629081\nER-\nMedium\n\n\n...\n...\n...\n...\n...\n...\n\n\nF2962\n0.979503\n0.020497\n0.979503\nER+\nHigh\n\n\nF2965\n0.126436\n0.873564\n0.873564\nER-\nHigh\n\n\nF2967\n0.999174\n0.000826\n0.999174\nER+\nHigh\n\n\nF2976\n0.999446\n0.000554\n0.999446\nER+\nHigh\n\n\nF3242\n0.380777\n0.619223\n0.619223\nER-\nMedium\n\n\n\n\n200 rows × 5 columns\n\n\n\n\n    \n      ER Status Distribution\n      \n\n\n\n\nLabel\nCount\n\n\nER_Status\n\n\n\n\n\n\nER+\n0\n27\n\n\nER-\n1\n173\n\n\n\n\n              \n    \n      Confidence Level Distribution\n      \n\n\n\n\nCount\nPercentage\n\n\nConfidence_Level\n\n\n\n\n\n\nHigh\n147\n73.5\n\n\nMedium\n40\n20.0\n\n\nLow\n13\n6.5"
  },
  {
    "objectID": "r4_predict_erstatus.html#results",
    "href": "r4_predict_erstatus.html#results",
    "title": "Predicting ER status imputing missing values",
    "section": "Results",
    "text": "Results\nBelow we populate the original dataset with the predicted ER staus and the imputed values obtained by the best model (random forest) according to the averaged balanced accuracy.\n\npd.DataFrame({\n  'Model': ['Logistic Regression',\n            'Random Forest',\n            'SVM'],\n  'Avg_Balanced_Accuracy': [f\"{grid_lr.best_score_:.3f}\", \n                            f\"{grid_rf.best_score_:.3f}\", \n                            f\"{grid_svm.best_score_:.3f}\"],\n}).set_index('Model').sort_values('Avg_Balanced_Accuracy', ascending=False)\n\n\n\n\n\n\n\n\nAvg_Balanced_Accuracy\n\n\nModel\n\n\n\n\n\nRandom Forest\n0.963\n\n\nSVM\n0.961\n\n\nLogistic Regression\n0.955\n\n\n\n\n\n\n\n\n# get imputer for the best model\nimputer = best_model_rf.named_steps['imputation']\n\n# get fitted imputations\nX_train_imputed = imputer.transform(X_train)\nX_test_imputed = imputer.transform(X_test)\n\n# split imputed data back into numerical and categorical parts\n# nb: the slicing order is defined by ColumnTransformer in imputation_pipeline() -&gt; categorical come before numerical features\ncat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\nnum_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n\nn_cat = len(cat_features)\nn_num = len(num_features)\n\nX_train_cat = X_train_imputed[:, :n_cat]\nX_train_num = X_train_imputed[:, n_cat:n_num+n_cat]\n\nX_test_cat = X_test_imputed[:, :n_cat]\nX_test_num = X_test_imputed[:, n_cat:n_num+n_cat]\n\n# get the ordinal encoder from the categorical transformer\ncategorical_transformer = imputer.named_transformers_['categorical']\nordinal_encoder = categorical_transformer.named_steps['encoder']\n\n# inverse transform categorical features to get original labels\nX_train_cat = ordinal_encoder.inverse_transform(X_train_cat)\nX_test_cat = ordinal_encoder.inverse_transform(X_test_cat)\n\n# create dataframes with original categorical values and processed numerical values\nX_train_imputed = pd.DataFrame(\n  np.column_stack([X_train_cat, X_train_num]),\n  columns=cat_features + num_features,\n  index=X_train.index\n)\n\nX_train_imputed = X_train_imputed[X_train.columns]\n\nX_test_imputed = pd.DataFrame(\n  np.column_stack([X_test_cat, X_test_num]),\n  columns=cat_features + num_features,\n  index=X_test.index\n)\n\nX_test_imputed = X_test_imputed[X_test.columns]\n\n## NaN comparison\n# print(\"Training set - original data:\")\n# display(X_train[X_train.isnull().any(axis=1)])\n\n# print(\"\\nTraining set - after imputation:\")\n# display(X_train_imputed[X_train.isnull().any(axis=1)])\n\n# print(\"\\nTest set - original data:\")\n# display(X_test[X_test.isnull().any(axis=1)])\n\n# print(\"\\nTest set - after imputation:\")\n# display(X_test_imputed[X_test.isnull().any(axis=1)])\n## \n\n## complete dataset with the predicted ER status and the imputed values.\npred_er = results_svm[['Predicted_ER_Status']].rename(columns={'Predicted_ER_Status': 'er_status'})\npred_er.index.name = 'patient'\nX_test_complete = pd.concat([X_test_imputed, pred_er], axis=1)\n\ntrain_er = df.loc[~y.isna(), ['er_status']]\nX_train_complete = pd.concat([X_train_imputed, train_er], axis=1)\n\ndisplay(pd.concat([X_train_complete, X_test_complete]).reindex(df.index))\n\n## check\nprint(\"\\nTot. missing values including training and test:\")\nprint(\"Before imputation:\", X_train.isnull().sum().sum() + X_test.isnull().sum().sum())\nprint(\"After imputation:\", X_train_imputed.isnull().sum().sum() + X_test_imputed.isnull().sum().sum())\n\n\n\n\n\n\n\n\nage_at_diagnosis\ntumor_size\nlymph_node_status\npgr_status\nher2_status\npam50_subtype\noverall_survival_days\noverall_survival_event\nendocrine_treated\nchemo_treated\nki67_status\nnhg\nseurat_clusters\ner_status\n\n\npatient\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF1\n-1.51916\n-0.904251\nNodeNegative\nPgR+\nHER2-\nBasal\n1.604754\nnosurvival\nuntreated\ntreated\nKi67+\nG3\n0.668592\nER-\n\n\nF2\n-1.135531\n-0.482241\nNodePositive\nPgR+\nHER2-\nLumA\n1.604754\nnosurvival\ntreated\ntreated\nKi67+\nG2\n-1.249785\nER+\n\n\nF3\n0.47571\n0.614988\nNodePositive\nPgR+\nHER2-\nLumB\n1.197026\nsurvival\ntreated\ntreated\nKi67+\nG3\n-0.86611\nER+\n\n\nF4\n-1.826063\n2.64064\nNodePositive\nPgR+\nHER2+\nLumA\n1.705149\nnosurvival\ntreated\ntreated\nKi67+\nG3\n0.284916\nER+\n\n\nF5\n0.782613\n3.40026\nNodePositive\nPgR+\nHER2-\nNormal\n1.64983\nnosurvival\ntreated\nuntreated\nKi67+\nG2\n-0.098759\nER+\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nF3269\n0.705887\n-0.566643\nNodeNegative\nPgR+\nHER2-\nLumB\n-1.491111\nnosurvival\ntreated\ntreated\nKi67+\nG2\n1.435942\nER+\n\n\nF3270\n0.47571\n0.868194\nNodePositive\nPgR+\nHER2-\nLumA\n-1.480866\nnosurvival\ntreated\ntreated\nKi67+\nG2\n1.819618\nER+\n\n\nF3271\n0.782613\n-0.144632\nNodeNegative\nPgR-\nHER2+\nLumB\n-1.478817\nnosurvival\ntreated\ntreated\nKi67+\nG3\n0.284916\nER+\n\n\nF3272\n0.322258\n1.121401\nNodePositive\nPgR+\nHER2-\nLumA\n-1.515697\nnosurvival\ntreated\nuntreated\nKi67+\nG2\n-1.249785\nER+\n\n\nF3273\n-0.214822\n-0.229034\nNodePositive\nPgR+\nHER2-\nLumA\n-1.517746\nnosurvival\ntreated\ntreated\nKi67+\nG2\n-0.098759\nER+\n\n\n\n\n3273 rows × 14 columns\n\n\n\n\nTot. missing values including training and test:\nBefore imputation: 2407\nAfter imputation: 0"
  }
]